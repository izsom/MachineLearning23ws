{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import f_classif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection(X, Y):\n",
    "    f, p = f_classif(X, Y)\n",
    "    corr_df = pd.DataFrame({'features': X.columns, 'f_val': f, 'p_val': p})\n",
    "    # using the 3 level significance test \n",
    "    # (***: p_val < 0.001, **: p_val < 0.01, *: p_val < 0.05)\n",
    "    # we will select the features with p_val < 0.05\n",
    "    p_tr = 0.001\n",
    "    relevant_features = corr_df.loc[corr_df['p_val'] < p_tr, \"features\"].tolist()\n",
    "    # print(f\"There are {len(relevant_features)} relevant features and they are: {relevant_features}\")\n",
    "    \n",
    "    return relevant_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(X, Y, preprocess, classifier, folds=5):\n",
    "    kf = KFold(n_splits=folds, shuffle=True)\n",
    "    f1_folds = []\n",
    "    #do the KFold corss validation\n",
    "    for train_index, test_index in kf.split(X,Y):\n",
    "        # split the data into train and test for this fold\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = Y.iloc[train_index], Y.iloc[test_index]   \n",
    "        \n",
    "        # preprocess the data\n",
    "        if preprocess == \"none\":\n",
    "            X_train_preprocessed = X_train\n",
    "            X_test_preprocessed = X_test\n",
    "        elif preprocess == \"featureselection\":\n",
    "            # sig_selector = VarianceThreshold(threshold=0.4)\n",
    "            # X_train_preprocessed = sig_selector.fit_transform(X_train)\n",
    "            # X_test_preprocessed = sig_selector.transform(X_test)\n",
    "            rel_features = feature_selection(X_train, y_train)\n",
    "            X_train_preprocessed = X_train[rel_features]\n",
    "            X_test_preprocessed = X_test[rel_features]\n",
    "        else:\n",
    "            scaler = StandardScaler()\n",
    "            X_train_preprocessed = scaler.fit_transform(X_train)\n",
    "            X_test_preprocessed = scaler.transform(X_test)\n",
    "            \n",
    "        # train and evaluate the model\n",
    "        if classifier.__class__.__name__ == \"SVC\":\n",
    "            clf = classifier\n",
    "            clf.fit(X_train_preprocessed, y_train)\n",
    "            Y_pred_fold = clf.predict(X_test_preprocessed)\n",
    "            \n",
    "        # calculate the accuracy per fold\n",
    "        f1_folds.append(f1_score(y_test, Y_pred_fold, average=\"weighted\"))\n",
    "    \n",
    "    # Calculate the mean accuracy over all folds\n",
    "    f1_mean = np.mean(f1_folds)    \n",
    "    \n",
    "            \n",
    "         \n",
    "        \n",
    "    return f1_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Congressional voting\n",
    "An iterativ imputation has been already done on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"./preprocessed-datasets/CongressionVoting_prepro.csv\")\n",
    "test_df_X = test_df.drop(columns=[\"class\"])\n",
    "test_df_Y = test_df[\"class\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "The **evaluate_model** function takes:\n",
    "* the input feature (*X*),\n",
    "* the dependent variable (*Y*)\n",
    "* the preprocessing method as a string:\n",
    "    * the so far implemented possible options can be found in the *preprocess_options* list. Here *else* is implemented as the *StandardScaler()*, however it could be combined with additional feature selection to achieve a better result.\n",
    "* classifier as a function:\n",
    "    * so far the only tried one is *SVC(C=3, kernel='sigmoid')*\n",
    "* folds to define the number of  folds. The default value is 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_options = [\"none\", \"featureselection\", \"else\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.847269679150177"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(test_df_X, test_df_Y, \"featureselection\", SVC(C=3, kernel='sigmoid'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
