{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"preprocessed-datasets/CongressionVoting_prepro.csv\")\n",
    "\n",
    "df['class'] = df['class'].map({'democrat': 0, 'republican': 1})\n",
    "\n",
    "# Convert to numpy array\n",
    "data = df.to_numpy()\n",
    "\n",
    "# Split the data into training (80%) and testing (20%) sets\n",
    "np.random.shuffle(data)\n",
    "split = int(0.8 * len(data))\n",
    "train_set = data[:split]\n",
    "test_set = data[split:]\n",
    "\n",
    "# Split training set to X and y\n",
    "X_train = train_set[:, :-1]\n",
    "y_train = train_set[:, -1]\n",
    "\n",
    "# Split testing set to X and y\n",
    "X_test = test_set[:, :-1]\n",
    "y_test = test_set[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def sigmoid(x):\n",
    "#     return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# def sigmoid_derivative(x):\n",
    "#     return x * (1 - x)\n",
    "\n",
    "# def initialize_parameters(input_size, hidden_size, output_size):\n",
    "#     np.random.seed(18)\n",
    "#     W_h = np.random.rand(input_size, hidden_size)\n",
    "#     W_o = np.random.rand(hidden_size, output_size)\n",
    "#     return W_h, W_o\n",
    "\n",
    "# def forward_propagation(X, W_h, W_o):\n",
    "#     hidden_layer_input = np.dot(X, W_h)\n",
    "#     hidden_layer_output = sigmoid(hidden_layer_input)\n",
    "\n",
    "#     output_layer_input = np.dot(hidden_layer_output, W_o)\n",
    "#     output_layer_output = sigmoid(output_layer_input)\n",
    "\n",
    "#     return hidden_layer_output, output_layer_output\n",
    "\n",
    "# def backward_propagation(X, y, hidden_layer_output, output_layer_output, W_o):\n",
    "#     output_error = y - output_layer_output\n",
    "#     output_delta = output_error * sigmoid_derivative(output_layer_output)\n",
    "\n",
    "#     hidden_layer_error = output_delta.dot(W_o.T)\n",
    "#     hidden_layer_delta = hidden_layer_error * sigmoid_derivative(hidden_layer_output)\n",
    "\n",
    "#     return hidden_layer_delta, output_delta\n",
    "\n",
    "# def update_weights(X, hidden_layer_output, output_delta, hidden_layer_delta, W_h, W_o, learning_rate):\n",
    "#     W_o += hidden_layer_output.T.dot(output_delta) * learning_rate\n",
    "#     W_h += X.T.dot(hidden_layer_delta) * learning_rate\n",
    "\n",
    "# def train_neural_network(X_train, y_train, epochs=10, hidden_size=25, learning_rate=0.01):\n",
    "#     input_size = X_train.shape[1]\n",
    "#     output_size = 1\n",
    "\n",
    "#     W_h, W_o = initialize_parameters(input_size, hidden_size, output_size)\n",
    "\n",
    "#     for epoch in range(epochs):\n",
    "#         hidden_layer_output, output_layer_output = forward_propagation(X_train, W_h, W_o)\n",
    "\n",
    "#         hidden_layer_delta, output_delta = backward_propagation(X_train, y_train.reshape(-1, 1), hidden_layer_output, output_layer_output, W_o)\n",
    "\n",
    "#         update_weights(X_train, hidden_layer_output, output_delta, hidden_layer_delta, W_h, W_o, learning_rate)\n",
    "\n",
    "#         loss = np.mean(np.square(y_train.reshape(-1, 1) - output_layer_output))\n",
    "#         print(f\"Epoch {epoch}, Loss: {loss}\")\n",
    "\n",
    "#     return W_h, W_o\n",
    "\n",
    "# def predict(X, W_h, W_o):\n",
    "#     _, output_layer_output = forward_propagation(X, W_h, W_o)\n",
    "#     return (output_layer_output > 0.5).astype(int).flatten()\n",
    "\n",
    "# # Train the neural network\n",
    "# W_h, W_o = train_neural_network(X_train, y_train, epochs=10, hidden_size=int(2/3 * X_train.shape[1] + 2), learning_rate=0.01)\n",
    "\n",
    "# # Test the neural network\n",
    "# y_pred = predict(X_test, W_h, W_o)\n",
    "\n",
    "# # Evaluate the accuracy\n",
    "# accuracy = np.mean(y_pred == y_test)\n",
    "# print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.6173457853015846\n",
      "Epoch 1, Loss: 0.6103499674528282\n",
      "Epoch 2, Loss: 0.5986254428179401\n",
      "Epoch 3, Loss: 0.5762474544319833\n",
      "Epoch 4, Loss: 0.5249733138496462\n",
      "Epoch 5, Loss: 0.3880353133682924\n",
      "Epoch 6, Loss: 0.23014577469595807\n",
      "Epoch 7, Loss: 0.2299299737175882\n",
      "Epoch 8, Loss: 0.22991669138125662\n",
      "Epoch 9, Loss: 0.2299112922679349\n",
      "Accuracy: 0.5909090909090909\n"
     ]
    }
   ],
   "source": [
    "class Sigmoid:\n",
    "    def forward(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def backward(self, x):\n",
    "        return x * (1 - x)\n",
    "    \n",
    "\n",
    "class MeanSquaredError:\n",
    "    def calculate(self, y_true, y_pred):\n",
    "        return np.mean(np.square(y_true - y_pred))\n",
    "    \n",
    "\n",
    "class MLP:\n",
    "    def __init__(self, input_size, hidden_size, output_size, activation, loss_function):\n",
    "        np.random.seed(18)\n",
    "        self.W_h = np.random.rand(input_size, hidden_size)\n",
    "        self.W_o = np.random.rand(hidden_size, output_size)\n",
    "        self.activation = activation\n",
    "        self.loss_function = loss_function\n",
    "\n",
    "    def forward_propagation(self, X):\n",
    "        self.hidden_layer_input = np.dot(X, self.W_h)\n",
    "        self.hidden_layer_output = self.activation.forward(self.hidden_layer_input)\n",
    "\n",
    "        self.output_layer_input = np.dot(self.hidden_layer_output, self.W_o)\n",
    "        self.output_layer_output = self.activation.forward(self.output_layer_input)\n",
    "\n",
    "    def backward_propagation(self, X, y):\n",
    "        output_error = y - self.output_layer_output\n",
    "        output_delta = output_error * self.activation.backward(self.output_layer_output)\n",
    "\n",
    "        hidden_layer_error = output_delta.dot(self.W_o.T)\n",
    "        hidden_layer_delta = hidden_layer_error * self.activation.backward(self.hidden_layer_output)\n",
    "\n",
    "        return hidden_layer_delta, output_delta\n",
    "\n",
    "    def update_weights(self, X, hidden_layer_delta, output_delta, learning_rate):\n",
    "        self.W_o += self.hidden_layer_output.T.dot(output_delta) * learning_rate\n",
    "        self.W_h += X.T.dot(hidden_layer_delta) * learning_rate\n",
    "\n",
    "    def predict(self, X):\n",
    "        self.forward_propagation(X)\n",
    "        return (self.output_layer_output > 0.5).astype(int).flatten()\n",
    "    \n",
    "class Trainer:\n",
    "    def __init__(self, neural_network):\n",
    "        self.neural_network = neural_network\n",
    "\n",
    "    def train(self, X_train, y_train, epochs=10, learning_rate=0.01):\n",
    "        for epoch in range(epochs):\n",
    "            self.neural_network.forward_propagation(X_train)\n",
    "            hidden_layer_delta, output_delta = self.neural_network.backward_propagation(X_train, y_train.reshape(-1, 1))\n",
    "            self.neural_network.update_weights(X_train, hidden_layer_delta, output_delta, learning_rate)\n",
    "\n",
    "            loss = self.neural_network.loss_function.calculate(y_train.reshape(-1, 1), self.neural_network.output_layer_output)\n",
    "            print(f\"Epoch {epoch}, Loss: {loss}\")\n",
    "\n",
    "    def evaluate_accuracy(self, X_test, y_test):\n",
    "        y_pred = self.neural_network.predict(X_test)\n",
    "        accuracy = np.mean(y_pred == y_test)\n",
    "        print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "\n",
    "activation = Sigmoid()\n",
    "loss_function = MeanSquaredError()\n",
    "\n",
    "input_size = X_train.shape[1]\n",
    "hidden_size = int(2 / 3 * input_size + 2)\n",
    "output_size = 1\n",
    "neural_network = MLP(input_size, hidden_size, output_size, activation, loss_function)\n",
    "\n",
    "trainer = Trainer(neural_network)\n",
    "\n",
    "trainer.train(X_train, y_train, epochs=10, learning_rate=0.01)\n",
    "\n",
    "trainer.evaluate_accuracy(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
