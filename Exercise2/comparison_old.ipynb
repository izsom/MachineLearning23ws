{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F  \n",
    "from torch import optim \n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn.init as init\n",
    "import random\n",
    "import time\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "from traditional_model import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class for the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self, input_size, num_classes, hidden_layer_sizes, activation_function, apply_softmax = False):\n",
    "        super(NN, self).__init__()\n",
    "\n",
    "        seed = 18\n",
    "        torch.manual_seed(seed)\n",
    "\n",
    "        self.activation = activation_function\n",
    "        self.apply_softmax = apply_softmax\n",
    "\n",
    "        # Input layer\n",
    "        self.input_layer = nn.Linear(input_size, hidden_layer_sizes[0])\n",
    "        init.kaiming_uniform_(self.input_layer.weight, mode='fan_in', nonlinearity=activation_function.__name__)\n",
    "\n",
    "\n",
    "        # Hidden layers\n",
    "        self.hidden_layers = nn.ModuleList([\n",
    "            nn.Linear(hidden_layer_sizes[i], hidden_layer_sizes[i + 1])\n",
    "            for i in range(len(hidden_layer_sizes) - 1)\n",
    "        ])\n",
    "\n",
    "        for layer in self.hidden_layers:\n",
    "            init.kaiming_uniform_(layer.weight, mode='fan_in', nonlinearity=activation_function.__name__)\n",
    "\n",
    "\n",
    "        # Output layer\n",
    "        self.output_layer = nn.Linear(hidden_layer_sizes[-1], num_classes)\n",
    "        init.kaiming_uniform_(self.output_layer.weight, mode='fan_in', nonlinearity=activation_function.__name__)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.float()\n",
    "        x = self.activation(self.input_layer(x))\n",
    "\n",
    "        # Process through hidden layers\n",
    "        for layer in self.hidden_layers:\n",
    "            x = self.activation(layer(x))\n",
    "\n",
    "        if self.apply_softmax:\n",
    "            x = F.softmax(self.output_layer(x), dim=1)\n",
    "        else:\n",
    "            x = self.output_layer(x)\n",
    "\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, optimizer, criterion, num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0.0  # Initialize total loss for the epoch\n",
    "        num_batches = len(train_loader)\n",
    "\n",
    "        for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "            data = data.reshape(data.shape[0], -1)\n",
    "\n",
    "            scores = model(data)\n",
    "            loss = criterion(scores, targets)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()  # Accumulate the batch loss\n",
    "\n",
    "        average_loss = total_loss / num_batches\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Average Loss: {average_loss}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to calculate the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(loader, model):\n",
    "\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "\n",
    "            x = x.reshape(x.shape[0], -1)\n",
    "\n",
    "            scores = model(x)\n",
    "            _, predictions = scores.max(1)\n",
    "\n",
    "            num_correct += (predictions == y).sum()\n",
    "            num_samples += predictions.size(0)\n",
    "\n",
    "    model.train()\n",
    "    return num_correct / num_samples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to split the data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(data: pd.DataFrame, target_label : str, test_size=0.2, return_torch=None):\n",
    "        \n",
    "    # split the data into train and test\n",
    "    train = data.sample(frac=(1-test_size),random_state=200)\n",
    "    test = data.drop(train.index)\n",
    "    \n",
    "    # split the train and test into X and Y\n",
    "    train_X = train.drop([target_label], axis=1).values\n",
    "    train_Y = train[target_label].values\n",
    "    test_X = test.drop([target_label], axis=1).values\n",
    "    test_Y = test[target_label].values\n",
    "    \n",
    "    if return_torch:\n",
    "        train_X = torch.tensor(train_X)\n",
    "        train_Y = torch.tensor(train_Y)\n",
    "        test_X = torch.tensor(test_X)\n",
    "        test_Y = torch.tensor(test_Y)\n",
    "    \n",
    "    return train_X, train_Y, test_X, test_Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using best configuration for the congressional voting dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>handicapped-infants</th>\n",
       "      <th>water-project-cost-sharing</th>\n",
       "      <th>adoption-of-the-budget-resolution</th>\n",
       "      <th>physician-fee-freeze</th>\n",
       "      <th>el-salvador-aid</th>\n",
       "      <th>religious-groups-in-schools</th>\n",
       "      <th>anti-satellite-test-ban</th>\n",
       "      <th>aid-to-nicaraguan-contras</th>\n",
       "      <th>mx-missile</th>\n",
       "      <th>immigration</th>\n",
       "      <th>synfuels-crporation-cutback</th>\n",
       "      <th>education-spending</th>\n",
       "      <th>superfund-right-to-sue</th>\n",
       "      <th>crime</th>\n",
       "      <th>duty-free-exports</th>\n",
       "      <th>export-administration-act-south-africa</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>140</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>383</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>297</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>309</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID  handicapped-infants  water-project-cost-sharing  \\\n",
       "0  140                  1.0                         0.0   \n",
       "1  383                  1.0                         1.0   \n",
       "2  201                  0.0                         0.0   \n",
       "3  297                  0.0                         0.0   \n",
       "4  309                  0.0                         0.0   \n",
       "\n",
       "   adoption-of-the-budget-resolution  physician-fee-freeze  el-salvador-aid  \\\n",
       "0                                1.0                   0.0              0.0   \n",
       "1                                0.0                   1.0              1.0   \n",
       "2                                1.0                   0.0              0.0   \n",
       "3                                1.0                   1.0              1.0   \n",
       "4                                0.0                   1.0              1.0   \n",
       "\n",
       "   religious-groups-in-schools  anti-satellite-test-ban  \\\n",
       "0                          1.0                      1.0   \n",
       "1                          1.0                      0.0   \n",
       "2                          0.0                      1.0   \n",
       "3                          1.0                      0.0   \n",
       "4                          1.0                      0.0   \n",
       "\n",
       "   aid-to-nicaraguan-contras  mx-missile  immigration  \\\n",
       "0                        1.0         1.0          0.0   \n",
       "1                        0.0         0.0          0.0   \n",
       "2                        1.0         1.0          0.0   \n",
       "3                        0.0         0.0          1.0   \n",
       "4                        0.0         0.0          1.0   \n",
       "\n",
       "   synfuels-crporation-cutback  education-spending  superfund-right-to-sue  \\\n",
       "0                          0.0                 0.0                     0.0   \n",
       "1                          1.0                 0.0                     1.0   \n",
       "2                          0.0                 0.0                     0.0   \n",
       "3                          0.0                 1.0                     1.0   \n",
       "4                          0.0                 1.0                     1.0   \n",
       "\n",
       "   crime  duty-free-exports  export-administration-act-south-africa  class  \n",
       "0    0.0                1.0                                     1.0      1  \n",
       "1    1.0                0.0                                     1.0      1  \n",
       "2    1.0                1.0                                     1.0      1  \n",
       "3    1.0                1.0                                     1.0      0  \n",
       "4    1.0                0.0                                     0.0      0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cong_voting = pd.read_csv('./preprocessed-datasets/CongressionVoting_prepro.csv')\n",
    "# encode class value democrat as 1 and republican as 0\n",
    "cong_voting['class'] = cong_voting['class'].map({'democrat': 1, 'republican': 0})\n",
    "cong_voting.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_Y, test_X, test_Y = train_test_split(cong_voting, \"class\", return_torch=True)\n",
    "\n",
    "dataset = TensorDataset(train_X, train_Y)\n",
    "train_loader = DataLoader(dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "dataset = TensorDataset(test_X, test_Y)\n",
    "test_loader = DataLoader(dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Average Loss: 0.8204039831956228\n",
      "Epoch 2/100, Average Loss: 0.6987561782201132\n",
      "Epoch 3/100, Average Loss: 0.6630964974562327\n",
      "Epoch 4/100, Average Loss: 0.5736258924007416\n",
      "Epoch 5/100, Average Loss: 0.4424207905928294\n",
      "Epoch 6/100, Average Loss: 0.3960420439640681\n",
      "Epoch 7/100, Average Loss: 0.29747725029786426\n",
      "Epoch 8/100, Average Loss: 0.2279346063733101\n",
      "Epoch 9/100, Average Loss: 0.22333091124892235\n",
      "Epoch 10/100, Average Loss: 0.3738237793246905\n",
      "Epoch 11/100, Average Loss: 0.2867339824636777\n",
      "Epoch 12/100, Average Loss: 0.14389140841861567\n",
      "Epoch 13/100, Average Loss: 0.13733384509881338\n",
      "Epoch 14/100, Average Loss: 0.09313429457445939\n",
      "Epoch 15/100, Average Loss: 0.10354475133741896\n",
      "Epoch 16/100, Average Loss: 0.10233023607482512\n",
      "Epoch 17/100, Average Loss: 0.08094628248363733\n",
      "Epoch 18/100, Average Loss: 0.07607210986316204\n",
      "Epoch 19/100, Average Loss: 0.06412325814987223\n",
      "Epoch 20/100, Average Loss: 0.06259010794262092\n",
      "Epoch 21/100, Average Loss: 0.05415845879664024\n",
      "Epoch 22/100, Average Loss: 0.05226375007381042\n",
      "Epoch 23/100, Average Loss: 0.048682927309225\n",
      "Epoch 24/100, Average Loss: 0.04856952823077639\n",
      "Epoch 25/100, Average Loss: 0.04516133572906256\n",
      "Epoch 26/100, Average Loss: 0.04406998911872506\n",
      "Epoch 27/100, Average Loss: 0.047682768277203046\n",
      "Epoch 28/100, Average Loss: 0.043627354549244046\n",
      "Epoch 29/100, Average Loss: 0.04141892399638891\n",
      "Epoch 30/100, Average Loss: 0.04121789250833293\n",
      "Epoch 31/100, Average Loss: 0.041002314149712525\n",
      "Epoch 32/100, Average Loss: 0.03957498671176533\n",
      "Epoch 33/100, Average Loss: 0.04009338095784187\n",
      "Epoch 34/100, Average Loss: 0.039028852324311934\n",
      "Epoch 35/100, Average Loss: 0.03832243250993391\n",
      "Epoch 36/100, Average Loss: 0.038569036638364196\n",
      "Epoch 37/100, Average Loss: 0.03783654569027325\n",
      "Epoch 38/100, Average Loss: 0.03771390983213981\n",
      "Epoch 39/100, Average Loss: 0.03752029198221862\n",
      "Epoch 40/100, Average Loss: 0.03720923334670564\n",
      "Epoch 41/100, Average Loss: 0.03707582472513119\n",
      "Epoch 42/100, Average Loss: 0.03687523274372021\n",
      "Epoch 43/100, Average Loss: 0.03668343873384098\n",
      "Epoch 44/100, Average Loss: 0.036545716846982636\n",
      "Epoch 45/100, Average Loss: 0.03638943494297564\n",
      "Epoch 46/100, Average Loss: 0.03623119338105122\n",
      "Epoch 47/100, Average Loss: 0.03618847283845147\n",
      "Epoch 48/100, Average Loss: 0.035603237338364124\n",
      "Epoch 49/100, Average Loss: 0.03607066596547762\n",
      "Epoch 50/100, Average Loss: 0.03596969453307489\n",
      "Epoch 51/100, Average Loss: 0.03590496901112298\n",
      "Epoch 52/100, Average Loss: 0.036496331760038934\n",
      "Epoch 53/100, Average Loss: 0.07189203519374132\n",
      "Epoch 54/100, Average Loss: 0.13790124437461296\n",
      "Epoch 55/100, Average Loss: 0.12887695214400688\n",
      "Epoch 56/100, Average Loss: 0.20104860297093788\n",
      "Epoch 57/100, Average Loss: 0.39478421832124394\n",
      "Epoch 58/100, Average Loss: 0.23707206174731255\n",
      "Epoch 59/100, Average Loss: 0.1132991382231315\n",
      "Epoch 60/100, Average Loss: 0.07326825118313234\n",
      "Epoch 61/100, Average Loss: 0.05825759439418713\n",
      "Epoch 62/100, Average Loss: 0.06334770082806547\n",
      "Epoch 63/100, Average Loss: 0.061608878429979086\n",
      "Epoch 64/100, Average Loss: 0.0826031156660368\n",
      "Epoch 65/100, Average Loss: 0.05942057158487538\n",
      "Epoch 66/100, Average Loss: 0.05072445189580321\n",
      "Epoch 67/100, Average Loss: 0.07386771504146357\n",
      "Epoch 68/100, Average Loss: 0.13707957742735744\n",
      "Epoch 69/100, Average Loss: 0.3486961526796222\n",
      "Epoch 70/100, Average Loss: 0.12757476853827635\n",
      "Epoch 71/100, Average Loss: 0.09979963550964992\n",
      "Epoch 72/100, Average Loss: 0.06447954227526982\n",
      "Epoch 73/100, Average Loss: 0.06301545056824882\n",
      "Epoch 74/100, Average Loss: 0.0682704175511996\n",
      "Epoch 75/100, Average Loss: 0.20872952804590264\n",
      "Epoch 76/100, Average Loss: 0.0999700181807081\n",
      "Epoch 77/100, Average Loss: 0.07258104827875893\n",
      "Epoch 78/100, Average Loss: 0.05033177820344766\n",
      "Epoch 79/100, Average Loss: 0.06589046337952216\n",
      "Epoch 80/100, Average Loss: 0.07545723983397086\n",
      "Epoch 81/100, Average Loss: 0.06868512649089098\n",
      "Epoch 82/100, Average Loss: 0.06994250665108363\n",
      "Epoch 83/100, Average Loss: 0.15357094863429666\n",
      "Epoch 84/100, Average Loss: 0.08044719494258364\n",
      "Epoch 85/100, Average Loss: 0.13718119791398445\n",
      "Epoch 86/100, Average Loss: 0.0942526925355196\n",
      "Epoch 87/100, Average Loss: 0.07663403451442719\n",
      "Epoch 88/100, Average Loss: 0.05060915524760882\n",
      "Epoch 89/100, Average Loss: 0.049751124965647854\n",
      "Epoch 90/100, Average Loss: 0.05559230650154253\n",
      "Epoch 91/100, Average Loss: 0.060222275322303176\n",
      "Epoch 92/100, Average Loss: 0.07180619961582124\n",
      "Epoch 93/100, Average Loss: 0.04700460750609636\n",
      "Epoch 94/100, Average Loss: 0.04701133677735925\n",
      "Epoch 95/100, Average Loss: 0.049840178806334734\n",
      "Epoch 96/100, Average Loss: 0.0665747335491081\n",
      "Epoch 97/100, Average Loss: 0.05247290665283799\n",
      "Epoch 98/100, Average Loss: 0.05982209726547202\n",
      "Epoch 99/100, Average Loss: 0.05366467467198769\n",
      "Epoch 100/100, Average Loss: 0.06391760210196178\n",
      "Accuracy on training set: 0.9885057210922241\n",
      "Accuracy on test set: 0.930232584476471\n"
     ]
    }
   ],
   "source": [
    "input_size = train_X.shape[1]\n",
    "num_classes = 2\n",
    "learning_rate = 0.01\n",
    "batch_size = 64\n",
    "num_epochs = 100\n",
    "hidden_layer_sizes = [25,30]\n",
    "activation_function = F.tanh\n",
    "\n",
    "model = NN(input_size=train_X.shape[1], num_classes=num_classes, hidden_layer_sizes=hidden_layer_sizes, activation_function=activation_function)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "train_model(model, train_loader, optimizer, criterion, num_epochs)\n",
    "\n",
    "print(f\"Accuracy on training set: {check_accuracy(train_loader, model)}\")\n",
    "print(f\"Accuracy on test set: {check_accuracy(test_loader, model)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Average Loss: 0.8180125951766968\n",
      "Epoch 2/100, Average Loss: 0.8117269078890482\n",
      "Epoch 3/100, Average Loss: 0.6783948938051859\n",
      "Epoch 4/100, Average Loss: 0.6918448209762573\n",
      "Epoch 5/100, Average Loss: 0.5437196294466654\n",
      "Epoch 6/100, Average Loss: 0.48232629895210266\n",
      "Epoch 7/100, Average Loss: 0.3559349775314331\n",
      "Epoch 8/100, Average Loss: 0.30739949146906537\n",
      "Epoch 9/100, Average Loss: 0.2549964189529419\n",
      "Epoch 10/100, Average Loss: 0.2912028183539708\n",
      "Epoch 11/100, Average Loss: 0.19942163427670798\n",
      "Epoch 12/100, Average Loss: 0.18456491082906723\n",
      "Epoch 13/100, Average Loss: 0.17688415199518204\n",
      "Epoch 14/100, Average Loss: 0.1865780552228292\n",
      "Epoch 15/100, Average Loss: 0.13970640301704407\n",
      "Epoch 16/100, Average Loss: 0.18340398743748665\n",
      "Epoch 17/100, Average Loss: 0.20670132835706076\n",
      "Epoch 18/100, Average Loss: 0.3920699805021286\n",
      "Epoch 19/100, Average Loss: 0.19739287594954172\n",
      "Epoch 20/100, Average Loss: 0.13955268015464148\n",
      "Epoch 21/100, Average Loss: 0.17436438302199045\n",
      "Epoch 22/100, Average Loss: 0.1794865975777308\n",
      "Epoch 23/100, Average Loss: 0.11167573680480321\n",
      "Epoch 24/100, Average Loss: 0.11923527717590332\n",
      "Epoch 25/100, Average Loss: 0.1313863843679428\n",
      "Epoch 26/100, Average Loss: 0.10939414302508037\n",
      "Epoch 27/100, Average Loss: 0.13395869235197702\n",
      "Epoch 28/100, Average Loss: 0.10158742964267731\n",
      "Epoch 29/100, Average Loss: 0.13803898046414056\n",
      "Epoch 30/100, Average Loss: 0.12232851982116699\n",
      "Epoch 31/100, Average Loss: 0.17770891512433687\n",
      "Epoch 32/100, Average Loss: 0.11269942422707875\n",
      "Epoch 33/100, Average Loss: 0.09768918777505557\n",
      "Epoch 34/100, Average Loss: 0.11078593010703723\n",
      "Epoch 35/100, Average Loss: 0.13816695660352707\n",
      "Epoch 36/100, Average Loss: 0.08283300697803497\n",
      "Epoch 37/100, Average Loss: 0.0911725889891386\n",
      "Epoch 38/100, Average Loss: 0.07978582133849461\n",
      "Epoch 39/100, Average Loss: 0.07570727604130904\n",
      "Epoch 40/100, Average Loss: 0.06572586670517921\n",
      "Epoch 41/100, Average Loss: 0.10017011811335881\n",
      "Epoch 42/100, Average Loss: 0.09474271535873413\n",
      "Epoch 43/100, Average Loss: 0.09336730589469273\n",
      "Epoch 44/100, Average Loss: 0.13971746092041334\n",
      "Epoch 45/100, Average Loss: 0.1348916490872701\n",
      "Epoch 46/100, Average Loss: 0.1739571193854014\n",
      "Epoch 47/100, Average Loss: 0.08757378906011581\n",
      "Epoch 48/100, Average Loss: 0.12048297623793285\n",
      "Epoch 49/100, Average Loss: 0.13749093065659204\n",
      "Epoch 50/100, Average Loss: 0.122097909450531\n",
      "Epoch 51/100, Average Loss: 0.06686203616360824\n",
      "Epoch 52/100, Average Loss: 0.19987339029709497\n",
      "Epoch 53/100, Average Loss: 0.11915711810191472\n",
      "Epoch 54/100, Average Loss: 0.09796252846717834\n",
      "Epoch 55/100, Average Loss: 0.06227015207211176\n",
      "Epoch 56/100, Average Loss: 0.07353032877047856\n",
      "Epoch 57/100, Average Loss: 0.06420356035232544\n",
      "Epoch 58/100, Average Loss: 0.07137595986326535\n",
      "Epoch 59/100, Average Loss: 0.06995248235762119\n",
      "Epoch 60/100, Average Loss: 0.05096672847867012\n",
      "Epoch 61/100, Average Loss: 0.046104613691568375\n",
      "Epoch 62/100, Average Loss: 0.05007312633097172\n",
      "Epoch 63/100, Average Loss: 0.05852113664150238\n",
      "Epoch 64/100, Average Loss: 0.045132902140418686\n",
      "Epoch 65/100, Average Loss: 0.049179144824544586\n",
      "Epoch 66/100, Average Loss: 0.04268070310354233\n",
      "Epoch 67/100, Average Loss: 0.05385383063306411\n",
      "Epoch 68/100, Average Loss: 0.04116728498289982\n",
      "Epoch 69/100, Average Loss: 0.040601776291926704\n",
      "Epoch 70/100, Average Loss: 0.042513586580753326\n",
      "Epoch 71/100, Average Loss: 0.049632483161985874\n",
      "Epoch 72/100, Average Loss: 0.03954424398640791\n",
      "Epoch 73/100, Average Loss: 0.0398115674033761\n",
      "Epoch 74/100, Average Loss: 0.03854974048833052\n",
      "Epoch 75/100, Average Loss: 0.039964322466403246\n",
      "Epoch 76/100, Average Loss: 0.041535175715883575\n",
      "Epoch 77/100, Average Loss: 0.03892664176722368\n",
      "Epoch 78/100, Average Loss: 0.03851079475134611\n",
      "Epoch 79/100, Average Loss: 0.039912523391346134\n",
      "Epoch 80/100, Average Loss: 0.049226575531065464\n",
      "Epoch 81/100, Average Loss: 0.04021626245230436\n",
      "Epoch 82/100, Average Loss: 0.05058267246931791\n",
      "Epoch 83/100, Average Loss: 0.03651888451228539\n",
      "Epoch 84/100, Average Loss: 0.04876312209914128\n",
      "Epoch 85/100, Average Loss: 0.037667084485292435\n",
      "Epoch 86/100, Average Loss: 0.036343900176386036\n",
      "Epoch 87/100, Average Loss: 0.04101841322456797\n",
      "Epoch 88/100, Average Loss: 0.048084476652244725\n",
      "Epoch 89/100, Average Loss: 0.04858846450224519\n",
      "Epoch 90/100, Average Loss: 0.048209527507424355\n",
      "Epoch 91/100, Average Loss: 0.03810584731400013\n",
      "Epoch 92/100, Average Loss: 0.0371526392797629\n",
      "Epoch 93/100, Average Loss: 0.03574170606831709\n",
      "Epoch 94/100, Average Loss: 0.03587340873976549\n",
      "Epoch 95/100, Average Loss: 0.0350104079892238\n",
      "Epoch 96/100, Average Loss: 0.04656789544969797\n",
      "Epoch 97/100, Average Loss: 0.03512093843892217\n",
      "Epoch 98/100, Average Loss: 0.03571851489444574\n",
      "Epoch 99/100, Average Loss: 0.04658061467731992\n",
      "Epoch 100/100, Average Loss: 0.045473951691140733\n",
      "Epoch 1/100, Average Loss: 0.891971210638682\n",
      "Epoch 2/100, Average Loss: 0.7988613645235697\n",
      "Epoch 3/100, Average Loss: 0.6821898221969604\n",
      "Epoch 4/100, Average Loss: 0.7065555453300476\n",
      "Epoch 5/100, Average Loss: 0.6436381538709005\n",
      "Epoch 6/100, Average Loss: 0.6248612006505331\n",
      "Epoch 7/100, Average Loss: 0.48706645766894024\n",
      "Epoch 8/100, Average Loss: 0.4053073624769847\n",
      "Epoch 9/100, Average Loss: 0.32456405957539874\n",
      "Epoch 10/100, Average Loss: 0.3063947260379791\n",
      "Epoch 11/100, Average Loss: 0.2192922681570053\n",
      "Epoch 12/100, Average Loss: 0.178924098610878\n",
      "Epoch 13/100, Average Loss: 0.14750454823176065\n",
      "Epoch 14/100, Average Loss: 0.14655900249878565\n",
      "Epoch 15/100, Average Loss: 0.13433916370073953\n",
      "Epoch 16/100, Average Loss: 0.10880729680260022\n",
      "Epoch 17/100, Average Loss: 0.11814845353364944\n",
      "Epoch 18/100, Average Loss: 0.13592218421399593\n",
      "Epoch 19/100, Average Loss: 0.1562503520399332\n",
      "Epoch 20/100, Average Loss: 0.12259424105286598\n",
      "Epoch 21/100, Average Loss: 0.09967457999785741\n",
      "Epoch 22/100, Average Loss: 0.07732958905398846\n",
      "Epoch 23/100, Average Loss: 0.06295778850714366\n",
      "Epoch 24/100, Average Loss: 0.056940065075953804\n",
      "Epoch 25/100, Average Loss: 0.07244821513692538\n",
      "Epoch 26/100, Average Loss: 0.05096137151122093\n",
      "Epoch 27/100, Average Loss: 0.07344188292821248\n",
      "Epoch 28/100, Average Loss: 0.0516988088687261\n",
      "Epoch 29/100, Average Loss: 0.04388674224416415\n",
      "Epoch 30/100, Average Loss: 0.03891692434748014\n",
      "Epoch 31/100, Average Loss: 0.038435996820529304\n",
      "Epoch 32/100, Average Loss: 0.051244339595238365\n",
      "Epoch 33/100, Average Loss: 0.04810057394206524\n",
      "Epoch 34/100, Average Loss: 0.08804473529259364\n",
      "Epoch 35/100, Average Loss: 0.17687771966060004\n",
      "Epoch 36/100, Average Loss: 0.2158599595228831\n",
      "Epoch 37/100, Average Loss: 0.2935079385836919\n",
      "Epoch 38/100, Average Loss: 0.32462669163942337\n",
      "Epoch 39/100, Average Loss: 0.347661758462588\n",
      "Epoch 40/100, Average Loss: 0.13946386923392615\n",
      "Epoch 41/100, Average Loss: 0.16148510202765465\n",
      "Epoch 42/100, Average Loss: 0.08113464775184791\n",
      "Epoch 43/100, Average Loss: 0.05028803274035454\n",
      "Epoch 44/100, Average Loss: 0.12923065572977066\n",
      "Epoch 45/100, Average Loss: 0.06141666819651922\n",
      "Epoch 46/100, Average Loss: 0.09740762909253438\n",
      "Epoch 47/100, Average Loss: 0.060274407267570496\n",
      "Epoch 48/100, Average Loss: 0.09676947444677353\n",
      "Epoch 49/100, Average Loss: 0.0610979658861955\n",
      "Epoch 50/100, Average Loss: 0.07180789671838284\n",
      "Epoch 51/100, Average Loss: 0.050548107673724495\n",
      "Epoch 52/100, Average Loss: 0.04859607666730881\n",
      "Epoch 53/100, Average Loss: 0.04932505699495474\n",
      "Epoch 54/100, Average Loss: 0.052425362169742584\n",
      "Epoch 55/100, Average Loss: 0.04740535778303941\n",
      "Epoch 56/100, Average Loss: 0.05498741318782171\n",
      "Epoch 57/100, Average Loss: 0.03781962891419729\n",
      "Epoch 58/100, Average Loss: 0.03289717777321736\n",
      "Epoch 59/100, Average Loss: 0.03939436220874389\n",
      "Epoch 60/100, Average Loss: 0.022597300664832193\n",
      "Epoch 61/100, Average Loss: 0.025189034175127745\n",
      "Epoch 62/100, Average Loss: 0.0376126739817361\n",
      "Epoch 63/100, Average Loss: 0.02094830417384704\n",
      "Epoch 64/100, Average Loss: 0.016597409111758072\n",
      "Epoch 65/100, Average Loss: 0.017248547325531643\n",
      "Epoch 66/100, Average Loss: 0.02161109820008278\n",
      "Epoch 67/100, Average Loss: 0.018579623584325116\n",
      "Epoch 68/100, Average Loss: 0.009352327324450016\n",
      "Epoch 69/100, Average Loss: 0.013914460316300392\n",
      "Epoch 70/100, Average Loss: 0.01051828203101953\n",
      "Epoch 71/100, Average Loss: 0.009255210403352976\n",
      "Epoch 72/100, Average Loss: 0.007638594678913553\n",
      "Epoch 73/100, Average Loss: 0.008281270042061806\n",
      "Epoch 74/100, Average Loss: 0.007356355121980111\n",
      "Epoch 75/100, Average Loss: 0.00677676157404979\n",
      "Epoch 76/100, Average Loss: 0.006858525487283866\n",
      "Epoch 77/100, Average Loss: 0.005604227616762121\n",
      "Epoch 78/100, Average Loss: 0.006455142749473453\n",
      "Epoch 79/100, Average Loss: 0.01145363498168687\n",
      "Epoch 80/100, Average Loss: 0.00873774103820324\n",
      "Epoch 81/100, Average Loss: 0.013914349566524228\n",
      "Epoch 82/100, Average Loss: 0.018015161311874788\n",
      "Epoch 83/100, Average Loss: 0.01876108841194461\n",
      "Epoch 84/100, Average Loss: 0.029941936178753775\n",
      "Epoch 85/100, Average Loss: 0.008066720018784205\n",
      "Epoch 86/100, Average Loss: 0.008871964101369182\n",
      "Epoch 87/100, Average Loss: 0.026031810014198225\n",
      "Epoch 88/100, Average Loss: 0.012974205155236026\n",
      "Epoch 89/100, Average Loss: 0.004377882306774457\n",
      "Epoch 90/100, Average Loss: 0.00820369195813934\n",
      "Epoch 91/100, Average Loss: 0.01070739266773065\n",
      "Epoch 92/100, Average Loss: 0.0327169606462121\n",
      "Epoch 93/100, Average Loss: 0.03548609325662255\n",
      "Epoch 94/100, Average Loss: 0.08847021140779059\n",
      "Epoch 95/100, Average Loss: 0.05197304921845595\n",
      "Epoch 96/100, Average Loss: 0.014933967031538486\n",
      "Epoch 97/100, Average Loss: 0.023392629499236744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/100, Average Loss: 0.01198496591920654\n",
      "Epoch 99/100, Average Loss: 0.022237518802285194\n",
      "Epoch 100/100, Average Loss: 0.048407101382811867\n",
      "Epoch 1/100, Average Loss: 0.8420432408650717\n",
      "Epoch 2/100, Average Loss: 0.7978150049845377\n",
      "Epoch 3/100, Average Loss: 0.6780501206715902\n",
      "Epoch 4/100, Average Loss: 0.7014119227727255\n",
      "Epoch 5/100, Average Loss: 0.638034462928772\n",
      "Epoch 6/100, Average Loss: 0.521091361840566\n",
      "Epoch 7/100, Average Loss: 0.41388893127441406\n",
      "Epoch 8/100, Average Loss: 0.36143534382184345\n",
      "Epoch 9/100, Average Loss: 0.2692701866229375\n",
      "Epoch 10/100, Average Loss: 0.19202392796675363\n",
      "Epoch 11/100, Average Loss: 0.16828558842341104\n",
      "Epoch 12/100, Average Loss: 0.15494502087434134\n",
      "Epoch 13/100, Average Loss: 0.23360012471675873\n",
      "Epoch 14/100, Average Loss: 0.2103150337934494\n",
      "Epoch 15/100, Average Loss: 0.1641582747300466\n",
      "Epoch 16/100, Average Loss: 0.1669037640094757\n",
      "Epoch 17/100, Average Loss: 0.16539868215719858\n",
      "Epoch 18/100, Average Loss: 0.16679110998908678\n",
      "Epoch 19/100, Average Loss: 0.09987180804212888\n",
      "Epoch 20/100, Average Loss: 0.09086020663380623\n",
      "Epoch 21/100, Average Loss: 0.10868606964747111\n",
      "Epoch 22/100, Average Loss: 0.134037879606088\n",
      "Epoch 23/100, Average Loss: 0.17137149969736734\n",
      "Epoch 24/100, Average Loss: 0.14710933590928713\n",
      "Epoch 25/100, Average Loss: 0.12171311179796855\n",
      "Epoch 26/100, Average Loss: 0.11558832414448261\n",
      "Epoch 27/100, Average Loss: 0.08895339568456014\n",
      "Epoch 28/100, Average Loss: 0.09536746392647426\n",
      "Epoch 29/100, Average Loss: 0.09240485603610675\n",
      "Epoch 30/100, Average Loss: 0.07130768398443858\n",
      "Epoch 31/100, Average Loss: 0.07663155222932498\n",
      "Epoch 32/100, Average Loss: 0.05989310642083486\n",
      "Epoch 33/100, Average Loss: 0.04980210525294145\n",
      "Epoch 34/100, Average Loss: 0.045695808716118336\n",
      "Epoch 35/100, Average Loss: 0.05711530055850744\n",
      "Epoch 36/100, Average Loss: 0.062289917220671974\n",
      "Epoch 37/100, Average Loss: 0.04944607615470886\n",
      "Epoch 38/100, Average Loss: 0.049394831682244934\n",
      "Epoch 39/100, Average Loss: 0.050245293105642\n",
      "Epoch 40/100, Average Loss: 0.03692656631271044\n",
      "Epoch 41/100, Average Loss: 0.039013843362530075\n",
      "Epoch 42/100, Average Loss: 0.03292123104135195\n",
      "Epoch 43/100, Average Loss: 0.041990043595433235\n",
      "Epoch 44/100, Average Loss: 0.03513450982669989\n",
      "Epoch 45/100, Average Loss: 0.041961751567820706\n",
      "Epoch 46/100, Average Loss: 0.03338131308555603\n",
      "Epoch 47/100, Average Loss: 0.037089409617086254\n",
      "Epoch 48/100, Average Loss: 0.03800032970805963\n",
      "Epoch 49/100, Average Loss: 0.03718744218349457\n",
      "Epoch 50/100, Average Loss: 0.03010335409392913\n",
      "Epoch 51/100, Average Loss: 0.03191229452689489\n",
      "Epoch 52/100, Average Loss: 0.032983991938332714\n",
      "Epoch 53/100, Average Loss: 0.1347060271849235\n",
      "Epoch 54/100, Average Loss: 0.12960750112930933\n",
      "Epoch 55/100, Average Loss: 0.055611014987031616\n",
      "Epoch 56/100, Average Loss: 0.0834807933618625\n",
      "Epoch 57/100, Average Loss: 0.1829884648323059\n",
      "Epoch 58/100, Average Loss: 0.35079603890577954\n",
      "Epoch 59/100, Average Loss: 0.34161267677942914\n",
      "Epoch 60/100, Average Loss: 0.3230673298239708\n",
      "Epoch 61/100, Average Loss: 0.15482614686091742\n",
      "Epoch 62/100, Average Loss: 0.1415321926275889\n",
      "Epoch 63/100, Average Loss: 0.07475042156875134\n",
      "Epoch 64/100, Average Loss: 0.07495579930643241\n",
      "Epoch 65/100, Average Loss: 0.1282917826126019\n",
      "Epoch 66/100, Average Loss: 0.13078694293896356\n",
      "Epoch 67/100, Average Loss: 0.08413644507527351\n",
      "Epoch 68/100, Average Loss: 0.08156703412532806\n",
      "Epoch 69/100, Average Loss: 0.10381246854861577\n",
      "Epoch 70/100, Average Loss: 0.057595432425538697\n",
      "Epoch 71/100, Average Loss: 0.09010499964157741\n",
      "Epoch 72/100, Average Loss: 0.05428364003698031\n",
      "Epoch 73/100, Average Loss: 0.04858767675856749\n",
      "Epoch 74/100, Average Loss: 0.06502865875760715\n",
      "Epoch 75/100, Average Loss: 0.06587960912535588\n",
      "Epoch 76/100, Average Loss: 0.05701094741622607\n",
      "Epoch 77/100, Average Loss: 0.05031093955039978\n",
      "Epoch 78/100, Average Loss: 0.043117507050434746\n",
      "Epoch 79/100, Average Loss: 0.041859653467933335\n",
      "Epoch 80/100, Average Loss: 0.05318419076502323\n",
      "Epoch 81/100, Average Loss: 0.13646053584913412\n",
      "Epoch 82/100, Average Loss: 0.11115150277813275\n",
      "Epoch 83/100, Average Loss: 0.063471220433712\n",
      "Epoch 84/100, Average Loss: 0.05399153878291448\n",
      "Epoch 85/100, Average Loss: 0.02511207029844324\n",
      "Epoch 86/100, Average Loss: 0.08451206733783086\n",
      "Epoch 87/100, Average Loss: 0.12397544241199891\n",
      "Epoch 88/100, Average Loss: 0.054517886911829315\n",
      "Epoch 89/100, Average Loss: 0.08912427350878716\n",
      "Epoch 90/100, Average Loss: 0.08861793080965678\n",
      "Epoch 91/100, Average Loss: 0.04112633721282085\n",
      "Epoch 92/100, Average Loss: 0.071466197570165\n",
      "Epoch 93/100, Average Loss: 0.05974732960263888\n",
      "Epoch 94/100, Average Loss: 0.046532961229483284\n",
      "Epoch 95/100, Average Loss: 0.05752928306659063\n",
      "Epoch 96/100, Average Loss: 0.05014928306142489\n",
      "Epoch 97/100, Average Loss: 0.04443408828228712\n",
      "Epoch 98/100, Average Loss: 0.040189223984877266\n",
      "Epoch 99/100, Average Loss: 0.03745583693186442\n",
      "Epoch 100/100, Average Loss: 0.03892033267766237\n",
      "Epoch 1/100, Average Loss: 0.9025875727335612\n",
      "Epoch 2/100, Average Loss: 0.7734087705612183\n",
      "Epoch 3/100, Average Loss: 0.671548068523407\n",
      "Epoch 4/100, Average Loss: 0.692212720712026\n",
      "Epoch 5/100, Average Loss: 0.6465549468994141\n",
      "Epoch 6/100, Average Loss: 0.5654401183128357\n",
      "Epoch 7/100, Average Loss: 0.5134459733963013\n",
      "Epoch 8/100, Average Loss: 0.4416021704673767\n",
      "Epoch 9/100, Average Loss: 0.3941309650739034\n",
      "Epoch 10/100, Average Loss: 0.3103290895620982\n",
      "Epoch 11/100, Average Loss: 0.27092361946900684\n",
      "Epoch 12/100, Average Loss: 0.2516450484593709\n",
      "Epoch 13/100, Average Loss: 0.18886683384577432\n",
      "Epoch 14/100, Average Loss: 0.26193589220444363\n",
      "Epoch 15/100, Average Loss: 0.2183903008699417\n",
      "Epoch 16/100, Average Loss: 0.24659202992916107\n",
      "Epoch 17/100, Average Loss: 0.26401576896508533\n",
      "Epoch 18/100, Average Loss: 0.2476121485233307\n",
      "Epoch 19/100, Average Loss: 0.27112190922101337\n",
      "Epoch 20/100, Average Loss: 0.2521653200189273\n",
      "Epoch 21/100, Average Loss: 0.17559289435545603\n",
      "Epoch 22/100, Average Loss: 0.2340691238641739\n",
      "Epoch 23/100, Average Loss: 0.13948442290226618\n",
      "Epoch 24/100, Average Loss: 0.15918407340844473\n",
      "Epoch 25/100, Average Loss: 0.1390728751818339\n",
      "Epoch 26/100, Average Loss: 0.11633113026618958\n",
      "Epoch 27/100, Average Loss: 0.11173677320281665\n",
      "Epoch 28/100, Average Loss: 0.10380125294129054\n",
      "Epoch 29/100, Average Loss: 0.09692205240329106\n",
      "Epoch 30/100, Average Loss: 0.11772528042395909\n",
      "Epoch 31/100, Average Loss: 0.09820813685655594\n",
      "Epoch 32/100, Average Loss: 0.07532053130368392\n",
      "Epoch 33/100, Average Loss: 0.07493168115615845\n",
      "Epoch 34/100, Average Loss: 0.09038980677723885\n",
      "Epoch 35/100, Average Loss: 0.06464702201386292\n",
      "Epoch 36/100, Average Loss: 0.06151731374363104\n",
      "Epoch 37/100, Average Loss: 0.06747544184327126\n",
      "Epoch 38/100, Average Loss: 0.06948350742459297\n",
      "Epoch 39/100, Average Loss: 0.05690975052615007\n",
      "Epoch 40/100, Average Loss: 0.05701366625726223\n",
      "Epoch 41/100, Average Loss: 0.06669620238244534\n",
      "Epoch 42/100, Average Loss: 0.05002892389893532\n",
      "Epoch 43/100, Average Loss: 0.05075646564364433\n",
      "Epoch 44/100, Average Loss: 0.06319108543296655\n",
      "Epoch 45/100, Average Loss: 0.05302014605452617\n",
      "Epoch 46/100, Average Loss: 0.06983644453187783\n",
      "Epoch 47/100, Average Loss: 0.0829145647585392\n",
      "Epoch 48/100, Average Loss: 0.055766394982735314\n",
      "Epoch 49/100, Average Loss: 0.06408848178883393\n",
      "Epoch 50/100, Average Loss: 0.09029534893731277\n",
      "Epoch 51/100, Average Loss: 0.14826613136877617\n",
      "Epoch 52/100, Average Loss: 0.10320442294081052\n",
      "Epoch 53/100, Average Loss: 0.056274883449077606\n",
      "Epoch 54/100, Average Loss: 0.05458211184789737\n",
      "Epoch 55/100, Average Loss: 0.06764239942034085\n",
      "Epoch 56/100, Average Loss: 0.04252567794173956\n",
      "Epoch 57/100, Average Loss: 0.061354331051309906\n",
      "Epoch 58/100, Average Loss: 0.07496311143040657\n",
      "Epoch 59/100, Average Loss: 0.08280967424313228\n",
      "Epoch 60/100, Average Loss: 0.10299188488473494\n",
      "Epoch 61/100, Average Loss: 0.10731435567140579\n",
      "Epoch 62/100, Average Loss: 0.12358693778514862\n",
      "Epoch 63/100, Average Loss: 0.0890758049984773\n",
      "Epoch 64/100, Average Loss: 0.05364695626000563\n",
      "Epoch 65/100, Average Loss: 0.0564948475609223\n",
      "Epoch 66/100, Average Loss: 0.06291185629864533\n",
      "Epoch 67/100, Average Loss: 0.047965366703768574\n",
      "Epoch 68/100, Average Loss: 0.04142756418635448\n",
      "Epoch 69/100, Average Loss: 0.055005839094519615\n",
      "Epoch 70/100, Average Loss: 0.05825246808429559\n",
      "Epoch 71/100, Average Loss: 0.06353929359465837\n",
      "Epoch 72/100, Average Loss: 0.06449014414101839\n",
      "Epoch 73/100, Average Loss: 0.045379629358649254\n",
      "Epoch 74/100, Average Loss: 0.04387038480490446\n",
      "Epoch 75/100, Average Loss: 0.09332283027470112\n",
      "Epoch 76/100, Average Loss: 0.28425624190519255\n",
      "Epoch 77/100, Average Loss: 0.10104513416687648\n",
      "Epoch 78/100, Average Loss: 0.0754476748406887\n",
      "Epoch 79/100, Average Loss: 0.0965628195554018\n",
      "Epoch 80/100, Average Loss: 0.11518640133241813\n",
      "Epoch 81/100, Average Loss: 0.12395246451099713\n",
      "Epoch 82/100, Average Loss: 0.09190939615170161\n",
      "Epoch 83/100, Average Loss: 0.04352644396324953\n",
      "Epoch 84/100, Average Loss: 0.07283712426821391\n",
      "Epoch 85/100, Average Loss: 0.06975870579481125\n",
      "Epoch 86/100, Average Loss: 0.04728759452700615\n",
      "Epoch 87/100, Average Loss: 0.043194009301563106\n",
      "Epoch 88/100, Average Loss: 0.04568119874844948\n",
      "Epoch 89/100, Average Loss: 0.05462761068095764\n",
      "Epoch 90/100, Average Loss: 0.04014629342903694\n",
      "Epoch 91/100, Average Loss: 0.0391081552952528\n",
      "Epoch 92/100, Average Loss: 0.03768932167440653\n",
      "Epoch 93/100, Average Loss: 0.038537899032235146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/100, Average Loss: 0.03844649841388067\n",
      "Epoch 95/100, Average Loss: 0.041466968754927315\n",
      "Epoch 96/100, Average Loss: 0.03610756527632475\n",
      "Epoch 97/100, Average Loss: 0.049347108229994774\n",
      "Epoch 98/100, Average Loss: 0.04864650623251995\n",
      "Epoch 99/100, Average Loss: 0.03906491786862413\n",
      "Epoch 100/100, Average Loss: 0.04855617849777142\n",
      "Epoch 1/100, Average Loss: 0.8526902596155802\n",
      "Epoch 2/100, Average Loss: 0.8033377925554911\n",
      "Epoch 3/100, Average Loss: 0.6664307514826456\n",
      "Epoch 4/100, Average Loss: 0.6913187106450399\n",
      "Epoch 5/100, Average Loss: 0.6324726939201355\n",
      "Epoch 6/100, Average Loss: 0.6088979442914327\n",
      "Epoch 7/100, Average Loss: 0.5952257513999939\n",
      "Epoch 8/100, Average Loss: 0.46835898359616596\n",
      "Epoch 9/100, Average Loss: 0.38707205653190613\n",
      "Epoch 10/100, Average Loss: 0.32711730897426605\n",
      "Epoch 11/100, Average Loss: 0.2868749449650447\n",
      "Epoch 12/100, Average Loss: 0.23903718094031015\n",
      "Epoch 13/100, Average Loss: 0.18091660737991333\n",
      "Epoch 14/100, Average Loss: 0.18090970814228058\n",
      "Epoch 15/100, Average Loss: 0.1808781921863556\n",
      "Epoch 16/100, Average Loss: 0.22042038043340048\n",
      "Epoch 17/100, Average Loss: 0.15301602085431418\n",
      "Epoch 18/100, Average Loss: 0.1300822546084722\n",
      "Epoch 19/100, Average Loss: 0.14048448701699576\n",
      "Epoch 20/100, Average Loss: 0.1354762613773346\n",
      "Epoch 21/100, Average Loss: 0.13309727857510248\n",
      "Epoch 22/100, Average Loss: 0.11031665777166684\n",
      "Epoch 23/100, Average Loss: 0.11083638668060303\n",
      "Epoch 24/100, Average Loss: 0.13490135967731476\n",
      "Epoch 25/100, Average Loss: 0.11342041939496994\n",
      "Epoch 26/100, Average Loss: 0.12295850863059361\n",
      "Epoch 27/100, Average Loss: 0.1047914872566859\n",
      "Epoch 28/100, Average Loss: 0.12075358380873998\n",
      "Epoch 29/100, Average Loss: 0.10440570736924808\n",
      "Epoch 30/100, Average Loss: 0.0785503623386224\n",
      "Epoch 31/100, Average Loss: 0.1080347200234731\n",
      "Epoch 32/100, Average Loss: 0.20971170191963515\n",
      "Epoch 33/100, Average Loss: 0.2890277902285258\n",
      "Epoch 34/100, Average Loss: 0.29909853140513104\n",
      "Epoch 35/100, Average Loss: 0.3378298332293828\n",
      "Epoch 36/100, Average Loss: 0.24800427009661993\n",
      "Epoch 37/100, Average Loss: 0.2968660145998001\n",
      "Epoch 38/100, Average Loss: 0.21016263961791992\n",
      "Epoch 39/100, Average Loss: 0.158523578196764\n",
      "Epoch 40/100, Average Loss: 0.20639245212078094\n",
      "Epoch 41/100, Average Loss: 0.12315072740117709\n",
      "Epoch 42/100, Average Loss: 0.1595926135778427\n",
      "Epoch 43/100, Average Loss: 0.1095661794145902\n",
      "Epoch 44/100, Average Loss: 0.12732834865649542\n",
      "Epoch 45/100, Average Loss: 0.09536677598953247\n",
      "Epoch 46/100, Average Loss: 0.11239831894636154\n",
      "Epoch 47/100, Average Loss: 0.09065518528223038\n",
      "Epoch 48/100, Average Loss: 0.07651988665262859\n",
      "Epoch 49/100, Average Loss: 0.09173055986563365\n",
      "Epoch 50/100, Average Loss: 0.07294149572650592\n",
      "Epoch 51/100, Average Loss: 0.090309693167607\n",
      "Epoch 52/100, Average Loss: 0.08535964414477348\n",
      "Epoch 53/100, Average Loss: 0.10192490617434184\n",
      "Epoch 54/100, Average Loss: 0.11933070421218872\n",
      "Epoch 55/100, Average Loss: 0.08249732665717602\n",
      "Epoch 56/100, Average Loss: 0.08612561163802941\n",
      "Epoch 57/100, Average Loss: 0.07861185570557912\n",
      "Epoch 58/100, Average Loss: 0.07705701018373172\n",
      "Epoch 59/100, Average Loss: 0.07279849797487259\n",
      "Epoch 60/100, Average Loss: 0.06812142487615347\n",
      "Epoch 61/100, Average Loss: 0.06557603428761165\n",
      "Epoch 62/100, Average Loss: 0.06357783389588197\n",
      "Epoch 63/100, Average Loss: 0.06368941068649292\n",
      "Epoch 64/100, Average Loss: 0.05673892113069693\n",
      "Epoch 65/100, Average Loss: 0.053102693210045494\n",
      "Epoch 66/100, Average Loss: 0.06591094968219598\n",
      "Epoch 67/100, Average Loss: 0.058557321627934776\n",
      "Epoch 68/100, Average Loss: 0.06686853369077046\n",
      "Epoch 69/100, Average Loss: 0.06875408130387466\n",
      "Epoch 70/100, Average Loss: 0.07431424657503764\n",
      "Epoch 71/100, Average Loss: 0.08542201823244493\n",
      "Epoch 72/100, Average Loss: 0.06943571132918198\n",
      "Epoch 73/100, Average Loss: 0.05484114525218805\n",
      "Epoch 74/100, Average Loss: 0.07548777262369792\n",
      "Epoch 75/100, Average Loss: 0.06214137592663368\n",
      "Epoch 76/100, Average Loss: 0.05338109874476989\n",
      "Epoch 77/100, Average Loss: 0.059986481753488384\n",
      "Epoch 78/100, Average Loss: 0.05947506551941236\n",
      "Epoch 79/100, Average Loss: 0.04948541087408861\n",
      "Epoch 80/100, Average Loss: 0.049668947234749794\n",
      "Epoch 81/100, Average Loss: 0.049553546433647476\n",
      "Epoch 82/100, Average Loss: 0.06656879217674334\n",
      "Epoch 83/100, Average Loss: 0.051734755436579384\n",
      "Epoch 84/100, Average Loss: 0.06091093892852465\n",
      "Epoch 85/100, Average Loss: 0.0543394231547912\n",
      "Epoch 86/100, Average Loss: 0.054646833489338555\n",
      "Epoch 87/100, Average Loss: 0.054239505281051\n",
      "Epoch 88/100, Average Loss: 0.047766352693239846\n",
      "Epoch 89/100, Average Loss: 0.05318699528773626\n",
      "Epoch 90/100, Average Loss: 0.04424933561434349\n",
      "Epoch 91/100, Average Loss: 0.041983152429262795\n",
      "Epoch 92/100, Average Loss: 0.043819078244268894\n",
      "Epoch 93/100, Average Loss: 0.05168319152047237\n",
      "Epoch 94/100, Average Loss: 0.04796191118657589\n",
      "Epoch 95/100, Average Loss: 0.03887971226746837\n",
      "Epoch 96/100, Average Loss: 0.05886913649737835\n",
      "Epoch 97/100, Average Loss: 0.04206377733498812\n",
      "Epoch 98/100, Average Loss: 0.047723392490297556\n",
      "Epoch 99/100, Average Loss: 0.03495086325953404\n",
      "Epoch 100/100, Average Loss: 0.051237244779864945\n",
      "Average accuracy on training set: 0.9930901527404785\n",
      "Average accuracy on test set: 0.9770612716674805\n"
     ]
    }
   ],
   "source": [
    "X = cong_voting.drop('class', axis=1).values\n",
    "y = cong_voting['class'].values\n",
    "\n",
    "num_splits = 5\n",
    "\n",
    "kf = KFold(n_splits=num_splits, shuffle=True, random_state=42)\n",
    "\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    train_X_fold = torch.tensor(X_train, dtype=torch.float32)\n",
    "    train_Y_fold = torch.tensor(y_train, dtype=torch.long)\n",
    "    test_X_fold = torch.tensor(X_test, dtype=torch.float32)\n",
    "    test_Y_fold = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "    train_dataset_fold = TensorDataset(train_X_fold, train_Y_fold)\n",
    "    train_loader_fold = DataLoader(train_dataset_fold, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    test_dataset_fold = TensorDataset(test_X_fold, test_Y_fold)\n",
    "    test_loader_fold = DataLoader(test_dataset_fold, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    model_fold = NN(input_size=input_size, num_classes=num_classes,\n",
    "                    hidden_layer_sizes=hidden_layer_sizes, activation_function=activation_function)\n",
    "    criterion_fold = nn.CrossEntropyLoss()\n",
    "    optimizer_fold = optim.Adam(model_fold.parameters(), lr=learning_rate)\n",
    "\n",
    "    train_model(model_fold, train_loader_fold, optimizer_fold, criterion_fold, num_epochs)\n",
    "\n",
    "\n",
    "    train_accuracy_fold = check_accuracy(train_loader_fold, model_fold)\n",
    "    test_accuracy_fold = check_accuracy(test_loader_fold, model_fold)\n",
    "\n",
    "    train_accuracies.append(train_accuracy_fold)\n",
    "    test_accuracies.append(test_accuracy_fold)\n",
    "\n",
    "print(f\"Average accuracy on training set: {np.mean(train_accuracies)}\")\n",
    "print(f\"Average accuracy on test set: {np.mean(test_accuracies)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy on training set: 0.9666002258986113\n",
      "Average accuracy on test set: 0.9677589852008456\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.01\n",
    "batch_size = 64\n",
    "num_epochs = 100\n",
    "hidden_layer_sizes = (25, 30)\n",
    "activation_function = 'tanh'\n",
    "\n",
    "num_splits = 5\n",
    "\n",
    "kf = KFold(n_splits=num_splits, shuffle=True, random_state=42)\n",
    "\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # MLPClassifier\n",
    "    mlp_model = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes,\n",
    "                              activation=activation_function,\n",
    "                              learning_rate_init=learning_rate,\n",
    "                              batch_size=batch_size,\n",
    "                              max_iter=num_epochs)\n",
    "    \n",
    "    # Train MLPClassifier\n",
    "    mlp_model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    mlp_predictions_train = mlp_model.predict(X_train)\n",
    "    mlp_predictions_test = mlp_model.predict(X_test)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    train_accuracy_fold = accuracy_score(y_train, mlp_predictions_train)\n",
    "    test_accuracy_fold = accuracy_score(y_test, mlp_predictions_test)\n",
    "\n",
    "    train_accuracies.append(train_accuracy_fold)\n",
    "    test_accuracies.append(test_accuracy_fold)\n",
    "\n",
    "print(f\"Average accuracy on training set: {np.mean(train_accuracies)}\")\n",
    "print(f\"Average accuracy on test set: {np.mean(test_accuracies)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
