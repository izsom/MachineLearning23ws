{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F  \n",
    "from torch import optim \n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn.init as init\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class for the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self, input_size, num_classes, hidden_layer_sizes, activation_function, apply_softmax = False):\n",
    "        super(NN, self).__init__()\n",
    "\n",
    "        seed = 18\n",
    "        torch.manual_seed(seed)\n",
    "\n",
    "        self.activation = activation_function\n",
    "        self.apply_softmax = apply_softmax\n",
    "\n",
    "        # Input layer\n",
    "        self.input_layer = nn.Linear(input_size, hidden_layer_sizes[0])\n",
    "        init.kaiming_uniform_(self.input_layer.weight, mode='fan_in', nonlinearity=activation_function.__name__)\n",
    "\n",
    "\n",
    "        # Hidden layers\n",
    "        self.hidden_layers = nn.ModuleList([\n",
    "            nn.Linear(hidden_layer_sizes[i], hidden_layer_sizes[i + 1])\n",
    "            for i in range(len(hidden_layer_sizes) - 1)\n",
    "        ])\n",
    "\n",
    "        for layer in self.hidden_layers:\n",
    "            init.kaiming_uniform_(layer.weight, mode='fan_in', nonlinearity=activation_function.__name__)\n",
    "\n",
    "\n",
    "        # Output layer\n",
    "        self.output_layer = nn.Linear(hidden_layer_sizes[-1], num_classes)\n",
    "        init.kaiming_uniform_(self.output_layer.weight, mode='fan_in', nonlinearity=activation_function.__name__)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.float()\n",
    "        x = self.activation(self.input_layer(x))\n",
    "\n",
    "        # Process through hidden layers\n",
    "        for layer in self.hidden_layers:\n",
    "            x = self.activation(layer(x))\n",
    "\n",
    "        if self.apply_softmax:\n",
    "            x = F.softmax(self.output_layer(x), dim=1)\n",
    "        else:\n",
    "            x = self.output_layer(x)\n",
    "\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, optimizer, criterion, num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0.0  # Initialize total loss for the epoch\n",
    "        num_batches = len(train_loader)\n",
    "\n",
    "        for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "            data = data.reshape(data.shape[0], -1)\n",
    "\n",
    "            scores = model(data)\n",
    "            loss = criterion(scores, targets)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()  # Accumulate the batch loss\n",
    "\n",
    "        average_loss = total_loss / num_batches\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Average Loss: {average_loss}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to calculate the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(loader, model):\n",
    "\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "\n",
    "            x = x.reshape(x.shape[0], -1)\n",
    "\n",
    "            scores = model(x)\n",
    "            _, predictions = scores.max(1)\n",
    "\n",
    "            num_correct += (predictions == y).sum()\n",
    "            num_samples += predictions.size(0)\n",
    "\n",
    "    model.train()\n",
    "    return num_correct / num_samples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to split the data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(data: pd.DataFrame, target_label : str, test_size=0.2, return_torch=None):\n",
    "        \n",
    "    # split the data into train and test\n",
    "    train = data.sample(frac=(1-test_size),random_state=200)\n",
    "    test = data.drop(train.index)\n",
    "    \n",
    "    # split the train and test into X and Y\n",
    "    train_X = train.drop([target_label], axis=1).values\n",
    "    train_Y = train[target_label].values\n",
    "    test_X = test.drop([target_label], axis=1).values\n",
    "    test_Y = test[target_label].values\n",
    "    \n",
    "    if return_torch:\n",
    "        train_X = torch.tensor(train_X)\n",
    "        train_Y = torch.tensor(train_Y)\n",
    "        test_X = torch.tensor(test_X)\n",
    "        test_Y = torch.tensor(test_Y)\n",
    "    \n",
    "    return train_X, train_Y, test_X, test_Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(hidden_layer_sizes_list, activation_functions, learning_rates, batch_sizes, num_epochs_list, train_loader, test_loader):\n",
    "    best_accuracy = 0.0\n",
    "    best_combination = None\n",
    "    results = []\n",
    "\n",
    "    for hidden_layer_sizes in hidden_layer_sizes_list:\n",
    "        for activation_function in activation_functions:\n",
    "            for learning_rate in learning_rates:\n",
    "                for batch_size in batch_sizes:\n",
    "                    for num_epochs in num_epochs_list:\n",
    "                \n",
    "                        model = NN(input_size=train_loader.dataset.tensors[0].shape[1],\n",
    "                                   num_classes=num_classes,\n",
    "                                   hidden_layer_sizes=hidden_layer_sizes,\n",
    "                                   activation_function=activation_function)\n",
    "                        criterion = nn.CrossEntropyLoss()\n",
    "                        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "                        train_start_time = time.time()\n",
    "                        train_model(model, train_loader, optimizer, criterion, num_epochs)\n",
    "                        train_end_time = time.time()\n",
    "                        \n",
    "                        accuracy_train = check_accuracy(train_loader, model)\n",
    "                        accuracy_test = check_accuracy(test_loader, model)\n",
    "\n",
    "                        result = {\n",
    "                            'Hidden Layer Sizes': hidden_layer_sizes,\n",
    "                            'Activation Function': activation_function.__name__,\n",
    "                            'Learning Rate': learning_rate,\n",
    "                            'Batch Size': batch_size,\n",
    "                            'Number of Epochs': num_epochs,\n",
    "                            'Accuracy (Train)': accuracy_train.item(),\n",
    "                            'Accuracy (Test)': accuracy_test.item(),\n",
    "                            'Training Time': train_end_time - train_start_time\n",
    "                        }\n",
    "\n",
    "                        results.append(result)\n",
    "                        \n",
    "                        if accuracy_test > best_accuracy:\n",
    "                            best_accuracy = accuracy_test\n",
    "                            best_combination = result\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    return results_df, best_accuracy, best_combination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_search(num_iterations, initial_configuration, param_ranges, train_loader, test_loader):\n",
    "    best_accuracy = 0.0\n",
    "    best_combination = initial_configuration\n",
    "    train_times = []\n",
    "    results = []\n",
    "\n",
    "    for _ in range(num_iterations):\n",
    "        # Randomly sample hyperparameter values inthe specified ranges\n",
    "        sampled_configuration = {\n",
    "            'Hidden Layer Sizes': [random.randint(param_ranges['min_hidden'], param_ranges['max_hidden']) for _ in range(random.randint(param_ranges['min_layers'], param_ranges['max_layers']))],\n",
    "            'Activation Function': random.choice(param_ranges['activation_functions']),\n",
    "            'Learning Rate': random.uniform(param_ranges['min_lr'], param_ranges['max_lr']),\n",
    "            'Batch Size': random.choice(param_ranges['batch_sizes']),\n",
    "            'Number of Epochs': random.choice(param_ranges['num_epochs'])\n",
    "        }\n",
    "\n",
    "        train_start_time = time.time()\n",
    "        model = NN(input_size=train_loader.dataset.tensors[0].shape[1],\n",
    "                   num_classes=num_classes,\n",
    "                   hidden_layer_sizes=sampled_configuration['Hidden Layer Sizes'],\n",
    "                   activation_function=sampled_configuration['Activation Function'])\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=sampled_configuration['Learning Rate'])\n",
    "\n",
    "        train_model(model, train_loader, optimizer, criterion, sampled_configuration['Number of Epochs'])\n",
    "\n",
    "        train_end_time = time.time()\n",
    "        train_times.append(train_end_time - train_start_time)\n",
    "        accuracy_test = check_accuracy(test_loader, model)\n",
    "\n",
    "        result_entry = {\n",
    "            'Hidden Layer Sizes': sampled_configuration['Hidden Layer Sizes'],\n",
    "            'Activation Function': sampled_configuration['Activation Function'].__name__,\n",
    "            'Learning Rate': sampled_configuration['Learning Rate'],\n",
    "            'Batch Size': sampled_configuration['Batch Size'],\n",
    "            'Number of Epochs': sampled_configuration['Number of Epochs'],\n",
    "            'Accuracy': accuracy_test.item(),\n",
    "            'Training Time': train_end_time - train_start_time\n",
    "        }\n",
    "\n",
    "        results.append(result_entry)\n",
    "\n",
    "        if accuracy_test > best_accuracy:\n",
    "            best_accuracy = accuracy_test\n",
    "            best_combination = sampled_configuration\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    return best_combination, best_accuracy, results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for Local Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_search(num_iterations, initial_configuration, param_ranges, train_loader, test_loader):\n",
    "    best_accuracy = 0.0\n",
    "    best_combination = None\n",
    "    current_configuration = initial_configuration\n",
    "    train_times = []\n",
    "    results = []\n",
    "\n",
    "    for _ in range(num_iterations):\n",
    "        # small changes to the current configuration\n",
    "        new_configuration = {\n",
    "            'Hidden Layer Sizes': [\n",
    "                max(1, size + random.randint(-1, 1)) for size in current_configuration['Hidden Layer Sizes']\n",
    "            ],\n",
    "            'Activation Function': random.choice(param_ranges['activation_functions']),\n",
    "            'Learning Rate': max(param_ranges['min_lr'], min(param_ranges['max_lr'], current_configuration['Learning Rate'] + random.uniform(-0.01, 0.01))),\n",
    "            'Batch Size': random.choice(param_ranges['batch_sizes']),\n",
    "            'Number of Epochs': max(1, current_configuration['Number of Epochs'] + random.randint(-1, 1))\n",
    "        }\n",
    "\n",
    "        train_start_time = time.time()\n",
    "        model = NN(input_size=train_loader.dataset.tensors[0].shape[1],\n",
    "                   num_classes=num_classes,\n",
    "                   hidden_layer_sizes=new_configuration['Hidden Layer Sizes'],\n",
    "                   activation_function=new_configuration['Activation Function'])\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=new_configuration['Learning Rate'])\n",
    "\n",
    "        train_model(model, train_loader, optimizer, criterion, new_configuration['Number of Epochs'])\n",
    "\n",
    "        train_end_time = time.time()\n",
    "        train_times.append(train_end_time - train_start_time)\n",
    "        accuracy_test = check_accuracy(test_loader, model)\n",
    "\n",
    "        result_entry = {\n",
    "            'Hidden Layer Sizes': new_configuration['Hidden Layer Sizes'],\n",
    "            'Activation Function': new_configuration['Activation Function'].__name__,\n",
    "            'Learning Rate': new_configuration['Learning Rate'],\n",
    "            'Batch Size': new_configuration['Batch Size'],\n",
    "            'Number of Epochs': new_configuration['Number of Epochs'],\n",
    "            'Accuracy': accuracy_test.item(),\n",
    "            'Training Time': train_end_time - train_start_time\n",
    "        }\n",
    "\n",
    "        results.append(result_entry)\n",
    "\n",
    "        if accuracy_test > best_accuracy:\n",
    "            best_accuracy = accuracy_test\n",
    "            best_combination = new_configuration\n",
    "\n",
    "        # Update the current configuration for the next iteration\n",
    "        current_configuration = new_configuration\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    return best_combination, best_accuracy, results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the model on the wine quality dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>class</th>\n",
       "      <th>wine_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  class  wine_type  \n",
       "0      9.4      5          1  \n",
       "1      9.8      5          1  \n",
       "2      9.8      5          1  \n",
       "3      9.8      6          1  \n",
       "4      9.4      5          1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_quality = pd.read_csv('./preprocessed-datasets/wine_quality_prepro.csv', index_col=0)\n",
    "wine_quality.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting the dataset into training and testing sets, converting to PyTorch tensors and creating PyTorch DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_Y, test_X, test_Y = train_test_split(wine_quality, \"class\", return_torch=True)\n",
    "\n",
    "dataset = TensorDataset(train_X, train_Y)\n",
    "train_loader = DataLoader(dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "dataset = TensorDataset(test_X, test_Y)\n",
    "test_loader = DataLoader(dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the model, training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Average Loss: 1.3338039038371454\n",
      "Epoch 2/10, Average Loss: 1.2913920031003425\n",
      "Epoch 3/10, Average Loss: 1.2882495277498398\n",
      "Epoch 4/10, Average Loss: 1.287879331711611\n",
      "Epoch 5/10, Average Loss: 1.2764818719559652\n",
      "Epoch 6/10, Average Loss: 1.273354259736699\n",
      "Epoch 7/10, Average Loss: 1.2613155139735872\n",
      "Epoch 8/10, Average Loss: 1.259151681069216\n",
      "Epoch 9/10, Average Loss: 1.2574602010791287\n",
      "Epoch 10/10, Average Loss: 1.2471537063458213\n",
      "Accuracy on training set: 0.44132357835769653\n",
      "Accuracy on test set: 0.4470588266849518\n"
     ]
    }
   ],
   "source": [
    "input_size = train_X.shape[1] # number of features in wine quality dataset\n",
    "num_classes = 10 # 10 classes in wine quality dataset\n",
    "learning_rate = 0.01\n",
    "batch_size = 64\n",
    "num_epochs = 10\n",
    "hidden_layer_sizes = [25,30]\n",
    "activation_function = F.tanh\n",
    "\n",
    "model = NN(input_size=train_X.shape[1], num_classes=num_classes, hidden_layer_sizes=hidden_layer_sizes, activation_function=activation_function)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "train_model(model, train_loader, optimizer, criterion, num_epochs)\n",
    "\n",
    "print(f\"Accuracy on training set: {check_accuracy(train_loader, model)}\")\n",
    "print(f\"Accuracy on test set: {check_accuracy(test_loader, model)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing out Grid Search on the wine quality dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Average Loss: 1.3338039038371454\n",
      "Epoch 2/10, Average Loss: 1.2913920031003425\n",
      "Epoch 3/10, Average Loss: 1.2882495277498398\n",
      "Epoch 4/10, Average Loss: 1.287879331711611\n",
      "Epoch 5/10, Average Loss: 1.2764818719559652\n",
      "Epoch 6/10, Average Loss: 1.273354259736699\n",
      "Epoch 7/10, Average Loss: 1.2613155139735872\n",
      "Epoch 8/10, Average Loss: 1.259151681069216\n",
      "Epoch 9/10, Average Loss: 1.2574602010791287\n",
      "Epoch 10/10, Average Loss: 1.2471537063458213\n",
      "Epoch 1/15, Average Loss: 1.3338039038371454\n",
      "Epoch 2/15, Average Loss: 1.2913920031003425\n",
      "Epoch 3/15, Average Loss: 1.2882495277498398\n",
      "Epoch 4/15, Average Loss: 1.287879331711611\n",
      "Epoch 5/15, Average Loss: 1.2764818719559652\n",
      "Epoch 6/15, Average Loss: 1.273354259736699\n",
      "Epoch 7/15, Average Loss: 1.2613155139735872\n",
      "Epoch 8/15, Average Loss: 1.259151681069216\n",
      "Epoch 9/15, Average Loss: 1.2574602010791287\n",
      "Epoch 10/15, Average Loss: 1.2471537063458213\n",
      "Epoch 11/15, Average Loss: 1.2420796514288779\n",
      "Epoch 12/15, Average Loss: 1.2381280730107078\n",
      "Epoch 13/15, Average Loss: 1.2328106647620172\n",
      "Epoch 14/15, Average Loss: 1.2374375352830242\n",
      "Epoch 15/15, Average Loss: 1.2307769359986476\n",
      "Epoch 1/10, Average Loss: 1.3338039038371454\n",
      "Epoch 2/10, Average Loss: 1.2913920031003425\n",
      "Epoch 3/10, Average Loss: 1.2882495277498398\n",
      "Epoch 4/10, Average Loss: 1.287879331711611\n",
      "Epoch 5/10, Average Loss: 1.2764818719559652\n",
      "Epoch 6/10, Average Loss: 1.273354259736699\n",
      "Epoch 7/10, Average Loss: 1.2613155139735872\n",
      "Epoch 8/10, Average Loss: 1.259151681069216\n",
      "Epoch 9/10, Average Loss: 1.2574602010791287\n",
      "Epoch 10/10, Average Loss: 1.2471537063458213\n",
      "Epoch 1/15, Average Loss: 1.3338039038371454\n",
      "Epoch 2/15, Average Loss: 1.2913920031003425\n",
      "Epoch 3/15, Average Loss: 1.2882495277498398\n",
      "Epoch 4/15, Average Loss: 1.287879331711611\n",
      "Epoch 5/15, Average Loss: 1.2764818719559652\n",
      "Epoch 6/15, Average Loss: 1.273354259736699\n",
      "Epoch 7/15, Average Loss: 1.2613155139735872\n",
      "Epoch 8/15, Average Loss: 1.259151681069216\n",
      "Epoch 9/15, Average Loss: 1.2574602010791287\n",
      "Epoch 10/15, Average Loss: 1.2471537063458213\n",
      "Epoch 11/15, Average Loss: 1.2420796514288779\n",
      "Epoch 12/15, Average Loss: 1.2381280730107078\n",
      "Epoch 13/15, Average Loss: 1.2328106647620172\n",
      "Epoch 14/15, Average Loss: 1.2374375352830242\n",
      "Epoch 15/15, Average Loss: 1.2307769359986476\n",
      "Epoch 1/10, Average Loss: 1.5157994134294475\n",
      "Epoch 2/10, Average Loss: 1.289651695936004\n",
      "Epoch 3/10, Average Loss: 1.2775678963748955\n",
      "Epoch 4/10, Average Loss: 1.271873358568531\n",
      "Epoch 5/10, Average Loss: 1.2688023327318436\n",
      "Epoch 6/10, Average Loss: 1.2669888844519306\n",
      "Epoch 7/10, Average Loss: 1.2652103176877543\n",
      "Epoch 8/10, Average Loss: 1.2641891548238648\n",
      "Epoch 9/10, Average Loss: 1.262900858568999\n",
      "Epoch 10/10, Average Loss: 1.2618493456050661\n",
      "Epoch 1/15, Average Loss: 1.5157994134294475\n",
      "Epoch 2/15, Average Loss: 1.289651695936004\n",
      "Epoch 3/15, Average Loss: 1.2775678963748955\n",
      "Epoch 4/15, Average Loss: 1.271873358568531\n",
      "Epoch 5/15, Average Loss: 1.2688023327318436\n",
      "Epoch 6/15, Average Loss: 1.2669888844519306\n",
      "Epoch 7/15, Average Loss: 1.2652103176877543\n",
      "Epoch 8/15, Average Loss: 1.2641891548238648\n",
      "Epoch 9/15, Average Loss: 1.262900858568999\n",
      "Epoch 10/15, Average Loss: 1.2618493456050661\n",
      "Epoch 11/15, Average Loss: 1.2610034028445285\n",
      "Epoch 12/15, Average Loss: 1.2602082052113819\n",
      "Epoch 13/15, Average Loss: 1.2594348828485407\n",
      "Epoch 14/15, Average Loss: 1.258613472335909\n",
      "Epoch 15/15, Average Loss: 1.2577254099348572\n",
      "Epoch 1/10, Average Loss: 1.5157994134294475\n",
      "Epoch 2/10, Average Loss: 1.289651695936004\n",
      "Epoch 3/10, Average Loss: 1.2775678963748955\n",
      "Epoch 4/10, Average Loss: 1.271873358568531\n",
      "Epoch 5/10, Average Loss: 1.2688023327318436\n",
      "Epoch 6/10, Average Loss: 1.2669888844519306\n",
      "Epoch 7/10, Average Loss: 1.2652103176877543\n",
      "Epoch 8/10, Average Loss: 1.2641891548238648\n",
      "Epoch 9/10, Average Loss: 1.262900858568999\n",
      "Epoch 10/10, Average Loss: 1.2618493456050661\n",
      "Epoch 1/15, Average Loss: 1.5157994134294475\n",
      "Epoch 2/15, Average Loss: 1.289651695936004\n",
      "Epoch 3/15, Average Loss: 1.2775678963748955\n",
      "Epoch 4/15, Average Loss: 1.271873358568531\n",
      "Epoch 5/15, Average Loss: 1.2688023327318436\n",
      "Epoch 6/15, Average Loss: 1.2669888844519306\n",
      "Epoch 7/15, Average Loss: 1.2652103176877543\n",
      "Epoch 8/15, Average Loss: 1.2641891548238648\n",
      "Epoch 9/15, Average Loss: 1.262900858568999\n",
      "Epoch 10/15, Average Loss: 1.2618493456050661\n",
      "Epoch 11/15, Average Loss: 1.2610034028445285\n",
      "Epoch 12/15, Average Loss: 1.2602082052113819\n",
      "Epoch 13/15, Average Loss: 1.2594348828485407\n",
      "Epoch 14/15, Average Loss: 1.258613472335909\n",
      "Epoch 15/15, Average Loss: 1.2577254099348572\n",
      "Epoch 1/10, Average Loss: 3.2324448842212465\n",
      "Epoch 2/10, Average Loss: 1.3856300353272561\n",
      "Epoch 3/10, Average Loss: 1.3462281845098625\n",
      "Epoch 4/10, Average Loss: 1.257918922813392\n",
      "Epoch 5/10, Average Loss: 1.2235256934458494\n",
      "Epoch 6/10, Average Loss: 1.2044907881438367\n",
      "Epoch 7/10, Average Loss: 1.2062567889324727\n",
      "Epoch 8/10, Average Loss: 1.1796548176396844\n",
      "Epoch 9/10, Average Loss: 1.1690722276096694\n",
      "Epoch 10/10, Average Loss: 1.1569972122373757\n",
      "Epoch 1/15, Average Loss: 3.2324448842212465\n",
      "Epoch 2/15, Average Loss: 1.3856300353272561\n",
      "Epoch 3/15, Average Loss: 1.3462281845098625\n",
      "Epoch 4/15, Average Loss: 1.257918922813392\n",
      "Epoch 5/15, Average Loss: 1.2235256934458494\n",
      "Epoch 6/15, Average Loss: 1.2044907881438367\n",
      "Epoch 7/15, Average Loss: 1.2062567889324727\n",
      "Epoch 8/15, Average Loss: 1.1796548176396844\n",
      "Epoch 9/15, Average Loss: 1.1690722276096694\n",
      "Epoch 10/15, Average Loss: 1.1569972122373757\n",
      "Epoch 11/15, Average Loss: 1.1473126883155729\n",
      "Epoch 12/15, Average Loss: 1.1473307430378499\n",
      "Epoch 13/15, Average Loss: 1.13545050028643\n",
      "Epoch 14/15, Average Loss: 1.1412049959773667\n",
      "Epoch 15/15, Average Loss: 1.1266190789959913\n",
      "Epoch 1/10, Average Loss: 3.2324448842212465\n",
      "Epoch 2/10, Average Loss: 1.3856300353272561\n",
      "Epoch 3/10, Average Loss: 1.3462281845098625\n",
      "Epoch 4/10, Average Loss: 1.257918922813392\n",
      "Epoch 5/10, Average Loss: 1.2235256934458494\n",
      "Epoch 6/10, Average Loss: 1.2044907881438367\n",
      "Epoch 7/10, Average Loss: 1.2062567889324727\n",
      "Epoch 8/10, Average Loss: 1.1796548176396844\n",
      "Epoch 9/10, Average Loss: 1.1690722276096694\n",
      "Epoch 10/10, Average Loss: 1.1569972122373757\n",
      "Epoch 1/15, Average Loss: 3.2324448842212465\n",
      "Epoch 2/15, Average Loss: 1.3856300353272561\n",
      "Epoch 3/15, Average Loss: 1.3462281845098625\n",
      "Epoch 4/15, Average Loss: 1.257918922813392\n",
      "Epoch 5/15, Average Loss: 1.2235256934458494\n",
      "Epoch 6/15, Average Loss: 1.2044907881438367\n",
      "Epoch 7/15, Average Loss: 1.2062567889324727\n",
      "Epoch 8/15, Average Loss: 1.1796548176396844\n",
      "Epoch 9/15, Average Loss: 1.1690722276096694\n",
      "Epoch 10/15, Average Loss: 1.1569972122373757\n",
      "Epoch 11/15, Average Loss: 1.1473126883155729\n",
      "Epoch 12/15, Average Loss: 1.1473307430378499\n",
      "Epoch 13/15, Average Loss: 1.13545050028643\n",
      "Epoch 14/15, Average Loss: 1.1412049959773667\n",
      "Epoch 15/15, Average Loss: 1.1266190789959913\n",
      "Epoch 1/10, Average Loss: 9.377237459633248\n",
      "Epoch 2/10, Average Loss: 1.4767584391166828\n",
      "Epoch 3/10, Average Loss: 1.3564692805149803\n",
      "Epoch 4/10, Average Loss: 1.3102094132476059\n",
      "Epoch 5/10, Average Loss: 1.2892052538555825\n",
      "Epoch 6/10, Average Loss: 1.2768256934873896\n",
      "Epoch 7/10, Average Loss: 1.2672780251210451\n",
      "Epoch 8/10, Average Loss: 1.2594708646733337\n",
      "Epoch 9/10, Average Loss: 1.2536153712886975\n",
      "Epoch 10/10, Average Loss: 1.247289777899081\n",
      "Epoch 1/15, Average Loss: 9.377237459633248\n",
      "Epoch 2/15, Average Loss: 1.4767584391166828\n",
      "Epoch 3/15, Average Loss: 1.3564692805149803\n",
      "Epoch 4/15, Average Loss: 1.3102094132476059\n",
      "Epoch 5/15, Average Loss: 1.2892052538555825\n",
      "Epoch 6/15, Average Loss: 1.2768256934873896\n",
      "Epoch 7/15, Average Loss: 1.2672780251210451\n",
      "Epoch 8/15, Average Loss: 1.2594708646733337\n",
      "Epoch 9/15, Average Loss: 1.2536153712886975\n",
      "Epoch 10/15, Average Loss: 1.247289777899081\n",
      "Epoch 11/15, Average Loss: 1.2416112975108844\n",
      "Epoch 12/15, Average Loss: 1.2359264591720207\n",
      "Epoch 13/15, Average Loss: 1.2301301670952078\n",
      "Epoch 14/15, Average Loss: 1.224707898918105\n",
      "Epoch 15/15, Average Loss: 1.2197116788910942\n",
      "Epoch 1/10, Average Loss: 9.377237459633248\n",
      "Epoch 2/10, Average Loss: 1.4767584391166828\n",
      "Epoch 3/10, Average Loss: 1.3564692805149803\n",
      "Epoch 4/10, Average Loss: 1.3102094132476059\n",
      "Epoch 5/10, Average Loss: 1.2892052538555825\n",
      "Epoch 6/10, Average Loss: 1.2768256934873896\n",
      "Epoch 7/10, Average Loss: 1.2672780251210451\n",
      "Epoch 8/10, Average Loss: 1.2594708646733337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Average Loss: 1.2536153712886975\n",
      "Epoch 10/10, Average Loss: 1.247289777899081\n",
      "Epoch 1/15, Average Loss: 9.377237459633248\n",
      "Epoch 2/15, Average Loss: 1.4767584391166828\n",
      "Epoch 3/15, Average Loss: 1.3564692805149803\n",
      "Epoch 4/15, Average Loss: 1.3102094132476059\n",
      "Epoch 5/15, Average Loss: 1.2892052538555825\n",
      "Epoch 6/15, Average Loss: 1.2768256934873896\n",
      "Epoch 7/15, Average Loss: 1.2672780251210451\n",
      "Epoch 8/15, Average Loss: 1.2594708646733337\n",
      "Epoch 9/15, Average Loss: 1.2536153712886975\n",
      "Epoch 10/15, Average Loss: 1.247289777899081\n",
      "Epoch 11/15, Average Loss: 1.2416112975108844\n",
      "Epoch 12/15, Average Loss: 1.2359264591720207\n",
      "Epoch 13/15, Average Loss: 1.2301301670952078\n",
      "Epoch 14/15, Average Loss: 1.224707898918105\n",
      "Epoch 15/15, Average Loss: 1.2197116788910942\n",
      "Epoch 1/10, Average Loss: 1.3134170412285928\n",
      "Epoch 2/10, Average Loss: 1.2745691197781475\n",
      "Epoch 3/10, Average Loss: 1.2602842044245246\n",
      "Epoch 4/10, Average Loss: 1.255159665836147\n",
      "Epoch 5/10, Average Loss: 1.2602674778253755\n",
      "Epoch 6/10, Average Loss: 1.264168846826612\n",
      "Epoch 7/10, Average Loss: 1.2485608608444776\n",
      "Epoch 8/10, Average Loss: 1.2595036161457833\n",
      "Epoch 9/10, Average Loss: 1.2443360799660712\n",
      "Epoch 10/10, Average Loss: 1.237217853771397\n",
      "Epoch 1/15, Average Loss: 1.3134170412285928\n",
      "Epoch 2/15, Average Loss: 1.2745691197781475\n",
      "Epoch 3/15, Average Loss: 1.2602842044245246\n",
      "Epoch 4/15, Average Loss: 1.255159665836147\n",
      "Epoch 5/15, Average Loss: 1.2602674778253755\n",
      "Epoch 6/15, Average Loss: 1.264168846826612\n",
      "Epoch 7/15, Average Loss: 1.2485608608444776\n",
      "Epoch 8/15, Average Loss: 1.2595036161457833\n",
      "Epoch 9/15, Average Loss: 1.2443360799660712\n",
      "Epoch 10/15, Average Loss: 1.237217853771397\n",
      "Epoch 11/15, Average Loss: 1.2370942703053995\n",
      "Epoch 12/15, Average Loss: 1.2128963415608085\n",
      "Epoch 13/15, Average Loss: 1.2062858120064062\n",
      "Epoch 14/15, Average Loss: 1.210134333628087\n",
      "Epoch 15/15, Average Loss: 1.2093613930275104\n",
      "Epoch 1/10, Average Loss: 1.3134170412285928\n",
      "Epoch 2/10, Average Loss: 1.2745691197781475\n",
      "Epoch 3/10, Average Loss: 1.2602842044245246\n",
      "Epoch 4/10, Average Loss: 1.255159665836147\n",
      "Epoch 5/10, Average Loss: 1.2602674778253755\n",
      "Epoch 6/10, Average Loss: 1.264168846826612\n",
      "Epoch 7/10, Average Loss: 1.2485608608444776\n",
      "Epoch 8/10, Average Loss: 1.2595036161457833\n",
      "Epoch 9/10, Average Loss: 1.2443360799660712\n",
      "Epoch 10/10, Average Loss: 1.237217853771397\n",
      "Epoch 1/15, Average Loss: 1.3134170412285928\n",
      "Epoch 2/15, Average Loss: 1.2745691197781475\n",
      "Epoch 3/15, Average Loss: 1.2602842044245246\n",
      "Epoch 4/15, Average Loss: 1.255159665836147\n",
      "Epoch 5/15, Average Loss: 1.2602674778253755\n",
      "Epoch 6/15, Average Loss: 1.264168846826612\n",
      "Epoch 7/15, Average Loss: 1.2485608608444776\n",
      "Epoch 8/15, Average Loss: 1.2595036161457833\n",
      "Epoch 9/15, Average Loss: 1.2443360799660712\n",
      "Epoch 10/15, Average Loss: 1.237217853771397\n",
      "Epoch 11/15, Average Loss: 1.2370942703053995\n",
      "Epoch 12/15, Average Loss: 1.2128963415608085\n",
      "Epoch 13/15, Average Loss: 1.2062858120064062\n",
      "Epoch 14/15, Average Loss: 1.210134333628087\n",
      "Epoch 15/15, Average Loss: 1.2093613930275104\n",
      "Epoch 1/10, Average Loss: 1.4186995102583997\n",
      "Epoch 2/10, Average Loss: 1.2782277314940844\n",
      "Epoch 3/10, Average Loss: 1.262066488617037\n",
      "Epoch 4/10, Average Loss: 1.2518391415385381\n",
      "Epoch 5/10, Average Loss: 1.2465846081452867\n",
      "Epoch 6/10, Average Loss: 1.2425309704856637\n",
      "Epoch 7/10, Average Loss: 1.2388924912440997\n",
      "Epoch 8/10, Average Loss: 1.235733364623017\n",
      "Epoch 9/10, Average Loss: 1.232753729893386\n",
      "Epoch 10/10, Average Loss: 1.2301347976081942\n",
      "Epoch 1/15, Average Loss: 1.4186995102583997\n",
      "Epoch 2/15, Average Loss: 1.2782277314940844\n",
      "Epoch 3/15, Average Loss: 1.262066488617037\n",
      "Epoch 4/15, Average Loss: 1.2518391415385381\n",
      "Epoch 5/15, Average Loss: 1.2465846081452867\n",
      "Epoch 6/15, Average Loss: 1.2425309704856637\n",
      "Epoch 7/15, Average Loss: 1.2388924912440997\n",
      "Epoch 8/15, Average Loss: 1.235733364623017\n",
      "Epoch 9/15, Average Loss: 1.232753729893386\n",
      "Epoch 10/15, Average Loss: 1.2301347976081942\n",
      "Epoch 11/15, Average Loss: 1.227657817624098\n",
      "Epoch 12/15, Average Loss: 1.224919873146923\n",
      "Epoch 13/15, Average Loss: 1.2219961314844938\n",
      "Epoch 14/15, Average Loss: 1.2194648458182447\n",
      "Epoch 15/15, Average Loss: 1.217335763153123\n",
      "Epoch 1/10, Average Loss: 1.4186995102583997\n",
      "Epoch 2/10, Average Loss: 1.2782277314940844\n",
      "Epoch 3/10, Average Loss: 1.262066488617037\n",
      "Epoch 4/10, Average Loss: 1.2518391415385381\n",
      "Epoch 5/10, Average Loss: 1.2465846081452867\n",
      "Epoch 6/10, Average Loss: 1.2425309704856637\n",
      "Epoch 7/10, Average Loss: 1.2388924912440997\n",
      "Epoch 8/10, Average Loss: 1.235733364623017\n",
      "Epoch 9/10, Average Loss: 1.232753729893386\n",
      "Epoch 10/10, Average Loss: 1.2301347976081942\n",
      "Epoch 1/15, Average Loss: 1.4186995102583997\n",
      "Epoch 2/15, Average Loss: 1.2782277314940844\n",
      "Epoch 3/15, Average Loss: 1.262066488617037\n",
      "Epoch 4/15, Average Loss: 1.2518391415385381\n",
      "Epoch 5/15, Average Loss: 1.2465846081452867\n",
      "Epoch 6/15, Average Loss: 1.2425309704856637\n",
      "Epoch 7/15, Average Loss: 1.2388924912440997\n",
      "Epoch 8/15, Average Loss: 1.235733364623017\n",
      "Epoch 9/15, Average Loss: 1.232753729893386\n",
      "Epoch 10/15, Average Loss: 1.2301347976081942\n",
      "Epoch 11/15, Average Loss: 1.227657817624098\n",
      "Epoch 12/15, Average Loss: 1.224919873146923\n",
      "Epoch 13/15, Average Loss: 1.2219961314844938\n",
      "Epoch 14/15, Average Loss: 1.2194648458182447\n",
      "Epoch 15/15, Average Loss: 1.217335763153123\n",
      "Epoch 1/10, Average Loss: 2.9295862613280126\n",
      "Epoch 2/10, Average Loss: 1.4053171090553143\n",
      "Epoch 3/10, Average Loss: 1.3101701901002896\n",
      "Epoch 4/10, Average Loss: 1.2456525750686787\n",
      "Epoch 5/10, Average Loss: 1.2154414986540203\n",
      "Epoch 6/10, Average Loss: 1.1932655766697748\n",
      "Epoch 7/10, Average Loss: 1.1867467870741535\n",
      "Epoch 8/10, Average Loss: 1.1742928529078245\n",
      "Epoch 9/10, Average Loss: 1.1715527827754342\n",
      "Epoch 10/10, Average Loss: 1.1706595387926861\n",
      "Epoch 1/15, Average Loss: 2.9295862613280126\n",
      "Epoch 2/15, Average Loss: 1.4053171090553143\n",
      "Epoch 3/15, Average Loss: 1.3101701901002896\n",
      "Epoch 4/15, Average Loss: 1.2456525750686787\n",
      "Epoch 5/15, Average Loss: 1.2154414986540203\n",
      "Epoch 6/15, Average Loss: 1.1932655766697748\n",
      "Epoch 7/15, Average Loss: 1.1867467870741535\n",
      "Epoch 8/15, Average Loss: 1.1742928529078245\n",
      "Epoch 9/15, Average Loss: 1.1715527827754342\n",
      "Epoch 10/15, Average Loss: 1.1706595387926861\n",
      "Epoch 11/15, Average Loss: 1.158407743357442\n",
      "Epoch 12/15, Average Loss: 1.1470830674551746\n",
      "Epoch 13/15, Average Loss: 1.150862929279819\n",
      "Epoch 14/15, Average Loss: 1.1405766434464717\n",
      "Epoch 15/15, Average Loss: 1.1453438390252049\n",
      "Epoch 1/10, Average Loss: 2.9295862613280126\n",
      "Epoch 2/10, Average Loss: 1.4053171090553143\n",
      "Epoch 3/10, Average Loss: 1.3101701901002896\n",
      "Epoch 4/10, Average Loss: 1.2456525750686787\n",
      "Epoch 5/10, Average Loss: 1.2154414986540203\n",
      "Epoch 6/10, Average Loss: 1.1932655766697748\n",
      "Epoch 7/10, Average Loss: 1.1867467870741535\n",
      "Epoch 8/10, Average Loss: 1.1742928529078245\n",
      "Epoch 9/10, Average Loss: 1.1715527827754342\n",
      "Epoch 10/10, Average Loss: 1.1706595387926861\n",
      "Epoch 1/15, Average Loss: 2.9295862613280126\n",
      "Epoch 2/15, Average Loss: 1.4053171090553143\n",
      "Epoch 3/15, Average Loss: 1.3101701901002896\n",
      "Epoch 4/15, Average Loss: 1.2456525750686787\n",
      "Epoch 5/15, Average Loss: 1.2154414986540203\n",
      "Epoch 6/15, Average Loss: 1.1932655766697748\n",
      "Epoch 7/15, Average Loss: 1.1867467870741535\n",
      "Epoch 8/15, Average Loss: 1.1742928529078245\n",
      "Epoch 9/15, Average Loss: 1.1715527827754342\n",
      "Epoch 10/15, Average Loss: 1.1706595387926861\n",
      "Epoch 11/15, Average Loss: 1.158407743357442\n",
      "Epoch 12/15, Average Loss: 1.1470830674551746\n",
      "Epoch 13/15, Average Loss: 1.150862929279819\n",
      "Epoch 14/15, Average Loss: 1.1405766434464717\n",
      "Epoch 15/15, Average Loss: 1.1453438390252049\n",
      "Epoch 1/10, Average Loss: 8.816645726835802\n",
      "Epoch 2/10, Average Loss: 1.8097324327457172\n",
      "Epoch 3/10, Average Loss: 1.591396429056039\n",
      "Epoch 4/10, Average Loss: 1.5077126728245085\n",
      "Epoch 5/10, Average Loss: 1.4583211479011489\n",
      "Epoch 6/10, Average Loss: 1.4147324657147646\n",
      "Epoch 7/10, Average Loss: 1.3891667884551675\n",
      "Epoch 8/10, Average Loss: 1.3638630611764873\n",
      "Epoch 9/10, Average Loss: 1.345775969189369\n",
      "Epoch 10/10, Average Loss: 1.3330556205445272\n",
      "Epoch 1/15, Average Loss: 8.816645726835802\n",
      "Epoch 2/15, Average Loss: 1.8097324327457172\n",
      "Epoch 3/15, Average Loss: 1.591396429056039\n",
      "Epoch 4/15, Average Loss: 1.5077126728245085\n",
      "Epoch 5/15, Average Loss: 1.4583211479011489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/15, Average Loss: 1.4147324657147646\n",
      "Epoch 7/15, Average Loss: 1.3891667884551675\n",
      "Epoch 8/15, Average Loss: 1.3638630611764873\n",
      "Epoch 9/15, Average Loss: 1.345775969189369\n",
      "Epoch 10/15, Average Loss: 1.3330556205445272\n",
      "Epoch 11/15, Average Loss: 1.320689352377792\n",
      "Epoch 12/15, Average Loss: 1.3102229701960746\n",
      "Epoch 13/15, Average Loss: 1.302969576756647\n",
      "Epoch 14/15, Average Loss: 1.29046348998883\n",
      "Epoch 15/15, Average Loss: 1.2835565172821466\n",
      "Epoch 1/10, Average Loss: 8.816645726835802\n",
      "Epoch 2/10, Average Loss: 1.8097324327457172\n",
      "Epoch 3/10, Average Loss: 1.591396429056039\n",
      "Epoch 4/10, Average Loss: 1.5077126728245085\n",
      "Epoch 5/10, Average Loss: 1.4583211479011489\n",
      "Epoch 6/10, Average Loss: 1.4147324657147646\n",
      "Epoch 7/10, Average Loss: 1.3891667884551675\n",
      "Epoch 8/10, Average Loss: 1.3638630611764873\n",
      "Epoch 9/10, Average Loss: 1.345775969189369\n",
      "Epoch 10/10, Average Loss: 1.3330556205445272\n",
      "Epoch 1/15, Average Loss: 8.816645726835802\n",
      "Epoch 2/15, Average Loss: 1.8097324327457172\n",
      "Epoch 3/15, Average Loss: 1.591396429056039\n",
      "Epoch 4/15, Average Loss: 1.5077126728245085\n",
      "Epoch 5/15, Average Loss: 1.4583211479011489\n",
      "Epoch 6/15, Average Loss: 1.4147324657147646\n",
      "Epoch 7/15, Average Loss: 1.3891667884551675\n",
      "Epoch 8/15, Average Loss: 1.3638630611764873\n",
      "Epoch 9/15, Average Loss: 1.345775969189369\n",
      "Epoch 10/15, Average Loss: 1.3330556205445272\n",
      "Epoch 11/15, Average Loss: 1.320689352377792\n",
      "Epoch 12/15, Average Loss: 1.3102229701960746\n",
      "Epoch 13/15, Average Loss: 1.302969576756647\n",
      "Epoch 14/15, Average Loss: 1.29046348998883\n",
      "Epoch 15/15, Average Loss: 1.2835565172821466\n",
      "Best Accuracy: tensor(0.4850)\n",
      "Best Combination:\n",
      "{'Hidden Layer Sizes': [25, 30], 'Activation Function': 'relu', 'Learning Rate': 0.01, 'Batch Size': 32, 'Number of Epochs': 15, 'Accuracy (Train)': 0.4974990487098694, 'Accuracy (Test)': 0.48496732115745544, 'Training Time': 3.3124191761016846}\n"
     ]
    }
   ],
   "source": [
    "hidden_layer_sizes_list = [[25, 30], [20, 25, 30]]\n",
    "activation_functions = [F.tanh, F.relu]\n",
    "learning_rates = [0.01, 0.001]\n",
    "batch_sizes = [32, 64]\n",
    "num_epochs_list = [10, 15]\n",
    "\n",
    "grid_results_df_wine, best_accuracy_wine, best_combination_wine = grid_search(hidden_layer_sizes_list, activation_functions, learning_rates, batch_sizes, num_epochs_list, train_loader, test_loader)\n",
    "\n",
    "print(\"Best Accuracy:\", best_accuracy_wine)\n",
    "print(\"Best Combination:\")\n",
    "print(best_combination_wine)\n",
    "\n",
    "# Saving results\n",
    "#results_df_wine.to_csv('grid_search_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hidden Layer Sizes</th>\n",
       "      <th>Activation Function</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Batch Size</th>\n",
       "      <th>Number of Epochs</th>\n",
       "      <th>Accuracy (Train)</th>\n",
       "      <th>Accuracy (Test)</th>\n",
       "      <th>Training Time</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[25, 30]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.010</td>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>0.441324</td>\n",
       "      <td>0.447059</td>\n",
       "      <td>1.888755</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[25, 30]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.010</td>\n",
       "      <td>32</td>\n",
       "      <td>15</td>\n",
       "      <td>0.443247</td>\n",
       "      <td>0.462745</td>\n",
       "      <td>3.049353</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[25, 30]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.010</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.441324</td>\n",
       "      <td>0.447059</td>\n",
       "      <td>1.875426</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[25, 30]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.010</td>\n",
       "      <td>64</td>\n",
       "      <td>15</td>\n",
       "      <td>0.443247</td>\n",
       "      <td>0.462745</td>\n",
       "      <td>2.630327</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[25, 30]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.001</td>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>0.449211</td>\n",
       "      <td>0.453595</td>\n",
       "      <td>1.687192</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[25, 30]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.001</td>\n",
       "      <td>32</td>\n",
       "      <td>15</td>\n",
       "      <td>0.446518</td>\n",
       "      <td>0.454902</td>\n",
       "      <td>2.637031</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[25, 30]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.001</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.449211</td>\n",
       "      <td>0.453595</td>\n",
       "      <td>1.803701</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[25, 30]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.001</td>\n",
       "      <td>64</td>\n",
       "      <td>15</td>\n",
       "      <td>0.446518</td>\n",
       "      <td>0.454902</td>\n",
       "      <td>2.624947</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[25, 30]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.010</td>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>0.503848</td>\n",
       "      <td>0.475817</td>\n",
       "      <td>2.112982</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[25, 30]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.010</td>\n",
       "      <td>32</td>\n",
       "      <td>15</td>\n",
       "      <td>0.497499</td>\n",
       "      <td>0.484967</td>\n",
       "      <td>3.312419</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[25, 30]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.010</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.503848</td>\n",
       "      <td>0.475817</td>\n",
       "      <td>1.680569</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[25, 30]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.010</td>\n",
       "      <td>64</td>\n",
       "      <td>15</td>\n",
       "      <td>0.497499</td>\n",
       "      <td>0.484967</td>\n",
       "      <td>2.529624</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[25, 30]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.001</td>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>0.428434</td>\n",
       "      <td>0.381699</td>\n",
       "      <td>1.748789</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[25, 30]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.001</td>\n",
       "      <td>32</td>\n",
       "      <td>15</td>\n",
       "      <td>0.446133</td>\n",
       "      <td>0.393464</td>\n",
       "      <td>2.635470</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[25, 30]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.001</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.428434</td>\n",
       "      <td>0.381699</td>\n",
       "      <td>1.644939</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[25, 30]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.001</td>\n",
       "      <td>64</td>\n",
       "      <td>15</td>\n",
       "      <td>0.446133</td>\n",
       "      <td>0.393464</td>\n",
       "      <td>2.483027</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[20, 25, 30]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.010</td>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>0.483263</td>\n",
       "      <td>0.461438</td>\n",
       "      <td>1.908524</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[20, 25, 30]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.010</td>\n",
       "      <td>32</td>\n",
       "      <td>15</td>\n",
       "      <td>0.462293</td>\n",
       "      <td>0.460131</td>\n",
       "      <td>2.824097</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[20, 25, 30]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.010</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.483263</td>\n",
       "      <td>0.461438</td>\n",
       "      <td>1.966794</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[20, 25, 30]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.010</td>\n",
       "      <td>64</td>\n",
       "      <td>15</td>\n",
       "      <td>0.462293</td>\n",
       "      <td>0.460131</td>\n",
       "      <td>2.931036</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[20, 25, 30]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.001</td>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>0.448442</td>\n",
       "      <td>0.450980</td>\n",
       "      <td>1.879540</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[20, 25, 30]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.001</td>\n",
       "      <td>32</td>\n",
       "      <td>15</td>\n",
       "      <td>0.465564</td>\n",
       "      <td>0.460131</td>\n",
       "      <td>2.817793</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[20, 25, 30]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.001</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.448442</td>\n",
       "      <td>0.450980</td>\n",
       "      <td>1.896694</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[20, 25, 30]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.001</td>\n",
       "      <td>64</td>\n",
       "      <td>15</td>\n",
       "      <td>0.465564</td>\n",
       "      <td>0.460131</td>\n",
       "      <td>2.996566</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[20, 25, 30]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.010</td>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>0.504617</td>\n",
       "      <td>0.465359</td>\n",
       "      <td>1.979141</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[20, 25, 30]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.010</td>\n",
       "      <td>32</td>\n",
       "      <td>15</td>\n",
       "      <td>0.493459</td>\n",
       "      <td>0.475817</td>\n",
       "      <td>2.961394</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[20, 25, 30]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.010</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.504617</td>\n",
       "      <td>0.465359</td>\n",
       "      <td>1.908300</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[20, 25, 30]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.010</td>\n",
       "      <td>64</td>\n",
       "      <td>15</td>\n",
       "      <td>0.493459</td>\n",
       "      <td>0.475817</td>\n",
       "      <td>2.894360</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[20, 25, 30]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.001</td>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>0.402270</td>\n",
       "      <td>0.358170</td>\n",
       "      <td>1.979165</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[20, 25, 30]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.001</td>\n",
       "      <td>32</td>\n",
       "      <td>15</td>\n",
       "      <td>0.409196</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>3.046232</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[20, 25, 30]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.001</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.402270</td>\n",
       "      <td>0.358170</td>\n",
       "      <td>1.946262</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[20, 25, 30]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.001</td>\n",
       "      <td>64</td>\n",
       "      <td>15</td>\n",
       "      <td>0.409196</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>2.798858</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Hidden Layer Sizes Activation Function  Learning Rate  Batch Size  \\\n",
       "0            [25, 30]                tanh          0.010          32   \n",
       "1            [25, 30]                tanh          0.010          32   \n",
       "2            [25, 30]                tanh          0.010          64   \n",
       "3            [25, 30]                tanh          0.010          64   \n",
       "4            [25, 30]                tanh          0.001          32   \n",
       "5            [25, 30]                tanh          0.001          32   \n",
       "6            [25, 30]                tanh          0.001          64   \n",
       "7            [25, 30]                tanh          0.001          64   \n",
       "8            [25, 30]                relu          0.010          32   \n",
       "9            [25, 30]                relu          0.010          32   \n",
       "10           [25, 30]                relu          0.010          64   \n",
       "11           [25, 30]                relu          0.010          64   \n",
       "12           [25, 30]                relu          0.001          32   \n",
       "13           [25, 30]                relu          0.001          32   \n",
       "14           [25, 30]                relu          0.001          64   \n",
       "15           [25, 30]                relu          0.001          64   \n",
       "16       [20, 25, 30]                tanh          0.010          32   \n",
       "17       [20, 25, 30]                tanh          0.010          32   \n",
       "18       [20, 25, 30]                tanh          0.010          64   \n",
       "19       [20, 25, 30]                tanh          0.010          64   \n",
       "20       [20, 25, 30]                tanh          0.001          32   \n",
       "21       [20, 25, 30]                tanh          0.001          32   \n",
       "22       [20, 25, 30]                tanh          0.001          64   \n",
       "23       [20, 25, 30]                tanh          0.001          64   \n",
       "24       [20, 25, 30]                relu          0.010          32   \n",
       "25       [20, 25, 30]                relu          0.010          32   \n",
       "26       [20, 25, 30]                relu          0.010          64   \n",
       "27       [20, 25, 30]                relu          0.010          64   \n",
       "28       [20, 25, 30]                relu          0.001          32   \n",
       "29       [20, 25, 30]                relu          0.001          32   \n",
       "30       [20, 25, 30]                relu          0.001          64   \n",
       "31       [20, 25, 30]                relu          0.001          64   \n",
       "\n",
       "    Number of Epochs  Accuracy (Train)  Accuracy (Test)  Training Time  \\\n",
       "0                 10          0.441324         0.447059       1.888755   \n",
       "1                 15          0.443247         0.462745       3.049353   \n",
       "2                 10          0.441324         0.447059       1.875426   \n",
       "3                 15          0.443247         0.462745       2.630327   \n",
       "4                 10          0.449211         0.453595       1.687192   \n",
       "5                 15          0.446518         0.454902       2.637031   \n",
       "6                 10          0.449211         0.453595       1.803701   \n",
       "7                 15          0.446518         0.454902       2.624947   \n",
       "8                 10          0.503848         0.475817       2.112982   \n",
       "9                 15          0.497499         0.484967       3.312419   \n",
       "10                10          0.503848         0.475817       1.680569   \n",
       "11                15          0.497499         0.484967       2.529624   \n",
       "12                10          0.428434         0.381699       1.748789   \n",
       "13                15          0.446133         0.393464       2.635470   \n",
       "14                10          0.428434         0.381699       1.644939   \n",
       "15                15          0.446133         0.393464       2.483027   \n",
       "16                10          0.483263         0.461438       1.908524   \n",
       "17                15          0.462293         0.460131       2.824097   \n",
       "18                10          0.483263         0.461438       1.966794   \n",
       "19                15          0.462293         0.460131       2.931036   \n",
       "20                10          0.448442         0.450980       1.879540   \n",
       "21                15          0.465564         0.460131       2.817793   \n",
       "22                10          0.448442         0.450980       1.896694   \n",
       "23                15          0.465564         0.460131       2.996566   \n",
       "24                10          0.504617         0.465359       1.979141   \n",
       "25                15          0.493459         0.475817       2.961394   \n",
       "26                10          0.504617         0.465359       1.908300   \n",
       "27                15          0.493459         0.475817       2.894360   \n",
       "28                10          0.402270         0.358170       1.979165   \n",
       "29                15          0.409196         0.352941       3.046232   \n",
       "30                10          0.402270         0.358170       1.946262   \n",
       "31                15          0.409196         0.352941       2.798858   \n",
       "\n",
       "         dataset  \n",
       "0   wine_quality  \n",
       "1   wine_quality  \n",
       "2   wine_quality  \n",
       "3   wine_quality  \n",
       "4   wine_quality  \n",
       "5   wine_quality  \n",
       "6   wine_quality  \n",
       "7   wine_quality  \n",
       "8   wine_quality  \n",
       "9   wine_quality  \n",
       "10  wine_quality  \n",
       "11  wine_quality  \n",
       "12  wine_quality  \n",
       "13  wine_quality  \n",
       "14  wine_quality  \n",
       "15  wine_quality  \n",
       "16  wine_quality  \n",
       "17  wine_quality  \n",
       "18  wine_quality  \n",
       "19  wine_quality  \n",
       "20  wine_quality  \n",
       "21  wine_quality  \n",
       "22  wine_quality  \n",
       "23  wine_quality  \n",
       "24  wine_quality  \n",
       "25  wine_quality  \n",
       "26  wine_quality  \n",
       "27  wine_quality  \n",
       "28  wine_quality  \n",
       "29  wine_quality  \n",
       "30  wine_quality  \n",
       "31  wine_quality  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_results_df_wine['dataset'] = 'wine_quality'\n",
    "grid_results_df_wine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing out random search on the wine quality dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Average Loss: 1.4267507520921392\n",
      "Epoch 2/10, Average Loss: 1.3992398114292168\n",
      "Epoch 3/10, Average Loss: 1.3986807257119864\n",
      "Epoch 4/10, Average Loss: 1.3990603743886656\n",
      "Epoch 5/10, Average Loss: 1.3991614748363845\n",
      "Epoch 6/10, Average Loss: 1.399175955474011\n",
      "Epoch 7/10, Average Loss: 1.3990336693137702\n",
      "Epoch 8/10, Average Loss: 1.399297660845189\n",
      "Epoch 9/10, Average Loss: 1.399294968763012\n",
      "Epoch 10/10, Average Loss: 1.3992904256457932\n",
      "Epoch 1/15, Average Loss: 3.26213581284131\n",
      "Epoch 2/15, Average Loss: 1.5386129248361646\n",
      "Epoch 3/15, Average Loss: 1.3514377745382624\n",
      "Epoch 4/15, Average Loss: 1.2727943241961894\n",
      "Epoch 5/15, Average Loss: 1.2372236471234654\n",
      "Epoch 6/15, Average Loss: 1.212742452606833\n",
      "Epoch 7/15, Average Loss: 1.1895369631381123\n",
      "Epoch 8/15, Average Loss: 1.1814518841497736\n",
      "Epoch 9/15, Average Loss: 1.1680733971069195\n",
      "Epoch 10/15, Average Loss: 1.157967927631425\n",
      "Epoch 11/15, Average Loss: 1.1476052224270405\n",
      "Epoch 12/15, Average Loss: 1.15077039581135\n",
      "Epoch 13/15, Average Loss: 1.1476291458299555\n",
      "Epoch 14/15, Average Loss: 1.138544517426403\n",
      "Epoch 15/15, Average Loss: 1.1273586687866164\n",
      "Epoch 1/5, Average Loss: 2.086807231961584\n",
      "Epoch 2/5, Average Loss: 1.2838071328730671\n",
      "Epoch 3/5, Average Loss: 1.2829006932264457\n",
      "Epoch 4/5, Average Loss: 1.2826915694160697\n",
      "Epoch 5/5, Average Loss: 1.2826590706234329\n",
      "Epoch 1/10, Average Loss: 1.3213230342221407\n",
      "Epoch 2/10, Average Loss: 1.2781058857046022\n",
      "Epoch 3/10, Average Loss: 1.252121242643134\n",
      "Epoch 4/10, Average Loss: 1.2050428679384337\n",
      "Epoch 5/10, Average Loss: 1.1739777030389003\n",
      "Epoch 6/10, Average Loss: 1.1565925241248007\n",
      "Epoch 7/10, Average Loss: 1.1467103131709655\n",
      "Epoch 8/10, Average Loss: 1.1390951173437154\n",
      "Epoch 9/10, Average Loss: 1.1317269882541492\n",
      "Epoch 10/10, Average Loss: 1.1302935649280899\n",
      "Epoch 1/15, Average Loss: 1.5383536281761216\n",
      "Epoch 2/15, Average Loss: 1.464590247423371\n",
      "Epoch 3/15, Average Loss: 1.4655593772607347\n",
      "Epoch 4/15, Average Loss: 1.4662143496647935\n",
      "Epoch 5/15, Average Loss: 1.46657315573078\n",
      "Epoch 6/15, Average Loss: 1.467093130562203\n",
      "Epoch 7/15, Average Loss: 1.4672309672174277\n",
      "Epoch 8/15, Average Loss: 1.4673271186512673\n",
      "Epoch 9/15, Average Loss: 1.4676335326001688\n",
      "Epoch 10/15, Average Loss: 1.4678869210869256\n",
      "Epoch 11/15, Average Loss: 1.4674474015557692\n",
      "Epoch 12/15, Average Loss: 1.4674715279070145\n",
      "Epoch 13/15, Average Loss: 1.4675211218968491\n",
      "Epoch 14/15, Average Loss: 1.467503715877884\n",
      "Epoch 15/15, Average Loss: 1.4676011888527432\n",
      "Epoch 1/5, Average Loss: 1.4624416111437089\n",
      "Epoch 2/5, Average Loss: 1.4536091001487217\n",
      "Epoch 3/5, Average Loss: 1.4576980358252496\n",
      "Epoch 4/5, Average Loss: 1.4573679218994329\n",
      "Epoch 5/5, Average Loss: 1.4574254809713072\n",
      "Epoch 1/5, Average Loss: 1.3504324171440734\n",
      "Epoch 2/5, Average Loss: 1.327067510847665\n",
      "Epoch 3/5, Average Loss: 1.3275419678424765\n",
      "Epoch 4/5, Average Loss: 1.3269271682376511\n",
      "Epoch 5/5, Average Loss: 1.3271359592859\n",
      "Epoch 1/15, Average Loss: 4.371587612877594\n",
      "Epoch 2/15, Average Loss: 1.303219041941356\n",
      "Epoch 3/15, Average Loss: 1.2768234446004856\n",
      "Epoch 4/15, Average Loss: 1.2695259601791944\n",
      "Epoch 5/15, Average Loss: 1.2632214701248825\n",
      "Epoch 6/15, Average Loss: 1.2557795391492317\n",
      "Epoch 7/15, Average Loss: 1.2405595973225458\n",
      "Epoch 8/15, Average Loss: 1.2778532717125548\n",
      "Epoch 9/15, Average Loss: 1.2404330818931018\n",
      "Epoch 10/15, Average Loss: 1.2273743777918669\n",
      "Epoch 11/15, Average Loss: 1.246273053204355\n",
      "Epoch 12/15, Average Loss: 1.2653953974232353\n",
      "Epoch 13/15, Average Loss: 1.2572532566778498\n",
      "Epoch 14/15, Average Loss: 1.2597710801048514\n",
      "Epoch 15/15, Average Loss: 1.2638563948906272\n",
      "Epoch 1/10, Average Loss: 1.3103937268988486\n",
      "Epoch 2/10, Average Loss: 1.2629191699934883\n",
      "Epoch 3/10, Average Loss: 1.2581787562809108\n",
      "Epoch 4/10, Average Loss: 1.25262926473208\n",
      "Epoch 5/10, Average Loss: 1.2402463039737537\n",
      "Epoch 6/10, Average Loss: 1.213820008046788\n",
      "Epoch 7/10, Average Loss: 1.188633534074561\n",
      "Epoch 8/10, Average Loss: 1.1816186158934985\n",
      "Epoch 9/10, Average Loss: 1.1739616748745456\n",
      "Epoch 10/10, Average Loss: 1.1654717033626112\n",
      "Epoch 1/15, Average Loss: 1.3293997184630553\n",
      "Epoch 2/15, Average Loss: 1.2887960306705872\n",
      "Epoch 3/15, Average Loss: 1.2857548846788933\n",
      "Epoch 4/15, Average Loss: 1.2837079843860462\n",
      "Epoch 5/15, Average Loss: 1.2827482289331822\n",
      "Epoch 6/15, Average Loss: 1.2823496398750258\n",
      "Epoch 7/15, Average Loss: 1.2821750494600073\n",
      "Epoch 8/15, Average Loss: 1.282093646336187\n",
      "Epoch 9/15, Average Loss: 1.2818947094349773\n",
      "Epoch 10/15, Average Loss: 1.2819847877771577\n",
      "Epoch 11/15, Average Loss: 1.2819420413736917\n",
      "Epoch 12/15, Average Loss: 1.2819611989647333\n",
      "Epoch 13/15, Average Loss: 1.2818752154250819\n",
      "Epoch 14/15, Average Loss: 1.2818806932016384\n",
      "Epoch 15/15, Average Loss: 1.2818567080000427\n",
      "Best Configuration: {'Hidden Layer Sizes': [41, 20], 'Activation Function': <function sigmoid at 0x7fb490d4fe50>, 'Learning Rate': 0.010362545858758797, 'Batch Size': 64, 'Number of Epochs': 10}\n",
      "Best Accuracy: tensor(0.4863)\n"
     ]
    }
   ],
   "source": [
    "num_iterations = 10\n",
    "param_ranges = {\n",
    "    'min_hidden': 5,\n",
    "    'max_hidden': 50,\n",
    "    'min_layers': 1,\n",
    "    'max_layers': 3,\n",
    "    'activation_functions': [F.relu, F.tanh, F.sigmoid],\n",
    "    'min_lr': 0.001,\n",
    "    'max_lr': 0.1,\n",
    "    'batch_sizes': [32, 64, 128],\n",
    "    'num_epochs': [5, 10, 15]\n",
    "}\n",
    "\n",
    "initial_configuration = {\n",
    "    'Hidden Layer Sizes': [25],\n",
    "    'Activation Function': F.relu,\n",
    "    'Learning Rate': 0.01,\n",
    "    'Batch Size': 64,\n",
    "    'Number of Epochs': 10\n",
    "}\n",
    "\n",
    "best_config, best_accuracy, random_results_table_wine = random_search(num_iterations, initial_configuration, param_ranges, train_loader, test_loader)\n",
    "print(\"Best Configuration:\", best_config)\n",
    "print(\"Best Accuracy:\", best_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hidden Layer Sizes</th>\n",
       "      <th>Activation Function</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Batch Size</th>\n",
       "      <th>Number of Epochs</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Training Time</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[36, 34, 26]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.071628</td>\n",
       "      <td>128</td>\n",
       "      <td>10</td>\n",
       "      <td>0.284967</td>\n",
       "      <td>2.066317</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[46, 37]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.008342</td>\n",
       "      <td>32</td>\n",
       "      <td>15</td>\n",
       "      <td>0.481046</td>\n",
       "      <td>2.595385</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[16, 23, 40]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.063862</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>0.458824</td>\n",
       "      <td>0.945579</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[41, 20]</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.010363</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.486275</td>\n",
       "      <td>1.682182</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[41, 37, 41]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.073547</td>\n",
       "      <td>32</td>\n",
       "      <td>15</td>\n",
       "      <td>0.284967</td>\n",
       "      <td>2.961220</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[13, 30, 44]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.058814</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>0.284967</td>\n",
       "      <td>0.952416</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[48]</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.046612</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>0.458824</td>\n",
       "      <td>0.739777</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[20]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.049819</td>\n",
       "      <td>64</td>\n",
       "      <td>15</td>\n",
       "      <td>0.473203</td>\n",
       "      <td>2.199781</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[19, 49]</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.019329</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.448366</td>\n",
       "      <td>1.675180</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[7, 50]</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.074720</td>\n",
       "      <td>64</td>\n",
       "      <td>15</td>\n",
       "      <td>0.284967</td>\n",
       "      <td>2.509224</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Hidden Layer Sizes Activation Function  Learning Rate  Batch Size  \\\n",
       "0       [36, 34, 26]                tanh       0.071628         128   \n",
       "1           [46, 37]                relu       0.008342          32   \n",
       "2       [16, 23, 40]                relu       0.063862          64   \n",
       "3           [41, 20]             sigmoid       0.010363          64   \n",
       "4       [41, 37, 41]                tanh       0.073547          32   \n",
       "5       [13, 30, 44]                tanh       0.058814          64   \n",
       "6               [48]             sigmoid       0.046612          32   \n",
       "7               [20]                relu       0.049819          64   \n",
       "8           [19, 49]             sigmoid       0.019329          64   \n",
       "9            [7, 50]             sigmoid       0.074720          64   \n",
       "\n",
       "   Number of Epochs  Accuracy  Training Time       dataset  \n",
       "0                10  0.284967       2.066317  wine_quality  \n",
       "1                15  0.481046       2.595385  wine_quality  \n",
       "2                 5  0.458824       0.945579  wine_quality  \n",
       "3                10  0.486275       1.682182  wine_quality  \n",
       "4                15  0.284967       2.961220  wine_quality  \n",
       "5                 5  0.284967       0.952416  wine_quality  \n",
       "6                 5  0.458824       0.739777  wine_quality  \n",
       "7                15  0.473203       2.199781  wine_quality  \n",
       "8                10  0.448366       1.675180  wine_quality  \n",
       "9                15  0.284967       2.509224  wine_quality  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_results_table_wine['dataset'] = 'wine_quality'\n",
    "random_results_table_wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Testing out Local Search on wine quality dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/11, Average Loss: 1.3584940192158237\n",
      "Epoch 2/11, Average Loss: 1.2512979511103015\n",
      "Epoch 3/11, Average Loss: 1.2212291678036649\n",
      "Epoch 4/11, Average Loss: 1.2004704731373699\n",
      "Epoch 5/11, Average Loss: 1.1875284727365694\n",
      "Epoch 6/11, Average Loss: 1.170317331706088\n",
      "Epoch 7/11, Average Loss: 1.1579291279330575\n",
      "Epoch 8/11, Average Loss: 1.1476109616595542\n",
      "Epoch 9/11, Average Loss: 1.1442622260813333\n",
      "Epoch 10/11, Average Loss: 1.1359261252397408\n",
      "Epoch 11/11, Average Loss: 1.132720259069665\n",
      "Epoch 1/10, Average Loss: 1.3082550573934075\n",
      "Epoch 2/10, Average Loss: 1.2724334762140286\n",
      "Epoch 3/10, Average Loss: 1.2610128562143244\n",
      "Epoch 4/10, Average Loss: 1.2563806969695297\n",
      "Epoch 5/10, Average Loss: 1.251952894260547\n",
      "Epoch 6/10, Average Loss: 1.2427995914330512\n",
      "Epoch 7/10, Average Loss: 1.2269865910699762\n",
      "Epoch 8/10, Average Loss: 1.203735042569096\n",
      "Epoch 9/10, Average Loss: 1.1786008009149984\n",
      "Epoch 10/10, Average Loss: 1.1722392670216004\n",
      "Epoch 1/11, Average Loss: 1.3410476277942307\n",
      "Epoch 2/11, Average Loss: 1.2987014494059277\n",
      "Epoch 3/11, Average Loss: 1.2967529567472773\n",
      "Epoch 4/11, Average Loss: 1.2984227402809938\n",
      "Epoch 5/11, Average Loss: 1.2951118770552559\n",
      "Epoch 6/11, Average Loss: 1.2958819017819831\n",
      "Epoch 7/11, Average Loss: 1.294192757343222\n",
      "Epoch 8/11, Average Loss: 1.2954787856962051\n",
      "Epoch 9/11, Average Loss: 1.2946214975754908\n",
      "Epoch 10/11, Average Loss: 1.2939339232591032\n",
      "Epoch 11/11, Average Loss: 1.29497779658967\n",
      "Epoch 1/12, Average Loss: 1.303967377159493\n",
      "Epoch 2/12, Average Loss: 1.2838697133620092\n",
      "Epoch 3/12, Average Loss: 1.2821134445857416\n",
      "Epoch 4/12, Average Loss: 1.277573895600676\n",
      "Epoch 5/12, Average Loss: 1.2752109488095242\n",
      "Epoch 6/12, Average Loss: 1.270286689506718\n",
      "Epoch 7/12, Average Loss: 1.265069247754805\n",
      "Epoch 8/12, Average Loss: 1.2575635939287992\n",
      "Epoch 9/12, Average Loss: 1.2514250834295355\n",
      "Epoch 10/12, Average Loss: 1.23472772785491\n",
      "Epoch 11/12, Average Loss: 1.2249165959884785\n",
      "Epoch 12/12, Average Loss: 1.2013915214070514\n",
      "Epoch 1/11, Average Loss: 1.34641473205543\n",
      "Epoch 2/11, Average Loss: 1.3183996333666375\n",
      "Epoch 3/11, Average Loss: 1.3175868673558615\n",
      "Epoch 4/11, Average Loss: 1.3185524545564242\n",
      "Epoch 5/11, Average Loss: 1.3174270142806819\n",
      "Epoch 6/11, Average Loss: 1.3178293222298652\n",
      "Epoch 7/11, Average Loss: 1.3174477801001145\n",
      "Epoch 8/11, Average Loss: 1.318156868402212\n",
      "Epoch 9/11, Average Loss: 1.3184551417461934\n",
      "Epoch 10/11, Average Loss: 1.3185247438816936\n",
      "Epoch 11/11, Average Loss: 1.3185245069258051\n",
      "Epoch 1/10, Average Loss: 1.3072843946562223\n",
      "Epoch 2/10, Average Loss: 1.2744943481281492\n",
      "Epoch 3/10, Average Loss: 1.2775295753420497\n",
      "Epoch 4/10, Average Loss: 1.2636681531835918\n",
      "Epoch 5/10, Average Loss: 1.2593257514977017\n",
      "Epoch 6/10, Average Loss: 1.232904675548062\n",
      "Epoch 7/10, Average Loss: 1.2132240098678262\n",
      "Epoch 8/10, Average Loss: 1.2262628681820595\n",
      "Epoch 9/10, Average Loss: 1.1884880391366643\n",
      "Epoch 10/10, Average Loss: 1.1924411497233105\n",
      "Epoch 1/9, Average Loss: 1.3276598292625754\n",
      "Epoch 2/9, Average Loss: 1.2875068780103345\n",
      "Epoch 3/9, Average Loss: 1.2886166104509786\n",
      "Epoch 4/9, Average Loss: 1.2893391057757513\n",
      "Epoch 5/9, Average Loss: 1.2890156412417173\n",
      "Epoch 6/9, Average Loss: 1.290019187459185\n",
      "Epoch 7/9, Average Loss: 1.2912335059394133\n",
      "Epoch 8/9, Average Loss: 1.2779806771892712\n",
      "Epoch 9/9, Average Loss: 1.2586684482960613\n",
      "Epoch 1/10, Average Loss: 1.3483251523386481\n",
      "Epoch 2/10, Average Loss: 1.3238975658007195\n",
      "Epoch 3/10, Average Loss: 1.321095798278879\n",
      "Epoch 4/10, Average Loss: 1.3166436871136624\n",
      "Epoch 5/10, Average Loss: 1.3201187483372132\n",
      "Epoch 6/10, Average Loss: 1.320212578846633\n",
      "Epoch 7/10, Average Loss: 1.3174240296603712\n",
      "Epoch 8/10, Average Loss: 1.3204870311760464\n",
      "Epoch 9/10, Average Loss: 1.3158148856250786\n",
      "Epoch 10/10, Average Loss: 1.3159207961310637\n",
      "Epoch 1/10, Average Loss: 4.232845410978867\n",
      "Epoch 2/10, Average Loss: 1.3331897006444404\n",
      "Epoch 3/10, Average Loss: 1.2625689239589715\n",
      "Epoch 4/10, Average Loss: 1.2058709954922915\n",
      "Epoch 5/10, Average Loss: 1.1801035470026402\n",
      "Epoch 6/10, Average Loss: 1.162590304766696\n",
      "Epoch 7/10, Average Loss: 1.1529657350727385\n",
      "Epoch 8/10, Average Loss: 1.1508025446552441\n",
      "Epoch 9/10, Average Loss: 1.147806584103707\n",
      "Epoch 10/10, Average Loss: 1.1413490593067708\n",
      "Epoch 1/10, Average Loss: 1.319838112848668\n",
      "Epoch 2/10, Average Loss: 1.2717455486578444\n",
      "Epoch 3/10, Average Loss: 1.259410465787525\n",
      "Epoch 4/10, Average Loss: 1.2457791643640015\n",
      "Epoch 5/10, Average Loss: 1.211502842010896\n",
      "Epoch 6/10, Average Loss: 1.194743599994051\n",
      "Epoch 7/10, Average Loss: 1.2013570593178637\n",
      "Epoch 8/10, Average Loss: 1.1886443323884273\n",
      "Epoch 9/10, Average Loss: 1.1854815124734048\n",
      "Epoch 10/10, Average Loss: 1.1805416521119194\n",
      "Best Configuration: {'Hidden Layer Sizes': [26], 'Activation Function': <function sigmoid at 0x7fb490d4fe50>, 'Learning Rate': 0.00832371010483279, 'Batch Size': 32, 'Number of Epochs': 11}\n",
      "Best Accuracy: tensor(0.4941)\n"
     ]
    }
   ],
   "source": [
    "num_iterations = 10\n",
    "param_ranges = {\n",
    "    'min_hidden': 5,\n",
    "    'max_hidden': 50,\n",
    "    'min_layers': 1,\n",
    "    'max_layers': 3,\n",
    "    'activation_functions': [F.relu, F.tanh, F.sigmoid],\n",
    "    'min_lr': 0.001,\n",
    "    'max_lr': 0.1,\n",
    "    'batch_sizes': [32, 64, 128],\n",
    "    'num_epochs': [5, 10, 15]\n",
    "}\n",
    "\n",
    "initial_configuration = {\n",
    "    'Hidden Layer Sizes': [25],\n",
    "    'Activation Function': F.relu,\n",
    "    'Learning Rate': 0.01,\n",
    "    'Batch Size': 64,\n",
    "    'Number of Epochs': 10\n",
    "}\n",
    "\n",
    "best_config, best_accuracy, local_results_table_wine = local_search(num_iterations, initial_configuration, param_ranges, train_loader, test_loader)\n",
    "print(\"Best Configuration:\", best_config)\n",
    "print(\"Best Accuracy:\", best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hidden Layer Sizes</th>\n",
       "      <th>Activation Function</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Batch Size</th>\n",
       "      <th>Number of Epochs</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Training Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[26]</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.008324</td>\n",
       "      <td>32</td>\n",
       "      <td>11</td>\n",
       "      <td>0.494118</td>\n",
       "      <td>2.548559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[25]</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.012688</td>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>0.462745</td>\n",
       "      <td>4.352979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[25]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.015207</td>\n",
       "      <td>32</td>\n",
       "      <td>11</td>\n",
       "      <td>0.454902</td>\n",
       "      <td>2.614930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[25]</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.020691</td>\n",
       "      <td>64</td>\n",
       "      <td>12</td>\n",
       "      <td>0.467974</td>\n",
       "      <td>1.869798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[26]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.023087</td>\n",
       "      <td>128</td>\n",
       "      <td>11</td>\n",
       "      <td>0.284967</td>\n",
       "      <td>4.247971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[26]</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.024981</td>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>0.471895</td>\n",
       "      <td>1.592727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[26]</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.017405</td>\n",
       "      <td>64</td>\n",
       "      <td>9</td>\n",
       "      <td>0.456209</td>\n",
       "      <td>1.362743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[27]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.024421</td>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>0.286275</td>\n",
       "      <td>2.294606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[26]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.030700</td>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>0.484967</td>\n",
       "      <td>1.626590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[26]</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.023405</td>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>0.475817</td>\n",
       "      <td>1.640130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Hidden Layer Sizes Activation Function  Learning Rate  Batch Size  \\\n",
       "0               [26]             sigmoid       0.008324          32   \n",
       "1               [25]             sigmoid       0.012688          32   \n",
       "2               [25]                tanh       0.015207          32   \n",
       "3               [25]             sigmoid       0.020691          64   \n",
       "4               [26]                tanh       0.023087         128   \n",
       "5               [26]             sigmoid       0.024981          32   \n",
       "6               [26]             sigmoid       0.017405          64   \n",
       "7               [27]                tanh       0.024421          32   \n",
       "8               [26]                relu       0.030700          32   \n",
       "9               [26]             sigmoid       0.023405          32   \n",
       "\n",
       "   Number of Epochs  Accuracy  Training Time  \n",
       "0                11  0.494118       2.548559  \n",
       "1                10  0.462745       4.352979  \n",
       "2                11  0.454902       2.614930  \n",
       "3                12  0.467974       1.869798  \n",
       "4                11  0.284967       4.247971  \n",
       "5                10  0.471895       1.592727  \n",
       "6                 9  0.456209       1.362743  \n",
       "7                10  0.286275       2.294606  \n",
       "8                10  0.484967       1.626590  \n",
       "9                10  0.475817       1.640130  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_results_table_wine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the model on the congressional voting dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>handicapped-infants</th>\n",
       "      <th>water-project-cost-sharing</th>\n",
       "      <th>adoption-of-the-budget-resolution</th>\n",
       "      <th>physician-fee-freeze</th>\n",
       "      <th>el-salvador-aid</th>\n",
       "      <th>religious-groups-in-schools</th>\n",
       "      <th>anti-satellite-test-ban</th>\n",
       "      <th>aid-to-nicaraguan-contras</th>\n",
       "      <th>mx-missile</th>\n",
       "      <th>immigration</th>\n",
       "      <th>synfuels-crporation-cutback</th>\n",
       "      <th>education-spending</th>\n",
       "      <th>superfund-right-to-sue</th>\n",
       "      <th>crime</th>\n",
       "      <th>duty-free-exports</th>\n",
       "      <th>export-administration-act-south-africa</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>140</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>383</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>297</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>309</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID  handicapped-infants  water-project-cost-sharing  \\\n",
       "0  140                  1.0                         0.0   \n",
       "1  383                  1.0                         1.0   \n",
       "2  201                  0.0                         0.0   \n",
       "3  297                  0.0                         0.0   \n",
       "4  309                  0.0                         0.0   \n",
       "\n",
       "   adoption-of-the-budget-resolution  physician-fee-freeze  el-salvador-aid  \\\n",
       "0                                1.0                   0.0              0.0   \n",
       "1                                0.0                   1.0              1.0   \n",
       "2                                1.0                   0.0              0.0   \n",
       "3                                1.0                   1.0              1.0   \n",
       "4                                0.0                   1.0              1.0   \n",
       "\n",
       "   religious-groups-in-schools  anti-satellite-test-ban  \\\n",
       "0                          1.0                      1.0   \n",
       "1                          1.0                      0.0   \n",
       "2                          0.0                      1.0   \n",
       "3                          1.0                      0.0   \n",
       "4                          1.0                      0.0   \n",
       "\n",
       "   aid-to-nicaraguan-contras  mx-missile  immigration  \\\n",
       "0                        1.0         1.0          0.0   \n",
       "1                        0.0         0.0          0.0   \n",
       "2                        1.0         1.0          0.0   \n",
       "3                        0.0         0.0          1.0   \n",
       "4                        0.0         0.0          1.0   \n",
       "\n",
       "   synfuels-crporation-cutback  education-spending  superfund-right-to-sue  \\\n",
       "0                          0.0                 0.0                     0.0   \n",
       "1                          1.0                 0.0                     1.0   \n",
       "2                          0.0                 0.0                     0.0   \n",
       "3                          0.0                 1.0                     1.0   \n",
       "4                          0.0                 1.0                     1.0   \n",
       "\n",
       "   crime  duty-free-exports  export-administration-act-south-africa  class  \n",
       "0    0.0                1.0                                     1.0      1  \n",
       "1    1.0                0.0                                     1.0      1  \n",
       "2    1.0                1.0                                     1.0      1  \n",
       "3    1.0                1.0                                     1.0      0  \n",
       "4    1.0                0.0                                     0.0      0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cong_voting = pd.read_csv('./preprocessed-datasets/CongressionVoting_prepro.csv')\n",
    "# encode class value democrat as 1 and republican as 0\n",
    "cong_voting['class'] = cong_voting['class'].map({'democrat': 1, 'republican': 0})\n",
    "cong_voting.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting the dataset into training and testing sets, converting to PyTorch tensors and creating PyTorch DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_Y, test_X, test_Y = train_test_split(cong_voting, \"class\", return_torch=True)\n",
    "\n",
    "dataset = TensorDataset(train_X, train_Y)\n",
    "train_loader = DataLoader(dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "dataset = TensorDataset(test_X, test_Y)\n",
    "test_loader = DataLoader(dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the model, training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Average Loss: 0.8204039831956228\n",
      "Epoch 2/10, Average Loss: 0.6987561782201132\n",
      "Epoch 3/10, Average Loss: 0.6630964974562327\n",
      "Epoch 4/10, Average Loss: 0.5736258924007416\n",
      "Epoch 5/10, Average Loss: 0.4424207905928294\n",
      "Epoch 6/10, Average Loss: 0.3960420439640681\n",
      "Epoch 7/10, Average Loss: 0.29747725029786426\n",
      "Epoch 8/10, Average Loss: 0.2279346063733101\n",
      "Epoch 9/10, Average Loss: 0.22333091124892235\n",
      "Epoch 10/10, Average Loss: 0.3738237793246905\n",
      "Accuracy on training set: 0.959770143032074\n",
      "Accuracy on test set: 0.8604651093482971\n"
     ]
    }
   ],
   "source": [
    "input_size = train_X.shape[1] # number of features in congr voting dataset\n",
    "num_classes = 2 # 2 classes in congr voting dataset\n",
    "learning_rate = 0.01\n",
    "batch_size = 64\n",
    "num_epochs = 10\n",
    "hidden_layer_sizes = [25,30]\n",
    "activation_function = F.tanh\n",
    "\n",
    "model = NN(input_size=train_X.shape[1], num_classes=num_classes, hidden_layer_sizes=hidden_layer_sizes, activation_function=activation_function)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "train_model(model, train_loader, optimizer, criterion, num_epochs)\n",
    "\n",
    "print(f\"Accuracy on training set: {check_accuracy(train_loader, model)}\")\n",
    "print(f\"Accuracy on test set: {check_accuracy(test_loader, model)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the model on bank marketing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading and preparing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_marketing = pd.read_csv('./preprocessed-datasets/bank_marketing_prepro.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>...</th>\n",
       "      <th>education_basic.9y</th>\n",
       "      <th>education_high.school</th>\n",
       "      <th>education_illiterate</th>\n",
       "      <th>education_professional.course</th>\n",
       "      <th>education_university.degree</th>\n",
       "      <th>education_unknown</th>\n",
       "      <th>poutcome_failure</th>\n",
       "      <th>poutcome_nonexistent</th>\n",
       "      <th>poutcome_success</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  default  housing  loan  campaign  pdays  previous  emp.var.rate  \\\n",
       "0   56      0.0      0.0   0.0         1    999         0           1.1   \n",
       "1   57      0.0      0.0   0.0         1    999         0           1.1   \n",
       "2   37      0.0      1.0   0.0         1    999         0           1.1   \n",
       "3   40      0.0      0.0   0.0         1    999         0           1.1   \n",
       "4   56      0.0      0.0   1.0         1    999         0           1.1   \n",
       "\n",
       "   cons.price.idx  cons.conf.idx  ...  education_basic.9y  \\\n",
       "0          93.994          -36.4  ...                   0   \n",
       "1          93.994          -36.4  ...                   0   \n",
       "2          93.994          -36.4  ...                   0   \n",
       "3          93.994          -36.4  ...                   0   \n",
       "4          93.994          -36.4  ...                   0   \n",
       "\n",
       "   education_high.school  education_illiterate  education_professional.course  \\\n",
       "0                      0                     0                              0   \n",
       "1                      1                     0                              0   \n",
       "2                      1                     0                              0   \n",
       "3                      0                     0                              0   \n",
       "4                      1                     0                              0   \n",
       "\n",
       "   education_university.degree  education_unknown  poutcome_failure  \\\n",
       "0                            0                  0                 0   \n",
       "1                            0                  0                 0   \n",
       "2                            0                  0                 0   \n",
       "3                            0                  0                 0   \n",
       "4                            0                  0                 0   \n",
       "\n",
       "   poutcome_nonexistent  poutcome_success  class  \n",
       "0                     1                 0      0  \n",
       "1                     1                 0      0  \n",
       "2                     1                 0      0  \n",
       "3                     1                 0      0  \n",
       "4                     1                 0      0  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_to_move = 'class'\n",
    "\n",
    "# Move class to the last index\n",
    "columns = [col for col in bank_marketing.columns if col != column_to_move] + [column_to_move]\n",
    "bank_marketing = bank_marketing[columns]\n",
    "\n",
    "bank_marketing.drop('Unnamed: 0', axis=1,inplace=True)\n",
    "\n",
    "bank_marketing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'default', 'housing', 'loan', 'campaign', 'pdays', 'previous',\n",
       "       'emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m',\n",
       "       'nr.employed', 'job_blue-collar', 'job_management', 'job_other',\n",
       "       'job_self-employed', 'job_serivces', 'job_technician',\n",
       "       'marital_divorced', 'marital_married', 'marital_single',\n",
       "       'marital_unknown', 'education_basic.4y', 'education_basic.6y',\n",
       "       'education_basic.9y', 'education_high.school', 'education_illiterate',\n",
       "       'education_professional.course', 'education_university.degree',\n",
       "       'education_unknown', 'poutcome_failure', 'poutcome_nonexistent',\n",
       "       'poutcome_success', 'class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank_marketing.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting the dataset into training and testing sets, converting to PyTorch tensors and creating PyTorch DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_Y, test_X, test_Y = train_test_split(bank_marketing, \"class\", return_torch=True)\n",
    "\n",
    "dataset = TensorDataset(train_X, train_Y)\n",
    "train_loader = DataLoader(dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "dataset = TensorDataset(test_X, test_Y)\n",
    "test_loader = DataLoader(dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the model, training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Average Loss: 0.33090905211142546\n",
      "Epoch 2/10, Average Loss: 0.32768635471686\n",
      "Epoch 3/10, Average Loss: 0.327213676422111\n",
      "Epoch 4/10, Average Loss: 0.3280542928255299\n",
      "Epoch 5/10, Average Loss: 0.32849315527139356\n",
      "Epoch 6/10, Average Loss: 0.32820502676937763\n",
      "Epoch 7/10, Average Loss: 0.3284298519956545\n",
      "Epoch 8/10, Average Loss: 0.3284010060674068\n",
      "Epoch 9/10, Average Loss: 0.3283500720249507\n",
      "Epoch 10/10, Average Loss: 0.3283919007888118\n",
      "Accuracy on training set: 0.8986949920654297\n",
      "Accuracy on test set: 0.8928138017654419\n"
     ]
    }
   ],
   "source": [
    "input_size = train_X.shape[1] # number of features in congr voting dataset\n",
    "num_classes = 2 # 2 classes in congr voting dataset\n",
    "learning_rate = 0.01\n",
    "batch_size = 64\n",
    "num_epochs = 10\n",
    "hidden_layer_sizes = [25,30]\n",
    "activation_function = F.tanh\n",
    "\n",
    "model = NN(input_size=train_X.shape[1], num_classes=num_classes, hidden_layer_sizes=hidden_layer_sizes, activation_function=activation_function)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "train_model(model, train_loader, optimizer, criterion, num_epochs)\n",
    "\n",
    "print(f\"Accuracy on training set: {check_accuracy(train_loader, model)}\")\n",
    "print(f\"Accuracy on test set: {check_accuracy(test_loader, model)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Grid search over all three datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Average Loss: 1.3338039038371454\n",
      "Epoch 2/10, Average Loss: 1.2913920031003425\n",
      "Epoch 3/10, Average Loss: 1.2882495277498398\n",
      "Epoch 4/10, Average Loss: 1.287879331711611\n",
      "Epoch 5/10, Average Loss: 1.2764818719559652\n",
      "Epoch 6/10, Average Loss: 1.273354259736699\n",
      "Epoch 7/10, Average Loss: 1.2613155139735872\n",
      "Epoch 8/10, Average Loss: 1.259151681069216\n",
      "Epoch 9/10, Average Loss: 1.2574602010791287\n",
      "Epoch 10/10, Average Loss: 1.2471537063458213\n",
      "Epoch 1/15, Average Loss: 1.3338039038371454\n",
      "Epoch 2/15, Average Loss: 1.2913920031003425\n",
      "Epoch 3/15, Average Loss: 1.2882495277498398\n",
      "Epoch 4/15, Average Loss: 1.287879331711611\n",
      "Epoch 5/15, Average Loss: 1.2764818719559652\n",
      "Epoch 6/15, Average Loss: 1.273354259736699\n",
      "Epoch 7/15, Average Loss: 1.2613155139735872\n",
      "Epoch 8/15, Average Loss: 1.259151681069216\n",
      "Epoch 9/15, Average Loss: 1.2574602010791287\n",
      "Epoch 10/15, Average Loss: 1.2471537063458213\n",
      "Epoch 11/15, Average Loss: 1.2420796514288779\n",
      "Epoch 12/15, Average Loss: 1.2381280730107078\n",
      "Epoch 13/15, Average Loss: 1.2328106647620172\n",
      "Epoch 14/15, Average Loss: 1.2374375352830242\n",
      "Epoch 15/15, Average Loss: 1.2307769359986476\n",
      "Epoch 1/10, Average Loss: 1.3338039038371454\n",
      "Epoch 2/10, Average Loss: 1.2913920031003425\n",
      "Epoch 3/10, Average Loss: 1.2882495277498398\n",
      "Epoch 4/10, Average Loss: 1.287879331711611\n",
      "Epoch 5/10, Average Loss: 1.2764818719559652\n",
      "Epoch 6/10, Average Loss: 1.273354259736699\n",
      "Epoch 7/10, Average Loss: 1.2613155139735872\n",
      "Epoch 8/10, Average Loss: 1.259151681069216\n",
      "Epoch 9/10, Average Loss: 1.2574602010791287\n",
      "Epoch 10/10, Average Loss: 1.2471537063458213\n",
      "Epoch 1/15, Average Loss: 1.3338039038371454\n",
      "Epoch 2/15, Average Loss: 1.2913920031003425\n",
      "Epoch 3/15, Average Loss: 1.2882495277498398\n",
      "Epoch 4/15, Average Loss: 1.287879331711611\n",
      "Epoch 5/15, Average Loss: 1.2764818719559652\n",
      "Epoch 6/15, Average Loss: 1.273354259736699\n",
      "Epoch 7/15, Average Loss: 1.2613155139735872\n",
      "Epoch 8/15, Average Loss: 1.259151681069216\n",
      "Epoch 9/15, Average Loss: 1.2574602010791287\n",
      "Epoch 10/15, Average Loss: 1.2471537063458213\n",
      "Epoch 11/15, Average Loss: 1.2420796514288779\n",
      "Epoch 12/15, Average Loss: 1.2381280730107078\n",
      "Epoch 13/15, Average Loss: 1.2328106647620172\n",
      "Epoch 14/15, Average Loss: 1.2374375352830242\n",
      "Epoch 15/15, Average Loss: 1.2307769359986476\n",
      "Epoch 1/10, Average Loss: 1.5157994134294475\n",
      "Epoch 2/10, Average Loss: 1.289651695936004\n",
      "Epoch 3/10, Average Loss: 1.2775678963748955\n",
      "Epoch 4/10, Average Loss: 1.271873358568531\n",
      "Epoch 5/10, Average Loss: 1.2688023327318436\n",
      "Epoch 6/10, Average Loss: 1.2669888844519306\n",
      "Epoch 7/10, Average Loss: 1.2652103176877543\n",
      "Epoch 8/10, Average Loss: 1.2641891548238648\n",
      "Epoch 9/10, Average Loss: 1.262900858568999\n",
      "Epoch 10/10, Average Loss: 1.2618493456050661\n",
      "Epoch 1/15, Average Loss: 1.5157994134294475\n",
      "Epoch 2/15, Average Loss: 1.289651695936004\n",
      "Epoch 3/15, Average Loss: 1.2775678963748955\n",
      "Epoch 4/15, Average Loss: 1.271873358568531\n",
      "Epoch 5/15, Average Loss: 1.2688023327318436\n",
      "Epoch 6/15, Average Loss: 1.2669888844519306\n",
      "Epoch 7/15, Average Loss: 1.2652103176877543\n",
      "Epoch 8/15, Average Loss: 1.2641891548238648\n",
      "Epoch 9/15, Average Loss: 1.262900858568999\n",
      "Epoch 10/15, Average Loss: 1.2618493456050661\n",
      "Epoch 11/15, Average Loss: 1.2610034028445285\n",
      "Epoch 12/15, Average Loss: 1.2602082052113819\n",
      "Epoch 13/15, Average Loss: 1.2594348828485407\n",
      "Epoch 14/15, Average Loss: 1.258613472335909\n",
      "Epoch 15/15, Average Loss: 1.2577254099348572\n",
      "Epoch 1/10, Average Loss: 1.5157994134294475\n",
      "Epoch 2/10, Average Loss: 1.289651695936004\n",
      "Epoch 3/10, Average Loss: 1.2775678963748955\n",
      "Epoch 4/10, Average Loss: 1.271873358568531\n",
      "Epoch 5/10, Average Loss: 1.2688023327318436\n",
      "Epoch 6/10, Average Loss: 1.2669888844519306\n",
      "Epoch 7/10, Average Loss: 1.2652103176877543\n",
      "Epoch 8/10, Average Loss: 1.2641891548238648\n",
      "Epoch 9/10, Average Loss: 1.262900858568999\n",
      "Epoch 10/10, Average Loss: 1.2618493456050661\n",
      "Epoch 1/15, Average Loss: 1.5157994134294475\n",
      "Epoch 2/15, Average Loss: 1.289651695936004\n",
      "Epoch 3/15, Average Loss: 1.2775678963748955\n",
      "Epoch 4/15, Average Loss: 1.271873358568531\n",
      "Epoch 5/15, Average Loss: 1.2688023327318436\n",
      "Epoch 6/15, Average Loss: 1.2669888844519306\n",
      "Epoch 7/15, Average Loss: 1.2652103176877543\n",
      "Epoch 8/15, Average Loss: 1.2641891548238648\n",
      "Epoch 9/15, Average Loss: 1.262900858568999\n",
      "Epoch 10/15, Average Loss: 1.2618493456050661\n",
      "Epoch 11/15, Average Loss: 1.2610034028445285\n",
      "Epoch 12/15, Average Loss: 1.2602082052113819\n",
      "Epoch 13/15, Average Loss: 1.2594348828485407\n",
      "Epoch 14/15, Average Loss: 1.258613472335909\n",
      "Epoch 15/15, Average Loss: 1.2577254099348572\n",
      "Epoch 1/10, Average Loss: 3.2324448842212465\n",
      "Epoch 2/10, Average Loss: 1.3856300353272561\n",
      "Epoch 3/10, Average Loss: 1.3462281845098625\n",
      "Epoch 4/10, Average Loss: 1.257918922813392\n",
      "Epoch 5/10, Average Loss: 1.2235256934458494\n",
      "Epoch 6/10, Average Loss: 1.2044907881438367\n",
      "Epoch 7/10, Average Loss: 1.2062567889324727\n",
      "Epoch 8/10, Average Loss: 1.1796548176396844\n",
      "Epoch 9/10, Average Loss: 1.1690722276096694\n",
      "Epoch 10/10, Average Loss: 1.1569972122373757\n",
      "Epoch 1/15, Average Loss: 3.2324448842212465\n",
      "Epoch 2/15, Average Loss: 1.3856300353272561\n",
      "Epoch 3/15, Average Loss: 1.3462281845098625\n",
      "Epoch 4/15, Average Loss: 1.257918922813392\n",
      "Epoch 5/15, Average Loss: 1.2235256934458494\n",
      "Epoch 6/15, Average Loss: 1.2044907881438367\n",
      "Epoch 7/15, Average Loss: 1.2062567889324727\n",
      "Epoch 8/15, Average Loss: 1.1796548176396844\n",
      "Epoch 9/15, Average Loss: 1.1690722276096694\n",
      "Epoch 10/15, Average Loss: 1.1569972122373757\n",
      "Epoch 11/15, Average Loss: 1.1473126883155729\n",
      "Epoch 12/15, Average Loss: 1.1473307430378499\n",
      "Epoch 13/15, Average Loss: 1.13545050028643\n",
      "Epoch 14/15, Average Loss: 1.1412049959773667\n",
      "Epoch 15/15, Average Loss: 1.1266190789959913\n",
      "Epoch 1/10, Average Loss: 3.2324448842212465\n",
      "Epoch 2/10, Average Loss: 1.3856300353272561\n",
      "Epoch 3/10, Average Loss: 1.3462281845098625\n",
      "Epoch 4/10, Average Loss: 1.257918922813392\n",
      "Epoch 5/10, Average Loss: 1.2235256934458494\n",
      "Epoch 6/10, Average Loss: 1.2044907881438367\n",
      "Epoch 7/10, Average Loss: 1.2062567889324727\n",
      "Epoch 8/10, Average Loss: 1.1796548176396844\n",
      "Epoch 9/10, Average Loss: 1.1690722276096694\n",
      "Epoch 10/10, Average Loss: 1.1569972122373757\n",
      "Epoch 1/15, Average Loss: 3.2324448842212465\n",
      "Epoch 2/15, Average Loss: 1.3856300353272561\n",
      "Epoch 3/15, Average Loss: 1.3462281845098625\n",
      "Epoch 4/15, Average Loss: 1.257918922813392\n",
      "Epoch 5/15, Average Loss: 1.2235256934458494\n",
      "Epoch 6/15, Average Loss: 1.2044907881438367\n",
      "Epoch 7/15, Average Loss: 1.2062567889324727\n",
      "Epoch 8/15, Average Loss: 1.1796548176396844\n",
      "Epoch 9/15, Average Loss: 1.1690722276096694\n",
      "Epoch 10/15, Average Loss: 1.1569972122373757\n",
      "Epoch 11/15, Average Loss: 1.1473126883155729\n",
      "Epoch 12/15, Average Loss: 1.1473307430378499\n",
      "Epoch 13/15, Average Loss: 1.13545050028643\n",
      "Epoch 14/15, Average Loss: 1.1412049959773667\n",
      "Epoch 15/15, Average Loss: 1.1266190789959913\n",
      "Epoch 1/10, Average Loss: 9.377237459633248\n",
      "Epoch 2/10, Average Loss: 1.4767584391166828\n",
      "Epoch 3/10, Average Loss: 1.3564692805149803\n",
      "Epoch 4/10, Average Loss: 1.3102094132476059\n",
      "Epoch 5/10, Average Loss: 1.2892052538555825\n",
      "Epoch 6/10, Average Loss: 1.2768256934873896\n",
      "Epoch 7/10, Average Loss: 1.2672780251210451\n",
      "Epoch 8/10, Average Loss: 1.2594708646733337\n",
      "Epoch 9/10, Average Loss: 1.2536153712886975\n",
      "Epoch 10/10, Average Loss: 1.247289777899081\n",
      "Epoch 1/15, Average Loss: 9.377237459633248\n",
      "Epoch 2/15, Average Loss: 1.4767584391166828\n",
      "Epoch 3/15, Average Loss: 1.3564692805149803\n",
      "Epoch 4/15, Average Loss: 1.3102094132476059\n",
      "Epoch 5/15, Average Loss: 1.2892052538555825\n",
      "Epoch 6/15, Average Loss: 1.2768256934873896\n",
      "Epoch 7/15, Average Loss: 1.2672780251210451\n",
      "Epoch 8/15, Average Loss: 1.2594708646733337\n",
      "Epoch 9/15, Average Loss: 1.2536153712886975\n",
      "Epoch 10/15, Average Loss: 1.247289777899081\n",
      "Epoch 11/15, Average Loss: 1.2416112975108844\n",
      "Epoch 12/15, Average Loss: 1.2359264591720207\n",
      "Epoch 13/15, Average Loss: 1.2301301670952078\n",
      "Epoch 14/15, Average Loss: 1.224707898918105\n",
      "Epoch 15/15, Average Loss: 1.2197116788910942\n",
      "Epoch 1/10, Average Loss: 9.377237459633248\n",
      "Epoch 2/10, Average Loss: 1.4767584391166828\n",
      "Epoch 3/10, Average Loss: 1.3564692805149803\n",
      "Epoch 4/10, Average Loss: 1.3102094132476059\n",
      "Epoch 5/10, Average Loss: 1.2892052538555825\n",
      "Epoch 6/10, Average Loss: 1.2768256934873896\n",
      "Epoch 7/10, Average Loss: 1.2672780251210451\n",
      "Epoch 8/10, Average Loss: 1.2594708646733337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Average Loss: 1.2536153712886975\n",
      "Epoch 10/10, Average Loss: 1.247289777899081\n",
      "Epoch 1/15, Average Loss: 9.377237459633248\n",
      "Epoch 2/15, Average Loss: 1.4767584391166828\n",
      "Epoch 3/15, Average Loss: 1.3564692805149803\n",
      "Epoch 4/15, Average Loss: 1.3102094132476059\n",
      "Epoch 5/15, Average Loss: 1.2892052538555825\n",
      "Epoch 6/15, Average Loss: 1.2768256934873896\n",
      "Epoch 7/15, Average Loss: 1.2672780251210451\n",
      "Epoch 8/15, Average Loss: 1.2594708646733337\n",
      "Epoch 9/15, Average Loss: 1.2536153712886975\n",
      "Epoch 10/15, Average Loss: 1.247289777899081\n",
      "Epoch 11/15, Average Loss: 1.2416112975108844\n",
      "Epoch 12/15, Average Loss: 1.2359264591720207\n",
      "Epoch 13/15, Average Loss: 1.2301301670952078\n",
      "Epoch 14/15, Average Loss: 1.224707898918105\n",
      "Epoch 15/15, Average Loss: 1.2197116788910942\n",
      "Epoch 1/10, Average Loss: 1.3134170412285928\n",
      "Epoch 2/10, Average Loss: 1.2745691197781475\n",
      "Epoch 3/10, Average Loss: 1.2602842044245246\n",
      "Epoch 4/10, Average Loss: 1.255159665836147\n",
      "Epoch 5/10, Average Loss: 1.2602674778253755\n",
      "Epoch 6/10, Average Loss: 1.264168846826612\n",
      "Epoch 7/10, Average Loss: 1.2485608608444776\n",
      "Epoch 8/10, Average Loss: 1.2595036161457833\n",
      "Epoch 9/10, Average Loss: 1.2443360799660712\n",
      "Epoch 10/10, Average Loss: 1.237217853771397\n",
      "Epoch 1/15, Average Loss: 1.3134170412285928\n",
      "Epoch 2/15, Average Loss: 1.2745691197781475\n",
      "Epoch 3/15, Average Loss: 1.2602842044245246\n",
      "Epoch 4/15, Average Loss: 1.255159665836147\n",
      "Epoch 5/15, Average Loss: 1.2602674778253755\n",
      "Epoch 6/15, Average Loss: 1.264168846826612\n",
      "Epoch 7/15, Average Loss: 1.2485608608444776\n",
      "Epoch 8/15, Average Loss: 1.2595036161457833\n",
      "Epoch 9/15, Average Loss: 1.2443360799660712\n",
      "Epoch 10/15, Average Loss: 1.237217853771397\n",
      "Epoch 11/15, Average Loss: 1.2370942703053995\n",
      "Epoch 12/15, Average Loss: 1.2128963415608085\n",
      "Epoch 13/15, Average Loss: 1.2062858120064062\n",
      "Epoch 14/15, Average Loss: 1.210134333628087\n",
      "Epoch 15/15, Average Loss: 1.2093613930275104\n",
      "Epoch 1/10, Average Loss: 1.3134170412285928\n",
      "Epoch 2/10, Average Loss: 1.2745691197781475\n",
      "Epoch 3/10, Average Loss: 1.2602842044245246\n",
      "Epoch 4/10, Average Loss: 1.255159665836147\n",
      "Epoch 5/10, Average Loss: 1.2602674778253755\n",
      "Epoch 6/10, Average Loss: 1.264168846826612\n",
      "Epoch 7/10, Average Loss: 1.2485608608444776\n",
      "Epoch 8/10, Average Loss: 1.2595036161457833\n",
      "Epoch 9/10, Average Loss: 1.2443360799660712\n",
      "Epoch 10/10, Average Loss: 1.237217853771397\n",
      "Epoch 1/15, Average Loss: 1.3134170412285928\n",
      "Epoch 2/15, Average Loss: 1.2745691197781475\n",
      "Epoch 3/15, Average Loss: 1.2602842044245246\n",
      "Epoch 4/15, Average Loss: 1.255159665836147\n",
      "Epoch 5/15, Average Loss: 1.2602674778253755\n",
      "Epoch 6/15, Average Loss: 1.264168846826612\n",
      "Epoch 7/15, Average Loss: 1.2485608608444776\n",
      "Epoch 8/15, Average Loss: 1.2595036161457833\n",
      "Epoch 9/15, Average Loss: 1.2443360799660712\n",
      "Epoch 10/15, Average Loss: 1.237217853771397\n",
      "Epoch 11/15, Average Loss: 1.2370942703053995\n",
      "Epoch 12/15, Average Loss: 1.2128963415608085\n",
      "Epoch 13/15, Average Loss: 1.2062858120064062\n",
      "Epoch 14/15, Average Loss: 1.210134333628087\n",
      "Epoch 15/15, Average Loss: 1.2093613930275104\n",
      "Epoch 1/10, Average Loss: 1.4186995102583997\n",
      "Epoch 2/10, Average Loss: 1.2782277314940844\n",
      "Epoch 3/10, Average Loss: 1.262066488617037\n",
      "Epoch 4/10, Average Loss: 1.2518391415385381\n",
      "Epoch 5/10, Average Loss: 1.2465846081452867\n",
      "Epoch 6/10, Average Loss: 1.2425309704856637\n",
      "Epoch 7/10, Average Loss: 1.2388924912440997\n",
      "Epoch 8/10, Average Loss: 1.235733364623017\n",
      "Epoch 9/10, Average Loss: 1.232753729893386\n",
      "Epoch 10/10, Average Loss: 1.2301347976081942\n",
      "Epoch 1/15, Average Loss: 1.4186995102583997\n",
      "Epoch 2/15, Average Loss: 1.2782277314940844\n",
      "Epoch 3/15, Average Loss: 1.262066488617037\n",
      "Epoch 4/15, Average Loss: 1.2518391415385381\n",
      "Epoch 5/15, Average Loss: 1.2465846081452867\n",
      "Epoch 6/15, Average Loss: 1.2425309704856637\n",
      "Epoch 7/15, Average Loss: 1.2388924912440997\n",
      "Epoch 8/15, Average Loss: 1.235733364623017\n",
      "Epoch 9/15, Average Loss: 1.232753729893386\n",
      "Epoch 10/15, Average Loss: 1.2301347976081942\n",
      "Epoch 11/15, Average Loss: 1.227657817624098\n",
      "Epoch 12/15, Average Loss: 1.224919873146923\n",
      "Epoch 13/15, Average Loss: 1.2219961314844938\n",
      "Epoch 14/15, Average Loss: 1.2194648458182447\n",
      "Epoch 15/15, Average Loss: 1.217335763153123\n",
      "Epoch 1/10, Average Loss: 1.4186995102583997\n",
      "Epoch 2/10, Average Loss: 1.2782277314940844\n",
      "Epoch 3/10, Average Loss: 1.262066488617037\n",
      "Epoch 4/10, Average Loss: 1.2518391415385381\n",
      "Epoch 5/10, Average Loss: 1.2465846081452867\n",
      "Epoch 6/10, Average Loss: 1.2425309704856637\n",
      "Epoch 7/10, Average Loss: 1.2388924912440997\n",
      "Epoch 8/10, Average Loss: 1.235733364623017\n",
      "Epoch 9/10, Average Loss: 1.232753729893386\n",
      "Epoch 10/10, Average Loss: 1.2301347976081942\n",
      "Epoch 1/15, Average Loss: 1.4186995102583997\n",
      "Epoch 2/15, Average Loss: 1.2782277314940844\n",
      "Epoch 3/15, Average Loss: 1.262066488617037\n",
      "Epoch 4/15, Average Loss: 1.2518391415385381\n",
      "Epoch 5/15, Average Loss: 1.2465846081452867\n",
      "Epoch 6/15, Average Loss: 1.2425309704856637\n",
      "Epoch 7/15, Average Loss: 1.2388924912440997\n",
      "Epoch 8/15, Average Loss: 1.235733364623017\n",
      "Epoch 9/15, Average Loss: 1.232753729893386\n",
      "Epoch 10/15, Average Loss: 1.2301347976081942\n",
      "Epoch 11/15, Average Loss: 1.227657817624098\n",
      "Epoch 12/15, Average Loss: 1.224919873146923\n",
      "Epoch 13/15, Average Loss: 1.2219961314844938\n",
      "Epoch 14/15, Average Loss: 1.2194648458182447\n",
      "Epoch 15/15, Average Loss: 1.217335763153123\n",
      "Epoch 1/10, Average Loss: 2.9295862613280126\n",
      "Epoch 2/10, Average Loss: 1.4053171090553143\n",
      "Epoch 3/10, Average Loss: 1.3101701901002896\n",
      "Epoch 4/10, Average Loss: 1.2456525750686787\n",
      "Epoch 5/10, Average Loss: 1.2154414986540203\n",
      "Epoch 6/10, Average Loss: 1.1932655766697748\n",
      "Epoch 7/10, Average Loss: 1.1867467870741535\n",
      "Epoch 8/10, Average Loss: 1.1742928529078245\n",
      "Epoch 9/10, Average Loss: 1.1715527827754342\n",
      "Epoch 10/10, Average Loss: 1.1706595387926861\n",
      "Epoch 1/15, Average Loss: 2.9295862613280126\n",
      "Epoch 2/15, Average Loss: 1.4053171090553143\n",
      "Epoch 3/15, Average Loss: 1.3101701901002896\n",
      "Epoch 4/15, Average Loss: 1.2456525750686787\n",
      "Epoch 5/15, Average Loss: 1.2154414986540203\n",
      "Epoch 6/15, Average Loss: 1.1932655766697748\n",
      "Epoch 7/15, Average Loss: 1.1867467870741535\n",
      "Epoch 8/15, Average Loss: 1.1742928529078245\n",
      "Epoch 9/15, Average Loss: 1.1715527827754342\n",
      "Epoch 10/15, Average Loss: 1.1706595387926861\n",
      "Epoch 11/15, Average Loss: 1.158407743357442\n",
      "Epoch 12/15, Average Loss: 1.1470830674551746\n",
      "Epoch 13/15, Average Loss: 1.150862929279819\n",
      "Epoch 14/15, Average Loss: 1.1405766434464717\n",
      "Epoch 15/15, Average Loss: 1.1453438390252049\n",
      "Epoch 1/10, Average Loss: 2.9295862613280126\n",
      "Epoch 2/10, Average Loss: 1.4053171090553143\n",
      "Epoch 3/10, Average Loss: 1.3101701901002896\n",
      "Epoch 4/10, Average Loss: 1.2456525750686787\n",
      "Epoch 5/10, Average Loss: 1.2154414986540203\n",
      "Epoch 6/10, Average Loss: 1.1932655766697748\n",
      "Epoch 7/10, Average Loss: 1.1867467870741535\n",
      "Epoch 8/10, Average Loss: 1.1742928529078245\n",
      "Epoch 9/10, Average Loss: 1.1715527827754342\n",
      "Epoch 10/10, Average Loss: 1.1706595387926861\n",
      "Epoch 1/15, Average Loss: 2.9295862613280126\n",
      "Epoch 2/15, Average Loss: 1.4053171090553143\n",
      "Epoch 3/15, Average Loss: 1.3101701901002896\n",
      "Epoch 4/15, Average Loss: 1.2456525750686787\n",
      "Epoch 5/15, Average Loss: 1.2154414986540203\n",
      "Epoch 6/15, Average Loss: 1.1932655766697748\n",
      "Epoch 7/15, Average Loss: 1.1867467870741535\n",
      "Epoch 8/15, Average Loss: 1.1742928529078245\n",
      "Epoch 9/15, Average Loss: 1.1715527827754342\n",
      "Epoch 10/15, Average Loss: 1.1706595387926861\n",
      "Epoch 11/15, Average Loss: 1.158407743357442\n",
      "Epoch 12/15, Average Loss: 1.1470830674551746\n",
      "Epoch 13/15, Average Loss: 1.150862929279819\n",
      "Epoch 14/15, Average Loss: 1.1405766434464717\n",
      "Epoch 15/15, Average Loss: 1.1453438390252049\n",
      "Epoch 1/10, Average Loss: 8.816645726835802\n",
      "Epoch 2/10, Average Loss: 1.8097324327457172\n",
      "Epoch 3/10, Average Loss: 1.591396429056039\n",
      "Epoch 4/10, Average Loss: 1.5077126728245085\n",
      "Epoch 5/10, Average Loss: 1.4583211479011489\n",
      "Epoch 6/10, Average Loss: 1.4147324657147646\n",
      "Epoch 7/10, Average Loss: 1.3891667884551675\n",
      "Epoch 8/10, Average Loss: 1.3638630611764873\n",
      "Epoch 9/10, Average Loss: 1.345775969189369\n",
      "Epoch 10/10, Average Loss: 1.3330556205445272\n",
      "Epoch 1/15, Average Loss: 8.816645726835802\n",
      "Epoch 2/15, Average Loss: 1.8097324327457172\n",
      "Epoch 3/15, Average Loss: 1.591396429056039\n",
      "Epoch 4/15, Average Loss: 1.5077126728245085\n",
      "Epoch 5/15, Average Loss: 1.4583211479011489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/15, Average Loss: 1.4147324657147646\n",
      "Epoch 7/15, Average Loss: 1.3891667884551675\n",
      "Epoch 8/15, Average Loss: 1.3638630611764873\n",
      "Epoch 9/15, Average Loss: 1.345775969189369\n",
      "Epoch 10/15, Average Loss: 1.3330556205445272\n",
      "Epoch 11/15, Average Loss: 1.320689352377792\n",
      "Epoch 12/15, Average Loss: 1.3102229701960746\n",
      "Epoch 13/15, Average Loss: 1.302969576756647\n",
      "Epoch 14/15, Average Loss: 1.29046348998883\n",
      "Epoch 15/15, Average Loss: 1.2835565172821466\n",
      "Epoch 1/10, Average Loss: 8.816645726835802\n",
      "Epoch 2/10, Average Loss: 1.8097324327457172\n",
      "Epoch 3/10, Average Loss: 1.591396429056039\n",
      "Epoch 4/10, Average Loss: 1.5077126728245085\n",
      "Epoch 5/10, Average Loss: 1.4583211479011489\n",
      "Epoch 6/10, Average Loss: 1.4147324657147646\n",
      "Epoch 7/10, Average Loss: 1.3891667884551675\n",
      "Epoch 8/10, Average Loss: 1.3638630611764873\n",
      "Epoch 9/10, Average Loss: 1.345775969189369\n",
      "Epoch 10/10, Average Loss: 1.3330556205445272\n",
      "Epoch 1/15, Average Loss: 8.816645726835802\n",
      "Epoch 2/15, Average Loss: 1.8097324327457172\n",
      "Epoch 3/15, Average Loss: 1.591396429056039\n",
      "Epoch 4/15, Average Loss: 1.5077126728245085\n",
      "Epoch 5/15, Average Loss: 1.4583211479011489\n",
      "Epoch 6/15, Average Loss: 1.4147324657147646\n",
      "Epoch 7/15, Average Loss: 1.3891667884551675\n",
      "Epoch 8/15, Average Loss: 1.3638630611764873\n",
      "Epoch 9/15, Average Loss: 1.345775969189369\n",
      "Epoch 10/15, Average Loss: 1.3330556205445272\n",
      "Epoch 11/15, Average Loss: 1.320689352377792\n",
      "Epoch 12/15, Average Loss: 1.3102229701960746\n",
      "Epoch 13/15, Average Loss: 1.302969576756647\n",
      "Epoch 14/15, Average Loss: 1.29046348998883\n",
      "Epoch 15/15, Average Loss: 1.2835565172821466\n",
      "Epoch 1/10, Average Loss: 0.8204039831956228\n",
      "Epoch 2/10, Average Loss: 0.6987561782201132\n",
      "Epoch 3/10, Average Loss: 0.6630964974562327\n",
      "Epoch 4/10, Average Loss: 0.5736258924007416\n",
      "Epoch 5/10, Average Loss: 0.4424207905928294\n",
      "Epoch 6/10, Average Loss: 0.3960420439640681\n",
      "Epoch 7/10, Average Loss: 0.29747725029786426\n",
      "Epoch 8/10, Average Loss: 0.2279346063733101\n",
      "Epoch 9/10, Average Loss: 0.22333091124892235\n",
      "Epoch 10/10, Average Loss: 0.3738237793246905\n",
      "Epoch 1/15, Average Loss: 0.8204039831956228\n",
      "Epoch 2/15, Average Loss: 0.6987561782201132\n",
      "Epoch 3/15, Average Loss: 0.6630964974562327\n",
      "Epoch 4/15, Average Loss: 0.5736258924007416\n",
      "Epoch 5/15, Average Loss: 0.4424207905928294\n",
      "Epoch 6/15, Average Loss: 0.3960420439640681\n",
      "Epoch 7/15, Average Loss: 0.29747725029786426\n",
      "Epoch 8/15, Average Loss: 0.2279346063733101\n",
      "Epoch 9/15, Average Loss: 0.22333091124892235\n",
      "Epoch 10/15, Average Loss: 0.3738237793246905\n",
      "Epoch 11/15, Average Loss: 0.2867339824636777\n",
      "Epoch 12/15, Average Loss: 0.14389140841861567\n",
      "Epoch 13/15, Average Loss: 0.13733384509881338\n",
      "Epoch 14/15, Average Loss: 0.09313429457445939\n",
      "Epoch 15/15, Average Loss: 0.10354475133741896\n",
      "Epoch 1/10, Average Loss: 0.8204039831956228\n",
      "Epoch 2/10, Average Loss: 0.6987561782201132\n",
      "Epoch 3/10, Average Loss: 0.6630964974562327\n",
      "Epoch 4/10, Average Loss: 0.5736258924007416\n",
      "Epoch 5/10, Average Loss: 0.4424207905928294\n",
      "Epoch 6/10, Average Loss: 0.3960420439640681\n",
      "Epoch 7/10, Average Loss: 0.29747725029786426\n",
      "Epoch 8/10, Average Loss: 0.2279346063733101\n",
      "Epoch 9/10, Average Loss: 0.22333091124892235\n",
      "Epoch 10/10, Average Loss: 0.3738237793246905\n",
      "Epoch 1/15, Average Loss: 0.8204039831956228\n",
      "Epoch 2/15, Average Loss: 0.6987561782201132\n",
      "Epoch 3/15, Average Loss: 0.6630964974562327\n",
      "Epoch 4/15, Average Loss: 0.5736258924007416\n",
      "Epoch 5/15, Average Loss: 0.4424207905928294\n",
      "Epoch 6/15, Average Loss: 0.3960420439640681\n",
      "Epoch 7/15, Average Loss: 0.29747725029786426\n",
      "Epoch 8/15, Average Loss: 0.2279346063733101\n",
      "Epoch 9/15, Average Loss: 0.22333091124892235\n",
      "Epoch 10/15, Average Loss: 0.3738237793246905\n",
      "Epoch 11/15, Average Loss: 0.2867339824636777\n",
      "Epoch 12/15, Average Loss: 0.14389140841861567\n",
      "Epoch 13/15, Average Loss: 0.13733384509881338\n",
      "Epoch 14/15, Average Loss: 0.09313429457445939\n",
      "Epoch 15/15, Average Loss: 0.10354475133741896\n",
      "Epoch 1/10, Average Loss: 0.929987629254659\n",
      "Epoch 2/10, Average Loss: 0.6982380151748657\n",
      "Epoch 3/10, Average Loss: 0.676446795463562\n",
      "Epoch 4/10, Average Loss: 0.6868465542793274\n",
      "Epoch 5/10, Average Loss: 0.670306662718455\n",
      "Epoch 6/10, Average Loss: 0.6574374139308929\n",
      "Epoch 7/10, Average Loss: 0.6572811007499695\n",
      "Epoch 8/10, Average Loss: 0.6551820735136668\n",
      "Epoch 9/10, Average Loss: 0.6470430692036947\n",
      "Epoch 10/10, Average Loss: 0.629673441251119\n",
      "Epoch 1/15, Average Loss: 0.929987629254659\n",
      "Epoch 2/15, Average Loss: 0.6982380151748657\n",
      "Epoch 3/15, Average Loss: 0.676446795463562\n",
      "Epoch 4/15, Average Loss: 0.6868465542793274\n",
      "Epoch 5/15, Average Loss: 0.670306662718455\n",
      "Epoch 6/15, Average Loss: 0.6574374139308929\n",
      "Epoch 7/15, Average Loss: 0.6572811007499695\n",
      "Epoch 8/15, Average Loss: 0.6551820735136668\n",
      "Epoch 9/15, Average Loss: 0.6470430692036947\n",
      "Epoch 10/15, Average Loss: 0.629673441251119\n",
      "Epoch 11/15, Average Loss: 0.6045704384644827\n",
      "Epoch 12/15, Average Loss: 0.5809908211231232\n",
      "Epoch 13/15, Average Loss: 0.5503312249978384\n",
      "Epoch 14/15, Average Loss: 0.5192752679189047\n",
      "Epoch 15/15, Average Loss: 0.4833599080642064\n",
      "Epoch 1/10, Average Loss: 0.929987629254659\n",
      "Epoch 2/10, Average Loss: 0.6982380151748657\n",
      "Epoch 3/10, Average Loss: 0.676446795463562\n",
      "Epoch 4/10, Average Loss: 0.6868465542793274\n",
      "Epoch 5/10, Average Loss: 0.670306662718455\n",
      "Epoch 6/10, Average Loss: 0.6574374139308929\n",
      "Epoch 7/10, Average Loss: 0.6572811007499695\n",
      "Epoch 8/10, Average Loss: 0.6551820735136668\n",
      "Epoch 9/10, Average Loss: 0.6470430692036947\n",
      "Epoch 10/10, Average Loss: 0.629673441251119\n",
      "Epoch 1/15, Average Loss: 0.929987629254659\n",
      "Epoch 2/15, Average Loss: 0.6982380151748657\n",
      "Epoch 3/15, Average Loss: 0.676446795463562\n",
      "Epoch 4/15, Average Loss: 0.6868465542793274\n",
      "Epoch 5/15, Average Loss: 0.670306662718455\n",
      "Epoch 6/15, Average Loss: 0.6574374139308929\n",
      "Epoch 7/15, Average Loss: 0.6572811007499695\n",
      "Epoch 8/15, Average Loss: 0.6551820735136668\n",
      "Epoch 9/15, Average Loss: 0.6470430692036947\n",
      "Epoch 10/15, Average Loss: 0.629673441251119\n",
      "Epoch 11/15, Average Loss: 0.6045704384644827\n",
      "Epoch 12/15, Average Loss: 0.5809908211231232\n",
      "Epoch 13/15, Average Loss: 0.5503312249978384\n",
      "Epoch 14/15, Average Loss: 0.5192752679189047\n",
      "Epoch 15/15, Average Loss: 0.4833599080642064\n",
      "Epoch 1/10, Average Loss: 38.72160251935323\n",
      "Epoch 2/10, Average Loss: 25.483660221099854\n",
      "Epoch 3/10, Average Loss: 16.219836602608364\n",
      "Epoch 4/10, Average Loss: 19.44821532567342\n",
      "Epoch 5/10, Average Loss: 12.351164177060127\n",
      "Epoch 6/10, Average Loss: 6.668073656658332\n",
      "Epoch 7/10, Average Loss: 3.3398536294698715\n",
      "Epoch 8/10, Average Loss: 1.678579183916251\n",
      "Epoch 9/10, Average Loss: 0.6306385522087415\n",
      "Epoch 10/10, Average Loss: 0.9085336625576019\n",
      "Epoch 1/15, Average Loss: 38.72160251935323\n",
      "Epoch 2/15, Average Loss: 25.483660221099854\n",
      "Epoch 3/15, Average Loss: 16.219836602608364\n",
      "Epoch 4/15, Average Loss: 19.44821532567342\n",
      "Epoch 5/15, Average Loss: 12.351164177060127\n",
      "Epoch 6/15, Average Loss: 6.668073656658332\n",
      "Epoch 7/15, Average Loss: 3.3398536294698715\n",
      "Epoch 8/15, Average Loss: 1.678579183916251\n",
      "Epoch 9/15, Average Loss: 0.6306385522087415\n",
      "Epoch 10/15, Average Loss: 0.9085336625576019\n",
      "Epoch 11/15, Average Loss: 1.116196759045124\n",
      "Epoch 12/15, Average Loss: 0.8409416178862253\n",
      "Epoch 13/15, Average Loss: 0.578924186527729\n",
      "Epoch 14/15, Average Loss: 0.6269246364633242\n",
      "Epoch 15/15, Average Loss: 0.7512960483630499\n",
      "Epoch 1/10, Average Loss: 38.72160251935323\n",
      "Epoch 2/10, Average Loss: 25.483660221099854\n",
      "Epoch 3/10, Average Loss: 16.219836602608364\n",
      "Epoch 4/10, Average Loss: 19.44821532567342\n",
      "Epoch 5/10, Average Loss: 12.351164177060127\n",
      "Epoch 6/10, Average Loss: 6.668073656658332\n",
      "Epoch 7/10, Average Loss: 3.3398536294698715\n",
      "Epoch 8/10, Average Loss: 1.678579183916251\n",
      "Epoch 9/10, Average Loss: 0.6306385522087415\n",
      "Epoch 10/10, Average Loss: 0.9085336625576019\n",
      "Epoch 1/15, Average Loss: 38.72160251935323\n",
      "Epoch 2/15, Average Loss: 25.483660221099854\n",
      "Epoch 3/15, Average Loss: 16.219836602608364\n",
      "Epoch 4/15, Average Loss: 19.44821532567342\n",
      "Epoch 5/15, Average Loss: 12.351164177060127\n",
      "Epoch 6/15, Average Loss: 6.668073656658332\n",
      "Epoch 7/15, Average Loss: 3.3398536294698715\n",
      "Epoch 8/15, Average Loss: 1.678579183916251\n",
      "Epoch 9/15, Average Loss: 0.6306385522087415\n",
      "Epoch 10/15, Average Loss: 0.9085336625576019\n",
      "Epoch 11/15, Average Loss: 1.116196759045124\n",
      "Epoch 12/15, Average Loss: 0.8409416178862253\n",
      "Epoch 13/15, Average Loss: 0.578924186527729\n",
      "Epoch 14/15, Average Loss: 0.6269246364633242\n",
      "Epoch 15/15, Average Loss: 0.7512960483630499\n",
      "Epoch 1/10, Average Loss: 52.3094285329183\n",
      "Epoch 2/10, Average Loss: 13.70142294963201\n",
      "Epoch 3/10, Average Loss: 7.520770311355591\n",
      "Epoch 4/10, Average Loss: 8.185037533442179\n",
      "Epoch 5/10, Average Loss: 2.8259220321973166\n",
      "Epoch 6/10, Average Loss: 2.318928783138593\n",
      "Epoch 7/10, Average Loss: 1.678759495417277\n",
      "Epoch 8/10, Average Loss: 0.986444835861524\n",
      "Epoch 9/10, Average Loss: 0.6860190977652868\n",
      "Epoch 10/10, Average Loss: 0.522232914964358\n",
      "Epoch 1/15, Average Loss: 52.3094285329183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/15, Average Loss: 13.70142294963201\n",
      "Epoch 3/15, Average Loss: 7.520770311355591\n",
      "Epoch 4/15, Average Loss: 8.185037533442179\n",
      "Epoch 5/15, Average Loss: 2.8259220321973166\n",
      "Epoch 6/15, Average Loss: 2.318928783138593\n",
      "Epoch 7/15, Average Loss: 1.678759495417277\n",
      "Epoch 8/15, Average Loss: 0.986444835861524\n",
      "Epoch 9/15, Average Loss: 0.6860190977652868\n",
      "Epoch 10/15, Average Loss: 0.522232914964358\n",
      "Epoch 11/15, Average Loss: 0.37667860339085263\n",
      "Epoch 12/15, Average Loss: 0.30535699675480527\n",
      "Epoch 13/15, Average Loss: 0.3000682443380356\n",
      "Epoch 14/15, Average Loss: 0.24604910363753638\n",
      "Epoch 15/15, Average Loss: 0.2401899273196856\n",
      "Epoch 1/10, Average Loss: 52.3094285329183\n",
      "Epoch 2/10, Average Loss: 13.70142294963201\n",
      "Epoch 3/10, Average Loss: 7.520770311355591\n",
      "Epoch 4/10, Average Loss: 8.185037533442179\n",
      "Epoch 5/10, Average Loss: 2.8259220321973166\n",
      "Epoch 6/10, Average Loss: 2.318928783138593\n",
      "Epoch 7/10, Average Loss: 1.678759495417277\n",
      "Epoch 8/10, Average Loss: 0.986444835861524\n",
      "Epoch 9/10, Average Loss: 0.6860190977652868\n",
      "Epoch 10/10, Average Loss: 0.522232914964358\n",
      "Epoch 1/15, Average Loss: 52.3094285329183\n",
      "Epoch 2/15, Average Loss: 13.70142294963201\n",
      "Epoch 3/15, Average Loss: 7.520770311355591\n",
      "Epoch 4/15, Average Loss: 8.185037533442179\n",
      "Epoch 5/15, Average Loss: 2.8259220321973166\n",
      "Epoch 6/15, Average Loss: 2.318928783138593\n",
      "Epoch 7/15, Average Loss: 1.678759495417277\n",
      "Epoch 8/15, Average Loss: 0.986444835861524\n",
      "Epoch 9/15, Average Loss: 0.6860190977652868\n",
      "Epoch 10/15, Average Loss: 0.522232914964358\n",
      "Epoch 11/15, Average Loss: 0.37667860339085263\n",
      "Epoch 12/15, Average Loss: 0.30535699675480527\n",
      "Epoch 13/15, Average Loss: 0.3000682443380356\n",
      "Epoch 14/15, Average Loss: 0.24604910363753638\n",
      "Epoch 15/15, Average Loss: 0.2401899273196856\n",
      "Epoch 1/10, Average Loss: 0.7169765134652456\n",
      "Epoch 2/10, Average Loss: 0.5746778547763824\n",
      "Epoch 3/10, Average Loss: 0.47384462257226306\n",
      "Epoch 4/10, Average Loss: 0.49100759625434875\n",
      "Epoch 5/10, Average Loss: 0.41167424867550534\n",
      "Epoch 6/10, Average Loss: 0.31671443829933804\n",
      "Epoch 7/10, Average Loss: 0.32507417102654773\n",
      "Epoch 8/10, Average Loss: 0.3783993199467659\n",
      "Epoch 9/10, Average Loss: 0.28102953483661014\n",
      "Epoch 10/10, Average Loss: 0.22736654554804167\n",
      "Epoch 1/15, Average Loss: 0.7169765134652456\n",
      "Epoch 2/15, Average Loss: 0.5746778547763824\n",
      "Epoch 3/15, Average Loss: 0.47384462257226306\n",
      "Epoch 4/15, Average Loss: 0.49100759625434875\n",
      "Epoch 5/15, Average Loss: 0.41167424867550534\n",
      "Epoch 6/15, Average Loss: 0.31671443829933804\n",
      "Epoch 7/15, Average Loss: 0.32507417102654773\n",
      "Epoch 8/15, Average Loss: 0.3783993199467659\n",
      "Epoch 9/15, Average Loss: 0.28102953483661014\n",
      "Epoch 10/15, Average Loss: 0.22736654554804167\n",
      "Epoch 11/15, Average Loss: 0.3205835285286109\n",
      "Epoch 12/15, Average Loss: 0.2556666284799576\n",
      "Epoch 13/15, Average Loss: 0.21405363952120146\n",
      "Epoch 14/15, Average Loss: 0.2725590728223324\n",
      "Epoch 15/15, Average Loss: 0.22123626122872034\n",
      "Epoch 1/10, Average Loss: 0.7169765134652456\n",
      "Epoch 2/10, Average Loss: 0.5746778547763824\n",
      "Epoch 3/10, Average Loss: 0.47384462257226306\n",
      "Epoch 4/10, Average Loss: 0.49100759625434875\n",
      "Epoch 5/10, Average Loss: 0.41167424867550534\n",
      "Epoch 6/10, Average Loss: 0.31671443829933804\n",
      "Epoch 7/10, Average Loss: 0.32507417102654773\n",
      "Epoch 8/10, Average Loss: 0.3783993199467659\n",
      "Epoch 9/10, Average Loss: 0.28102953483661014\n",
      "Epoch 10/10, Average Loss: 0.22736654554804167\n",
      "Epoch 1/15, Average Loss: 0.7169765134652456\n",
      "Epoch 2/15, Average Loss: 0.5746778547763824\n",
      "Epoch 3/15, Average Loss: 0.47384462257226306\n",
      "Epoch 4/15, Average Loss: 0.49100759625434875\n",
      "Epoch 5/15, Average Loss: 0.41167424867550534\n",
      "Epoch 6/15, Average Loss: 0.31671443829933804\n",
      "Epoch 7/15, Average Loss: 0.32507417102654773\n",
      "Epoch 8/15, Average Loss: 0.3783993199467659\n",
      "Epoch 9/15, Average Loss: 0.28102953483661014\n",
      "Epoch 10/15, Average Loss: 0.22736654554804167\n",
      "Epoch 11/15, Average Loss: 0.3205835285286109\n",
      "Epoch 12/15, Average Loss: 0.2556666284799576\n",
      "Epoch 13/15, Average Loss: 0.21405363952120146\n",
      "Epoch 14/15, Average Loss: 0.2725590728223324\n",
      "Epoch 15/15, Average Loss: 0.22123626122872034\n",
      "Epoch 1/10, Average Loss: 0.6756426692008972\n",
      "Epoch 2/10, Average Loss: 0.6646485527356466\n",
      "Epoch 3/10, Average Loss: 0.6595459779103597\n",
      "Epoch 4/10, Average Loss: 0.6507778664429983\n",
      "Epoch 5/10, Average Loss: 0.6186901231606802\n",
      "Epoch 6/10, Average Loss: 0.5308168530464172\n",
      "Epoch 7/10, Average Loss: 0.43908080955346424\n",
      "Epoch 8/10, Average Loss: 0.3876733233531316\n",
      "Epoch 9/10, Average Loss: 0.33672842383384705\n",
      "Epoch 10/10, Average Loss: 0.3144935096303622\n",
      "Epoch 1/15, Average Loss: 0.6756426692008972\n",
      "Epoch 2/15, Average Loss: 0.6646485527356466\n",
      "Epoch 3/15, Average Loss: 0.6595459779103597\n",
      "Epoch 4/15, Average Loss: 0.6507778664429983\n",
      "Epoch 5/15, Average Loss: 0.6186901231606802\n",
      "Epoch 6/15, Average Loss: 0.5308168530464172\n",
      "Epoch 7/15, Average Loss: 0.43908080955346424\n",
      "Epoch 8/15, Average Loss: 0.3876733233531316\n",
      "Epoch 9/15, Average Loss: 0.33672842383384705\n",
      "Epoch 10/15, Average Loss: 0.3144935096303622\n",
      "Epoch 11/15, Average Loss: 0.2880452200770378\n",
      "Epoch 12/15, Average Loss: 0.27718453854322433\n",
      "Epoch 13/15, Average Loss: 0.26172131796677905\n",
      "Epoch 14/15, Average Loss: 0.2571590964992841\n",
      "Epoch 15/15, Average Loss: 0.24738190323114395\n",
      "Epoch 1/10, Average Loss: 0.6756426692008972\n",
      "Epoch 2/10, Average Loss: 0.6646485527356466\n",
      "Epoch 3/10, Average Loss: 0.6595459779103597\n",
      "Epoch 4/10, Average Loss: 0.6507778664429983\n",
      "Epoch 5/10, Average Loss: 0.6186901231606802\n",
      "Epoch 6/10, Average Loss: 0.5308168530464172\n",
      "Epoch 7/10, Average Loss: 0.43908080955346424\n",
      "Epoch 8/10, Average Loss: 0.3876733233531316\n",
      "Epoch 9/10, Average Loss: 0.33672842383384705\n",
      "Epoch 10/10, Average Loss: 0.3144935096303622\n",
      "Epoch 1/15, Average Loss: 0.6756426692008972\n",
      "Epoch 2/15, Average Loss: 0.6646485527356466\n",
      "Epoch 3/15, Average Loss: 0.6595459779103597\n",
      "Epoch 4/15, Average Loss: 0.6507778664429983\n",
      "Epoch 5/15, Average Loss: 0.6186901231606802\n",
      "Epoch 6/15, Average Loss: 0.5308168530464172\n",
      "Epoch 7/15, Average Loss: 0.43908080955346424\n",
      "Epoch 8/15, Average Loss: 0.3876733233531316\n",
      "Epoch 9/15, Average Loss: 0.33672842383384705\n",
      "Epoch 10/15, Average Loss: 0.3144935096303622\n",
      "Epoch 11/15, Average Loss: 0.2880452200770378\n",
      "Epoch 12/15, Average Loss: 0.27718453854322433\n",
      "Epoch 13/15, Average Loss: 0.26172131796677905\n",
      "Epoch 14/15, Average Loss: 0.2571590964992841\n",
      "Epoch 15/15, Average Loss: 0.24738190323114395\n",
      "Epoch 1/10, Average Loss: 6.773732205231984\n",
      "Epoch 2/10, Average Loss: 4.018434405326843\n",
      "Epoch 3/10, Average Loss: 2.007512936989466\n",
      "Epoch 4/10, Average Loss: 1.499706506729126\n",
      "Epoch 5/10, Average Loss: 0.6650497366984686\n",
      "Epoch 6/10, Average Loss: 0.7141802956660589\n",
      "Epoch 7/10, Average Loss: 0.6037276039520899\n",
      "Epoch 8/10, Average Loss: 0.40288593868414563\n",
      "Epoch 9/10, Average Loss: 0.22095875442028046\n",
      "Epoch 10/10, Average Loss: 0.2620629755159219\n",
      "Epoch 1/15, Average Loss: 6.773732205231984\n",
      "Epoch 2/15, Average Loss: 4.018434405326843\n",
      "Epoch 3/15, Average Loss: 2.007512936989466\n",
      "Epoch 4/15, Average Loss: 1.499706506729126\n",
      "Epoch 5/15, Average Loss: 0.6650497366984686\n",
      "Epoch 6/15, Average Loss: 0.7141802956660589\n",
      "Epoch 7/15, Average Loss: 0.6037276039520899\n",
      "Epoch 8/15, Average Loss: 0.40288593868414563\n",
      "Epoch 9/15, Average Loss: 0.22095875442028046\n",
      "Epoch 10/15, Average Loss: 0.2620629755159219\n",
      "Epoch 11/15, Average Loss: 0.40768058349688846\n",
      "Epoch 12/15, Average Loss: 0.38734786957502365\n",
      "Epoch 13/15, Average Loss: 0.2638732021053632\n",
      "Epoch 14/15, Average Loss: 0.20991994316379228\n",
      "Epoch 15/15, Average Loss: 0.17325850079456964\n",
      "Epoch 1/10, Average Loss: 6.773732205231984\n",
      "Epoch 2/10, Average Loss: 4.018434405326843\n",
      "Epoch 3/10, Average Loss: 2.007512936989466\n",
      "Epoch 4/10, Average Loss: 1.499706506729126\n",
      "Epoch 5/10, Average Loss: 0.6650497366984686\n",
      "Epoch 6/10, Average Loss: 0.7141802956660589\n",
      "Epoch 7/10, Average Loss: 0.6037276039520899\n",
      "Epoch 8/10, Average Loss: 0.40288593868414563\n",
      "Epoch 9/10, Average Loss: 0.22095875442028046\n",
      "Epoch 10/10, Average Loss: 0.2620629755159219\n",
      "Epoch 1/15, Average Loss: 6.773732205231984\n",
      "Epoch 2/15, Average Loss: 4.018434405326843\n",
      "Epoch 3/15, Average Loss: 2.007512936989466\n",
      "Epoch 4/15, Average Loss: 1.499706506729126\n",
      "Epoch 5/15, Average Loss: 0.6650497366984686\n",
      "Epoch 6/15, Average Loss: 0.7141802956660589\n",
      "Epoch 7/15, Average Loss: 0.6037276039520899\n",
      "Epoch 8/15, Average Loss: 0.40288593868414563\n",
      "Epoch 9/15, Average Loss: 0.22095875442028046\n",
      "Epoch 10/15, Average Loss: 0.2620629755159219\n",
      "Epoch 11/15, Average Loss: 0.40768058349688846\n",
      "Epoch 12/15, Average Loss: 0.38734786957502365\n",
      "Epoch 13/15, Average Loss: 0.2638732021053632\n",
      "Epoch 14/15, Average Loss: 0.20991994316379228\n",
      "Epoch 15/15, Average Loss: 0.17325850079456964\n",
      "Epoch 1/10, Average Loss: 0.8128066658973694\n",
      "Epoch 2/10, Average Loss: 0.6831894516944885\n",
      "Epoch 3/10, Average Loss: 0.6026290853818258\n",
      "Epoch 4/10, Average Loss: 0.6084774732589722\n",
      "Epoch 5/10, Average Loss: 0.581465482711792\n",
      "Epoch 6/10, Average Loss: 0.5671104590098063\n",
      "Epoch 7/10, Average Loss: 0.564067671696345\n",
      "Epoch 8/10, Average Loss: 0.5438016951084137\n",
      "Epoch 9/10, Average Loss: 0.5356756647427877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Average Loss: 0.528020516037941\n",
      "Epoch 1/15, Average Loss: 0.8128066658973694\n",
      "Epoch 2/15, Average Loss: 0.6831894516944885\n",
      "Epoch 3/15, Average Loss: 0.6026290853818258\n",
      "Epoch 4/15, Average Loss: 0.6084774732589722\n",
      "Epoch 5/15, Average Loss: 0.581465482711792\n",
      "Epoch 6/15, Average Loss: 0.5671104590098063\n",
      "Epoch 7/15, Average Loss: 0.564067671696345\n",
      "Epoch 8/15, Average Loss: 0.5438016951084137\n",
      "Epoch 9/15, Average Loss: 0.5356756647427877\n",
      "Epoch 10/15, Average Loss: 0.528020516037941\n",
      "Epoch 11/15, Average Loss: 0.5085686445236206\n",
      "Epoch 12/15, Average Loss: 0.4716069499651591\n",
      "Epoch 13/15, Average Loss: 0.46406584481398266\n",
      "Epoch 14/15, Average Loss: 0.45526200036207837\n",
      "Epoch 15/15, Average Loss: 0.43859848380088806\n",
      "Epoch 1/10, Average Loss: 0.8128066658973694\n",
      "Epoch 2/10, Average Loss: 0.6831894516944885\n",
      "Epoch 3/10, Average Loss: 0.6026290853818258\n",
      "Epoch 4/10, Average Loss: 0.6084774732589722\n",
      "Epoch 5/10, Average Loss: 0.581465482711792\n",
      "Epoch 6/10, Average Loss: 0.5671104590098063\n",
      "Epoch 7/10, Average Loss: 0.564067671696345\n",
      "Epoch 8/10, Average Loss: 0.5438016951084137\n",
      "Epoch 9/10, Average Loss: 0.5356756647427877\n",
      "Epoch 10/10, Average Loss: 0.528020516037941\n",
      "Epoch 1/15, Average Loss: 0.8128066658973694\n",
      "Epoch 2/15, Average Loss: 0.6831894516944885\n",
      "Epoch 3/15, Average Loss: 0.6026290853818258\n",
      "Epoch 4/15, Average Loss: 0.6084774732589722\n",
      "Epoch 5/15, Average Loss: 0.581465482711792\n",
      "Epoch 6/15, Average Loss: 0.5671104590098063\n",
      "Epoch 7/15, Average Loss: 0.564067671696345\n",
      "Epoch 8/15, Average Loss: 0.5438016951084137\n",
      "Epoch 9/15, Average Loss: 0.5356756647427877\n",
      "Epoch 10/15, Average Loss: 0.528020516037941\n",
      "Epoch 11/15, Average Loss: 0.5085686445236206\n",
      "Epoch 12/15, Average Loss: 0.4716069499651591\n",
      "Epoch 13/15, Average Loss: 0.46406584481398266\n",
      "Epoch 14/15, Average Loss: 0.45526200036207837\n",
      "Epoch 15/15, Average Loss: 0.43859848380088806\n",
      "Epoch 1/10, Average Loss: 0.33090905211142546\n",
      "Epoch 2/10, Average Loss: 0.32768635471686\n",
      "Epoch 3/10, Average Loss: 0.327213676422111\n",
      "Epoch 4/10, Average Loss: 0.3280542928255299\n",
      "Epoch 5/10, Average Loss: 0.32849315527139356\n",
      "Epoch 6/10, Average Loss: 0.32820502676937763\n",
      "Epoch 7/10, Average Loss: 0.3284298519956545\n",
      "Epoch 8/10, Average Loss: 0.3284010060674068\n",
      "Epoch 9/10, Average Loss: 0.3283500720249507\n",
      "Epoch 10/10, Average Loss: 0.3283919007888118\n",
      "Epoch 1/15, Average Loss: 0.33090905211142546\n",
      "Epoch 2/15, Average Loss: 0.32768635471686\n",
      "Epoch 3/15, Average Loss: 0.327213676422111\n",
      "Epoch 4/15, Average Loss: 0.3280542928255299\n",
      "Epoch 5/15, Average Loss: 0.32849315527139356\n",
      "Epoch 6/15, Average Loss: 0.32820502676937763\n",
      "Epoch 7/15, Average Loss: 0.3284298519956545\n",
      "Epoch 8/15, Average Loss: 0.3284010060674068\n",
      "Epoch 9/15, Average Loss: 0.3283500720249507\n",
      "Epoch 10/15, Average Loss: 0.3283919007888118\n",
      "Epoch 11/15, Average Loss: 0.3283816939635763\n",
      "Epoch 12/15, Average Loss: 0.32837849001499636\n",
      "Epoch 13/15, Average Loss: 0.3283782474696636\n",
      "Epoch 14/15, Average Loss: 0.32838686461949235\n",
      "Epoch 15/15, Average Loss: 0.3283778346387796\n",
      "Epoch 1/10, Average Loss: 0.33090905211142546\n",
      "Epoch 2/10, Average Loss: 0.32768635471686\n",
      "Epoch 3/10, Average Loss: 0.327213676422111\n",
      "Epoch 4/10, Average Loss: 0.3280542928255299\n",
      "Epoch 5/10, Average Loss: 0.32849315527139356\n",
      "Epoch 6/10, Average Loss: 0.32820502676937763\n",
      "Epoch 7/10, Average Loss: 0.3284298519956545\n",
      "Epoch 8/10, Average Loss: 0.3284010060674068\n",
      "Epoch 9/10, Average Loss: 0.3283500720249507\n",
      "Epoch 10/10, Average Loss: 0.3283919007888118\n",
      "Epoch 1/15, Average Loss: 0.33090905211142546\n",
      "Epoch 2/15, Average Loss: 0.32768635471686\n",
      "Epoch 3/15, Average Loss: 0.327213676422111\n",
      "Epoch 4/15, Average Loss: 0.3280542928255299\n",
      "Epoch 5/15, Average Loss: 0.32849315527139356\n",
      "Epoch 6/15, Average Loss: 0.32820502676937763\n",
      "Epoch 7/15, Average Loss: 0.3284298519956545\n",
      "Epoch 8/15, Average Loss: 0.3284010060674068\n",
      "Epoch 9/15, Average Loss: 0.3283500720249507\n",
      "Epoch 10/15, Average Loss: 0.3283919007888118\n",
      "Epoch 11/15, Average Loss: 0.3283816939635763\n",
      "Epoch 12/15, Average Loss: 0.32837849001499636\n",
      "Epoch 13/15, Average Loss: 0.3283782474696636\n",
      "Epoch 14/15, Average Loss: 0.32838686461949235\n",
      "Epoch 15/15, Average Loss: 0.3283778346387796\n",
      "Epoch 1/10, Average Loss: 0.33680967414408053\n",
      "Epoch 2/10, Average Loss: 0.3203045994766708\n",
      "Epoch 3/10, Average Loss: 0.3201945049742472\n",
      "Epoch 4/10, Average Loss: 0.3200707459044688\n",
      "Epoch 5/10, Average Loss: 0.31996861719390723\n",
      "Epoch 6/10, Average Loss: 0.31988564222617055\n",
      "Epoch 7/10, Average Loss: 0.3198323784884319\n",
      "Epoch 8/10, Average Loss: 0.3197864885396749\n",
      "Epoch 9/10, Average Loss: 0.31974065036160276\n",
      "Epoch 10/10, Average Loss: 0.31969361647384836\n",
      "Epoch 1/15, Average Loss: 0.33680967414408053\n",
      "Epoch 2/15, Average Loss: 0.3203045994766708\n",
      "Epoch 3/15, Average Loss: 0.3201945049742472\n",
      "Epoch 4/15, Average Loss: 0.3200707459044688\n",
      "Epoch 5/15, Average Loss: 0.31996861719390723\n",
      "Epoch 6/15, Average Loss: 0.31988564222617055\n",
      "Epoch 7/15, Average Loss: 0.3198323784884319\n",
      "Epoch 8/15, Average Loss: 0.3197864885396749\n",
      "Epoch 9/15, Average Loss: 0.31974065036160276\n",
      "Epoch 10/15, Average Loss: 0.31969361647384836\n",
      "Epoch 11/15, Average Loss: 0.31967262936737934\n",
      "Epoch 12/15, Average Loss: 0.3196477955767831\n",
      "Epoch 13/15, Average Loss: 0.31962714994561325\n",
      "Epoch 14/15, Average Loss: 0.3196183377460947\n",
      "Epoch 15/15, Average Loss: 0.31961035384859854\n",
      "Epoch 1/10, Average Loss: 0.33680967414408053\n",
      "Epoch 2/10, Average Loss: 0.3203045994766708\n",
      "Epoch 3/10, Average Loss: 0.3201945049742472\n",
      "Epoch 4/10, Average Loss: 0.3200707459044688\n",
      "Epoch 5/10, Average Loss: 0.31996861719390723\n",
      "Epoch 6/10, Average Loss: 0.31988564222617055\n",
      "Epoch 7/10, Average Loss: 0.3198323784884319\n",
      "Epoch 8/10, Average Loss: 0.3197864885396749\n",
      "Epoch 9/10, Average Loss: 0.31974065036160276\n",
      "Epoch 10/10, Average Loss: 0.31969361647384836\n",
      "Epoch 1/15, Average Loss: 0.33680967414408053\n",
      "Epoch 2/15, Average Loss: 0.3203045994766708\n",
      "Epoch 3/15, Average Loss: 0.3201945049742472\n",
      "Epoch 4/15, Average Loss: 0.3200707459044688\n",
      "Epoch 5/15, Average Loss: 0.31996861719390723\n",
      "Epoch 6/15, Average Loss: 0.31988564222617055\n",
      "Epoch 7/15, Average Loss: 0.3198323784884319\n",
      "Epoch 8/15, Average Loss: 0.3197864885396749\n",
      "Epoch 9/15, Average Loss: 0.31974065036160276\n",
      "Epoch 10/15, Average Loss: 0.31969361647384836\n",
      "Epoch 11/15, Average Loss: 0.31967262936737934\n",
      "Epoch 12/15, Average Loss: 0.3196477955767831\n",
      "Epoch 13/15, Average Loss: 0.31962714994561325\n",
      "Epoch 14/15, Average Loss: 0.3196183377460947\n",
      "Epoch 15/15, Average Loss: 0.31961035384859854\n",
      "Epoch 1/10, Average Loss: 14.151947424982891\n",
      "Epoch 2/10, Average Loss: 2.0574364300837225\n",
      "Epoch 3/10, Average Loss: 0.7442118418204788\n",
      "Epoch 4/10, Average Loss: 0.45973794475150886\n",
      "Epoch 5/10, Average Loss: 0.32554703892900344\n",
      "Epoch 6/10, Average Loss: 0.31441083868911257\n",
      "Epoch 7/10, Average Loss: 0.31894920878112315\n",
      "Epoch 8/10, Average Loss: 0.32183119829707935\n",
      "Epoch 9/10, Average Loss: 0.33429822765507744\n",
      "Epoch 10/10, Average Loss: 0.3506328809102183\n",
      "Epoch 1/15, Average Loss: 14.151947424982891\n",
      "Epoch 2/15, Average Loss: 2.0574364300837225\n",
      "Epoch 3/15, Average Loss: 0.7442118418204788\n",
      "Epoch 4/15, Average Loss: 0.45973794475150886\n",
      "Epoch 5/15, Average Loss: 0.32554703892900344\n",
      "Epoch 6/15, Average Loss: 0.31441083868911257\n",
      "Epoch 7/15, Average Loss: 0.31894920878112315\n",
      "Epoch 8/15, Average Loss: 0.32183119829707935\n",
      "Epoch 9/15, Average Loss: 0.33429822765507744\n",
      "Epoch 10/15, Average Loss: 0.3506328809102183\n",
      "Epoch 11/15, Average Loss: 0.3506433578515516\n",
      "Epoch 12/15, Average Loss: 0.35055537434312906\n",
      "Epoch 13/15, Average Loss: 0.350455629623052\n",
      "Epoch 14/15, Average Loss: 0.35036220992508443\n",
      "Epoch 15/15, Average Loss: 0.35030375881825837\n",
      "Epoch 1/10, Average Loss: 14.151947424982891\n",
      "Epoch 2/10, Average Loss: 2.0574364300837225\n",
      "Epoch 3/10, Average Loss: 0.7442118418204788\n",
      "Epoch 4/10, Average Loss: 0.45973794475150886\n",
      "Epoch 5/10, Average Loss: 0.32554703892900344\n",
      "Epoch 6/10, Average Loss: 0.31441083868911257\n",
      "Epoch 7/10, Average Loss: 0.31894920878112315\n",
      "Epoch 8/10, Average Loss: 0.32183119829707935\n",
      "Epoch 9/10, Average Loss: 0.33429822765507744\n",
      "Epoch 10/10, Average Loss: 0.3506328809102183\n",
      "Epoch 1/15, Average Loss: 14.151947424982891\n",
      "Epoch 2/15, Average Loss: 2.0574364300837225\n",
      "Epoch 3/15, Average Loss: 0.7442118418204788\n",
      "Epoch 4/15, Average Loss: 0.45973794475150886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/15, Average Loss: 0.32554703892900344\n",
      "Epoch 6/15, Average Loss: 0.31441083868911257\n",
      "Epoch 7/15, Average Loss: 0.31894920878112315\n",
      "Epoch 8/15, Average Loss: 0.32183119829707935\n",
      "Epoch 9/15, Average Loss: 0.33429822765507744\n",
      "Epoch 10/15, Average Loss: 0.3506328809102183\n",
      "Epoch 11/15, Average Loss: 0.3506433578515516\n",
      "Epoch 12/15, Average Loss: 0.35055537434312906\n",
      "Epoch 13/15, Average Loss: 0.350455629623052\n",
      "Epoch 14/15, Average Loss: 0.35036220992508443\n",
      "Epoch 15/15, Average Loss: 0.35030375881825837\n",
      "Epoch 1/10, Average Loss: 5.5405291947448685\n",
      "Epoch 2/10, Average Loss: 2.752882260165062\n",
      "Epoch 3/10, Average Loss: 2.1771973654129253\n",
      "Epoch 4/10, Average Loss: 1.8716167330812523\n",
      "Epoch 5/10, Average Loss: 2.422839765288852\n",
      "Epoch 6/10, Average Loss: 1.8085828310284378\n",
      "Epoch 7/10, Average Loss: 1.98093881867435\n",
      "Epoch 8/10, Average Loss: 1.9040547810870319\n",
      "Epoch 9/10, Average Loss: 1.9979055106412462\n",
      "Epoch 10/10, Average Loss: 1.7279514920587051\n",
      "Epoch 1/15, Average Loss: 5.5405291947448685\n",
      "Epoch 2/15, Average Loss: 2.752882260165062\n",
      "Epoch 3/15, Average Loss: 2.1771973654129253\n",
      "Epoch 4/15, Average Loss: 1.8716167330812523\n",
      "Epoch 5/15, Average Loss: 2.422839765288852\n",
      "Epoch 6/15, Average Loss: 1.8085828310284378\n",
      "Epoch 7/15, Average Loss: 1.98093881867435\n",
      "Epoch 8/15, Average Loss: 1.9040547810870319\n",
      "Epoch 9/15, Average Loss: 1.9979055106412462\n",
      "Epoch 10/15, Average Loss: 1.7279514920587051\n",
      "Epoch 11/15, Average Loss: 1.603527196818915\n",
      "Epoch 12/15, Average Loss: 1.5469970123208825\n",
      "Epoch 13/15, Average Loss: 1.5395225785904612\n",
      "Epoch 14/15, Average Loss: 1.4076927365408463\n",
      "Epoch 15/15, Average Loss: 1.3856798120745726\n",
      "Epoch 1/10, Average Loss: 5.5405291947448685\n",
      "Epoch 2/10, Average Loss: 2.752882260165062\n",
      "Epoch 3/10, Average Loss: 2.1771973654129253\n",
      "Epoch 4/10, Average Loss: 1.8716167330812523\n",
      "Epoch 5/10, Average Loss: 2.422839765288852\n",
      "Epoch 6/10, Average Loss: 1.8085828310284378\n",
      "Epoch 7/10, Average Loss: 1.98093881867435\n",
      "Epoch 8/10, Average Loss: 1.9040547810870319\n",
      "Epoch 9/10, Average Loss: 1.9979055106412462\n",
      "Epoch 10/10, Average Loss: 1.7279514920587051\n",
      "Epoch 1/15, Average Loss: 5.5405291947448685\n",
      "Epoch 2/15, Average Loss: 2.752882260165062\n",
      "Epoch 3/15, Average Loss: 2.1771973654129253\n",
      "Epoch 4/15, Average Loss: 1.8716167330812523\n",
      "Epoch 5/15, Average Loss: 2.422839765288852\n",
      "Epoch 6/15, Average Loss: 1.8085828310284378\n",
      "Epoch 7/15, Average Loss: 1.98093881867435\n",
      "Epoch 8/15, Average Loss: 1.9040547810870319\n",
      "Epoch 9/15, Average Loss: 1.9979055106412462\n",
      "Epoch 10/15, Average Loss: 1.7279514920587051\n",
      "Epoch 11/15, Average Loss: 1.603527196818915\n",
      "Epoch 12/15, Average Loss: 1.5469970123208825\n",
      "Epoch 13/15, Average Loss: 1.5395225785904612\n",
      "Epoch 14/15, Average Loss: 1.4076927365408463\n",
      "Epoch 15/15, Average Loss: 1.3856798120745726\n",
      "Epoch 1/10, Average Loss: 0.3601578785233127\n",
      "Epoch 2/10, Average Loss: 0.3574882444789977\n",
      "Epoch 3/10, Average Loss: 0.3574025348443719\n",
      "Epoch 4/10, Average Loss: 0.3584608149362131\n",
      "Epoch 5/10, Average Loss: 0.3583966089430654\n",
      "Epoch 6/10, Average Loss: 0.3589774876326612\n",
      "Epoch 7/10, Average Loss: 0.3589971988633709\n",
      "Epoch 8/10, Average Loss: 0.3588774196550395\n",
      "Epoch 9/10, Average Loss: 0.3590278476585173\n",
      "Epoch 10/10, Average Loss: 0.3589931580626849\n",
      "Epoch 1/15, Average Loss: 0.3601578785233127\n",
      "Epoch 2/15, Average Loss: 0.3574882444789977\n",
      "Epoch 3/15, Average Loss: 0.3574025348443719\n",
      "Epoch 4/15, Average Loss: 0.3584608149362131\n",
      "Epoch 5/15, Average Loss: 0.3583966089430654\n",
      "Epoch 6/15, Average Loss: 0.3589774876326612\n",
      "Epoch 7/15, Average Loss: 0.3589971988633709\n",
      "Epoch 8/15, Average Loss: 0.3588774196550395\n",
      "Epoch 9/15, Average Loss: 0.3590278476585173\n",
      "Epoch 10/15, Average Loss: 0.3589931580626849\n",
      "Epoch 11/15, Average Loss: 0.3589714381373623\n",
      "Epoch 12/15, Average Loss: 0.3589322879838133\n",
      "Epoch 13/15, Average Loss: 0.3590103122034987\n",
      "Epoch 14/15, Average Loss: 0.358968199214455\n",
      "Epoch 15/15, Average Loss: 0.35895531266132025\n",
      "Epoch 1/10, Average Loss: 0.3601578785233127\n",
      "Epoch 2/10, Average Loss: 0.3574882444789977\n",
      "Epoch 3/10, Average Loss: 0.3574025348443719\n",
      "Epoch 4/10, Average Loss: 0.3584608149362131\n",
      "Epoch 5/10, Average Loss: 0.3583966089430654\n",
      "Epoch 6/10, Average Loss: 0.3589774876326612\n",
      "Epoch 7/10, Average Loss: 0.3589971988633709\n",
      "Epoch 8/10, Average Loss: 0.3588774196550395\n",
      "Epoch 9/10, Average Loss: 0.3590278476585173\n",
      "Epoch 10/10, Average Loss: 0.3589931580626849\n",
      "Epoch 1/15, Average Loss: 0.3601578785233127\n",
      "Epoch 2/15, Average Loss: 0.3574882444789977\n",
      "Epoch 3/15, Average Loss: 0.3574025348443719\n",
      "Epoch 4/15, Average Loss: 0.3584608149362131\n",
      "Epoch 5/15, Average Loss: 0.3583966089430654\n",
      "Epoch 6/15, Average Loss: 0.3589774876326612\n",
      "Epoch 7/15, Average Loss: 0.3589971988633709\n",
      "Epoch 8/15, Average Loss: 0.3588774196550395\n",
      "Epoch 9/15, Average Loss: 0.3590278476585173\n",
      "Epoch 10/15, Average Loss: 0.3589931580626849\n",
      "Epoch 11/15, Average Loss: 0.3589714381373623\n",
      "Epoch 12/15, Average Loss: 0.3589322879838133\n",
      "Epoch 13/15, Average Loss: 0.3590103122034987\n",
      "Epoch 14/15, Average Loss: 0.358968199214455\n",
      "Epoch 15/15, Average Loss: 0.35895531266132025\n",
      "Epoch 1/10, Average Loss: 0.35363060480471953\n",
      "Epoch 2/10, Average Loss: 0.3512944309890849\n",
      "Epoch 3/10, Average Loss: 0.3509477594885433\n",
      "Epoch 4/10, Average Loss: 0.3507528666370702\n",
      "Epoch 5/10, Average Loss: 0.3506372634140612\n",
      "Epoch 6/10, Average Loss: 0.35058665624231966\n",
      "Epoch 7/10, Average Loss: 0.35049330134993617\n",
      "Epoch 8/10, Average Loss: 0.35050407768163866\n",
      "Epoch 9/10, Average Loss: 0.35045688720148743\n",
      "Epoch 10/10, Average Loss: 0.35044780754782623\n",
      "Epoch 1/15, Average Loss: 0.35363060480471953\n",
      "Epoch 2/15, Average Loss: 0.3512944309890849\n",
      "Epoch 3/15, Average Loss: 0.3509477594885433\n",
      "Epoch 4/15, Average Loss: 0.3507528666370702\n",
      "Epoch 5/15, Average Loss: 0.3506372634140612\n",
      "Epoch 6/15, Average Loss: 0.35058665624231966\n",
      "Epoch 7/15, Average Loss: 0.35049330134993617\n",
      "Epoch 8/15, Average Loss: 0.35050407768163866\n",
      "Epoch 9/15, Average Loss: 0.35045688720148743\n",
      "Epoch 10/15, Average Loss: 0.35044780754782623\n",
      "Epoch 11/15, Average Loss: 0.35044185943105843\n",
      "Epoch 12/15, Average Loss: 0.35041693788998335\n",
      "Epoch 13/15, Average Loss: 0.35041490582731166\n",
      "Epoch 14/15, Average Loss: 0.3504166523085057\n",
      "Epoch 15/15, Average Loss: 0.35040439956107183\n",
      "Epoch 1/10, Average Loss: 0.35363060480471953\n",
      "Epoch 2/10, Average Loss: 0.3512944309890849\n",
      "Epoch 3/10, Average Loss: 0.3509477594885433\n",
      "Epoch 4/10, Average Loss: 0.3507528666370702\n",
      "Epoch 5/10, Average Loss: 0.3506372634140612\n",
      "Epoch 6/10, Average Loss: 0.35058665624231966\n",
      "Epoch 7/10, Average Loss: 0.35049330134993617\n",
      "Epoch 8/10, Average Loss: 0.35050407768163866\n",
      "Epoch 9/10, Average Loss: 0.35045688720148743\n",
      "Epoch 10/10, Average Loss: 0.35044780754782623\n",
      "Epoch 1/15, Average Loss: 0.35363060480471953\n",
      "Epoch 2/15, Average Loss: 0.3512944309890849\n",
      "Epoch 3/15, Average Loss: 0.3509477594885433\n",
      "Epoch 4/15, Average Loss: 0.3507528666370702\n",
      "Epoch 5/15, Average Loss: 0.3506372634140612\n",
      "Epoch 6/15, Average Loss: 0.35058665624231966\n",
      "Epoch 7/15, Average Loss: 0.35049330134993617\n",
      "Epoch 8/15, Average Loss: 0.35050407768163866\n",
      "Epoch 9/15, Average Loss: 0.35045688720148743\n",
      "Epoch 10/15, Average Loss: 0.35044780754782623\n",
      "Epoch 11/15, Average Loss: 0.35044185943105843\n",
      "Epoch 12/15, Average Loss: 0.35041693788998335\n",
      "Epoch 13/15, Average Loss: 0.35041490582731166\n",
      "Epoch 14/15, Average Loss: 0.3504166523085057\n",
      "Epoch 15/15, Average Loss: 0.35040439956107183\n",
      "Epoch 1/10, Average Loss: 4.014158828241413\n",
      "Epoch 2/10, Average Loss: 0.35046567689735914\n",
      "Epoch 3/10, Average Loss: 0.3504493251008895\n",
      "Epoch 4/10, Average Loss: 0.3504767712892838\n",
      "Epoch 5/10, Average Loss: 0.3504932030167395\n",
      "Epoch 6/10, Average Loss: 0.35050492353231005\n",
      "Epoch 7/10, Average Loss: 0.35051325668119687\n",
      "Epoch 8/10, Average Loss: 0.35050456835662275\n",
      "Epoch 9/10, Average Loss: 0.35046399449115817\n",
      "Epoch 10/10, Average Loss: 0.35040467370626993\n",
      "Epoch 1/15, Average Loss: 4.014158828241413\n",
      "Epoch 2/15, Average Loss: 0.35046567689735914\n",
      "Epoch 3/15, Average Loss: 0.3504493251008895\n",
      "Epoch 4/15, Average Loss: 0.3504767712892838\n",
      "Epoch 5/15, Average Loss: 0.3504932030167395\n",
      "Epoch 6/15, Average Loss: 0.35050492353231005\n",
      "Epoch 7/15, Average Loss: 0.35051325668119687\n",
      "Epoch 8/15, Average Loss: 0.35050456835662275\n",
      "Epoch 9/15, Average Loss: 0.35046399449115817\n",
      "Epoch 10/15, Average Loss: 0.35040467370626993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/15, Average Loss: 0.3503446742747594\n",
      "Epoch 12/15, Average Loss: 0.3502924434551336\n",
      "Epoch 13/15, Average Loss: 0.3502500360596527\n",
      "Epoch 14/15, Average Loss: 0.350221598893404\n",
      "Epoch 15/15, Average Loss: 0.3502073515098072\n",
      "Epoch 1/10, Average Loss: 4.014158828241413\n",
      "Epoch 2/10, Average Loss: 0.35046567689735914\n",
      "Epoch 3/10, Average Loss: 0.3504493251008895\n",
      "Epoch 4/10, Average Loss: 0.3504767712892838\n",
      "Epoch 5/10, Average Loss: 0.3504932030167395\n",
      "Epoch 6/10, Average Loss: 0.35050492353231005\n",
      "Epoch 7/10, Average Loss: 0.35051325668119687\n",
      "Epoch 8/10, Average Loss: 0.35050456835662275\n",
      "Epoch 9/10, Average Loss: 0.35046399449115817\n",
      "Epoch 10/10, Average Loss: 0.35040467370626993\n",
      "Epoch 1/15, Average Loss: 4.014158828241413\n",
      "Epoch 2/15, Average Loss: 0.35046567689735914\n",
      "Epoch 3/15, Average Loss: 0.3504493251008895\n",
      "Epoch 4/15, Average Loss: 0.3504767712892838\n",
      "Epoch 5/15, Average Loss: 0.3504932030167395\n",
      "Epoch 6/15, Average Loss: 0.35050492353231005\n",
      "Epoch 7/15, Average Loss: 0.35051325668119687\n",
      "Epoch 8/15, Average Loss: 0.35050456835662275\n",
      "Epoch 9/15, Average Loss: 0.35046399449115817\n",
      "Epoch 10/15, Average Loss: 0.35040467370626993\n",
      "Epoch 11/15, Average Loss: 0.3503446742747594\n",
      "Epoch 12/15, Average Loss: 0.3502924434551336\n",
      "Epoch 13/15, Average Loss: 0.3502500360596527\n",
      "Epoch 14/15, Average Loss: 0.350221598893404\n",
      "Epoch 15/15, Average Loss: 0.3502073515098072\n",
      "Epoch 1/10, Average Loss: 2.1157267201670718\n",
      "Epoch 2/10, Average Loss: 1.4267317496278706\n",
      "Epoch 3/10, Average Loss: 1.0819551537005854\n",
      "Epoch 4/10, Average Loss: 0.9648689109857832\n",
      "Epoch 5/10, Average Loss: 0.805617876205204\n",
      "Epoch 6/10, Average Loss: 0.5039244394828909\n",
      "Epoch 7/10, Average Loss: 0.43427115599650246\n",
      "Epoch 8/10, Average Loss: 0.3561864710123577\n",
      "Epoch 9/10, Average Loss: 0.33148225465409675\n",
      "Epoch 10/10, Average Loss: 0.31339073775390397\n",
      "Epoch 1/15, Average Loss: 2.1157267201670718\n",
      "Epoch 2/15, Average Loss: 1.4267317496278706\n",
      "Epoch 3/15, Average Loss: 1.0819551537005854\n",
      "Epoch 4/15, Average Loss: 0.9648689109857832\n",
      "Epoch 5/15, Average Loss: 0.805617876205204\n",
      "Epoch 6/15, Average Loss: 0.5039244394828909\n",
      "Epoch 7/15, Average Loss: 0.43427115599650246\n",
      "Epoch 8/15, Average Loss: 0.3561864710123577\n",
      "Epoch 9/15, Average Loss: 0.33148225465409675\n",
      "Epoch 10/15, Average Loss: 0.31339073775390397\n",
      "Epoch 11/15, Average Loss: 0.31074559564331494\n",
      "Epoch 12/15, Average Loss: 0.309774062341278\n",
      "Epoch 13/15, Average Loss: 0.30974213752570084\n",
      "Epoch 14/15, Average Loss: 0.31285816531592203\n",
      "Epoch 15/15, Average Loss: 0.3152166125283224\n",
      "Epoch 1/10, Average Loss: 2.1157267201670718\n",
      "Epoch 2/10, Average Loss: 1.4267317496278706\n",
      "Epoch 3/10, Average Loss: 1.0819551537005854\n",
      "Epoch 4/10, Average Loss: 0.9648689109857832\n",
      "Epoch 5/10, Average Loss: 0.805617876205204\n",
      "Epoch 6/10, Average Loss: 0.5039244394828909\n",
      "Epoch 7/10, Average Loss: 0.43427115599650246\n",
      "Epoch 8/10, Average Loss: 0.3561864710123577\n",
      "Epoch 9/10, Average Loss: 0.33148225465409675\n",
      "Epoch 10/10, Average Loss: 0.31339073775390397\n",
      "Epoch 1/15, Average Loss: 2.1157267201670718\n",
      "Epoch 2/15, Average Loss: 1.4267317496278706\n",
      "Epoch 3/15, Average Loss: 1.0819551537005854\n",
      "Epoch 4/15, Average Loss: 0.9648689109857832\n",
      "Epoch 5/15, Average Loss: 0.805617876205204\n",
      "Epoch 6/15, Average Loss: 0.5039244394828909\n",
      "Epoch 7/15, Average Loss: 0.43427115599650246\n",
      "Epoch 8/15, Average Loss: 0.3561864710123577\n",
      "Epoch 9/15, Average Loss: 0.33148225465409675\n",
      "Epoch 10/15, Average Loss: 0.31339073775390397\n",
      "Epoch 11/15, Average Loss: 0.31074559564331494\n",
      "Epoch 12/15, Average Loss: 0.309774062341278\n",
      "Epoch 13/15, Average Loss: 0.30974213752570084\n",
      "Epoch 14/15, Average Loss: 0.31285816531592203\n",
      "Epoch 15/15, Average Loss: 0.3152166125283224\n"
     ]
    }
   ],
   "source": [
    "datasets = {'wine_quality': wine_quality, 'cong_voting': cong_voting, 'bank_marketing': bank_marketing} #\n",
    "hidden_layer_sizes_list = [[25, 30], [20, 25, 30]]\n",
    "activation_functions = [F.tanh, F.relu] \n",
    "learning_rates = [0.01, 0.001]\n",
    "batch_sizes = [32, 64]\n",
    "num_epochs_list = [10, 15]\n",
    "all_results = []\n",
    "\n",
    "for dataset_name, dataset in datasets.items():\n",
    "    train_X, train_Y, test_X, test_Y = train_test_split(dataset, \"class\", return_torch=True)\n",
    "\n",
    "    train_data = TensorDataset(train_X, train_Y)\n",
    "    train_loader = DataLoader(train_data, batch_size=32, shuffle=False)\n",
    "\n",
    "    test_data = TensorDataset(test_X, test_Y)\n",
    "    test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n",
    "    \n",
    "    input_size = train_X.shape[1]\n",
    "\n",
    "    if dataset_name == 'wine_quality':\n",
    "        num_classes = 10\n",
    "    else:\n",
    "        num_classes = len(np.unique(train_Y))\n",
    "    #print(len(np.unique(train_Y)))\n",
    "\n",
    "    grid_results, best_accuracy, best_combination = grid_search(\n",
    "        hidden_layer_sizes_list, activation_functions, learning_rates, batch_sizes, num_epochs_list, train_loader, test_loader)\n",
    "\n",
    "    grid_results['dataset'] = dataset_name\n",
    "    \n",
    "    all_results.append(grid_results)\n",
    "\n",
    "grid_results_df = pd.concat(all_results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hidden Layer Sizes</th>\n",
       "      <th>Activation Function</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Batch Size</th>\n",
       "      <th>Number of Epochs</th>\n",
       "      <th>Accuracy (Train)</th>\n",
       "      <th>Accuracy (Test)</th>\n",
       "      <th>Training Time</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[25, 30]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.010</td>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>0.441324</td>\n",
       "      <td>0.447059</td>\n",
       "      <td>3.507027</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[25, 30]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.010</td>\n",
       "      <td>32</td>\n",
       "      <td>15</td>\n",
       "      <td>0.443247</td>\n",
       "      <td>0.462745</td>\n",
       "      <td>3.650189</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[25, 30]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.010</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.441324</td>\n",
       "      <td>0.447059</td>\n",
       "      <td>2.085237</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[25, 30]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.010</td>\n",
       "      <td>64</td>\n",
       "      <td>15</td>\n",
       "      <td>0.443247</td>\n",
       "      <td>0.462745</td>\n",
       "      <td>2.656608</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[25, 30]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.001</td>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>0.449211</td>\n",
       "      <td>0.453595</td>\n",
       "      <td>1.719398</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>[20, 25, 30]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.010</td>\n",
       "      <td>64</td>\n",
       "      <td>15</td>\n",
       "      <td>0.888407</td>\n",
       "      <td>0.883103</td>\n",
       "      <td>16.645287</td>\n",
       "      <td>bank_marketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>[20, 25, 30]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.001</td>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>0.898695</td>\n",
       "      <td>0.892814</td>\n",
       "      <td>11.018878</td>\n",
       "      <td>bank_marketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>[20, 25, 30]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.001</td>\n",
       "      <td>32</td>\n",
       "      <td>15</td>\n",
       "      <td>0.898695</td>\n",
       "      <td>0.892814</td>\n",
       "      <td>17.024868</td>\n",
       "      <td>bank_marketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>[20, 25, 30]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.001</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.898695</td>\n",
       "      <td>0.892814</td>\n",
       "      <td>10.937377</td>\n",
       "      <td>bank_marketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>[20, 25, 30]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.001</td>\n",
       "      <td>64</td>\n",
       "      <td>15</td>\n",
       "      <td>0.898695</td>\n",
       "      <td>0.892814</td>\n",
       "      <td>16.636869</td>\n",
       "      <td>bank_marketing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Hidden Layer Sizes Activation Function  Learning Rate  Batch Size  \\\n",
       "0            [25, 30]                tanh          0.010          32   \n",
       "1            [25, 30]                tanh          0.010          32   \n",
       "2            [25, 30]                tanh          0.010          64   \n",
       "3            [25, 30]                tanh          0.010          64   \n",
       "4            [25, 30]                tanh          0.001          32   \n",
       "..                ...                 ...            ...         ...   \n",
       "91       [20, 25, 30]                relu          0.010          64   \n",
       "92       [20, 25, 30]                relu          0.001          32   \n",
       "93       [20, 25, 30]                relu          0.001          32   \n",
       "94       [20, 25, 30]                relu          0.001          64   \n",
       "95       [20, 25, 30]                relu          0.001          64   \n",
       "\n",
       "    Number of Epochs  Accuracy (Train)  Accuracy (Test)  Training Time  \\\n",
       "0                 10          0.441324         0.447059       3.507027   \n",
       "1                 15          0.443247         0.462745       3.650189   \n",
       "2                 10          0.441324         0.447059       2.085237   \n",
       "3                 15          0.443247         0.462745       2.656608   \n",
       "4                 10          0.449211         0.453595       1.719398   \n",
       "..               ...               ...              ...            ...   \n",
       "91                15          0.888407         0.883103      16.645287   \n",
       "92                10          0.898695         0.892814      11.018878   \n",
       "93                15          0.898695         0.892814      17.024868   \n",
       "94                10          0.898695         0.892814      10.937377   \n",
       "95                15          0.898695         0.892814      16.636869   \n",
       "\n",
       "           dataset  \n",
       "0     wine_quality  \n",
       "1     wine_quality  \n",
       "2     wine_quality  \n",
       "3     wine_quality  \n",
       "4     wine_quality  \n",
       "..             ...  \n",
       "91  bank_marketing  \n",
       "92  bank_marketing  \n",
       "93  bank_marketing  \n",
       "94  bank_marketing  \n",
       "95  bank_marketing  \n",
       "\n",
       "[96 rows x 9 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Random Search over all three datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Average Loss: 1.3060762721336692\n",
      "Epoch 2/10, Average Loss: 1.277217772109377\n",
      "Epoch 3/10, Average Loss: 1.2667854095529194\n",
      "Epoch 4/10, Average Loss: 1.2539941251643596\n",
      "Epoch 5/10, Average Loss: 1.2450703005849217\n",
      "Epoch 6/10, Average Loss: 1.2147458192029614\n",
      "Epoch 7/10, Average Loss: 1.1898289940839897\n",
      "Epoch 8/10, Average Loss: 1.1940654428458652\n",
      "Epoch 9/10, Average Loss: 1.1851941292271293\n",
      "Epoch 10/10, Average Loss: 1.1793131930696452\n",
      "Epoch 1/15, Average Loss: 1.3429917122688761\n",
      "Epoch 2/15, Average Loss: 1.3290214728724006\n",
      "Epoch 3/15, Average Loss: 1.3277870789627355\n",
      "Epoch 4/15, Average Loss: 1.3282437075866511\n",
      "Epoch 5/15, Average Loss: 1.328351981800758\n",
      "Epoch 6/15, Average Loss: 1.3280822111785047\n",
      "Epoch 7/15, Average Loss: 1.328296303017739\n",
      "Epoch 8/15, Average Loss: 1.328261375427246\n",
      "Epoch 9/15, Average Loss: 1.3282252469677136\n",
      "Epoch 10/15, Average Loss: 1.3282340114102043\n",
      "Epoch 11/15, Average Loss: 1.3282237623366842\n",
      "Epoch 12/15, Average Loss: 1.328217453020482\n",
      "Epoch 13/15, Average Loss: 1.3282103450751743\n",
      "Epoch 14/15, Average Loss: 1.3282168942726462\n",
      "Epoch 15/15, Average Loss: 1.3282082526961718\n",
      "Epoch 1/5, Average Loss: 2.0591903083894882\n",
      "Epoch 2/5, Average Loss: 1.296753646405928\n",
      "Epoch 3/5, Average Loss: 1.2877575685641518\n",
      "Epoch 4/5, Average Loss: 1.2847477746156095\n",
      "Epoch 5/5, Average Loss: 1.283296399321293\n",
      "Epoch 1/10, Average Loss: 1.4160737033270618\n",
      "Epoch 2/10, Average Loss: 1.3948668614486974\n",
      "Epoch 3/10, Average Loss: 1.3981794952614908\n",
      "Epoch 4/10, Average Loss: 1.397243997070687\n",
      "Epoch 5/10, Average Loss: 1.3971111891459833\n",
      "Epoch 6/10, Average Loss: 1.3970171278971104\n",
      "Epoch 7/10, Average Loss: 1.396635824185939\n",
      "Epoch 8/10, Average Loss: 1.3973409778501358\n",
      "Epoch 9/10, Average Loss: 1.396721837710749\n",
      "Epoch 10/10, Average Loss: 1.3970513358437942\n",
      "Epoch 1/5, Average Loss: 1.3734399072963035\n",
      "Epoch 2/5, Average Loss: 1.3620069451127315\n",
      "Epoch 3/5, Average Loss: 1.3628541260409208\n",
      "Epoch 4/5, Average Loss: 1.3615356595969639\n",
      "Epoch 5/5, Average Loss: 1.3607177295567798\n",
      "Epoch 1/15, Average Loss: 2.4851778401918936\n",
      "Epoch 2/15, Average Loss: 1.2858673136658463\n",
      "Epoch 3/15, Average Loss: 1.282827281513097\n",
      "Epoch 4/15, Average Loss: 1.2820554401245585\n",
      "Epoch 5/15, Average Loss: 1.2817306730644835\n",
      "Epoch 6/15, Average Loss: 1.2815638327159764\n",
      "Epoch 7/15, Average Loss: 1.2814688309570033\n",
      "Epoch 8/15, Average Loss: 1.2814110159142618\n",
      "Epoch 9/15, Average Loss: 1.2813740515270116\n",
      "Epoch 10/15, Average Loss: 1.2813494688162774\n",
      "Epoch 11/15, Average Loss: 1.2813324950224052\n",
      "Epoch 12/15, Average Loss: 1.281320359809267\n",
      "Epoch 13/15, Average Loss: 1.2813113862020107\n",
      "Epoch 14/15, Average Loss: 1.2813045086304835\n",
      "Epoch 15/15, Average Loss: 1.2812990059881855\n",
      "Epoch 1/10, Average Loss: 3.5936522374123885\n",
      "Epoch 2/10, Average Loss: 1.5241583775888923\n",
      "Epoch 3/10, Average Loss: 1.4630733201840171\n",
      "Epoch 4/10, Average Loss: 1.3932215955359804\n",
      "Epoch 5/10, Average Loss: 1.3545105281783028\n",
      "Epoch 6/10, Average Loss: 1.3397194081288906\n",
      "Epoch 7/10, Average Loss: 1.3200074328235323\n",
      "Epoch 8/10, Average Loss: 1.3052779933426277\n",
      "Epoch 9/10, Average Loss: 1.2949170854194032\n",
      "Epoch 10/10, Average Loss: 1.2911233265707098\n",
      "Epoch 1/10, Average Loss: 2.0635517345615693\n",
      "Epoch 2/10, Average Loss: 1.2844801680442015\n",
      "Epoch 3/10, Average Loss: 1.282552741056571\n",
      "Epoch 4/10, Average Loss: 1.2815360686530364\n",
      "Epoch 5/10, Average Loss: 1.2815075578865098\n",
      "Epoch 6/10, Average Loss: 1.2816282415682554\n",
      "Epoch 7/10, Average Loss: 1.2816413319184006\n",
      "Epoch 8/10, Average Loss: 1.2815644931208137\n",
      "Epoch 9/10, Average Loss: 1.2814638212414606\n",
      "Epoch 10/10, Average Loss: 1.2814535187797311\n",
      "Epoch 1/10, Average Loss: 3.9685590596286797\n",
      "Epoch 2/10, Average Loss: 1.3622590797079122\n",
      "Epoch 3/10, Average Loss: 1.2420003995573594\n",
      "Epoch 4/10, Average Loss: 1.206690180155397\n",
      "Epoch 5/10, Average Loss: 1.1911270424632208\n",
      "Epoch 6/10, Average Loss: 1.1733428484823074\n",
      "Epoch 7/10, Average Loss: 1.1613755650315547\n",
      "Epoch 8/10, Average Loss: 1.1521685463519185\n",
      "Epoch 9/10, Average Loss: 1.1492849017944804\n",
      "Epoch 10/10, Average Loss: 1.1553398421936971\n",
      "Epoch 1/5, Average Loss: 1.361414944467369\n",
      "Epoch 2/5, Average Loss: 1.3501165315417425\n",
      "Epoch 3/5, Average Loss: 1.350257451548898\n",
      "Epoch 4/5, Average Loss: 1.3503561253927967\n",
      "Epoch 5/5, Average Loss: 1.3504389882819052\n",
      "Epoch 1/10, Average Loss: 1.047900398572286\n",
      "Epoch 2/10, Average Loss: 0.6933268904685974\n",
      "Epoch 3/10, Average Loss: 0.6554766098658243\n",
      "Epoch 4/10, Average Loss: 0.6536497374375662\n",
      "Epoch 5/10, Average Loss: 0.5385636687278748\n",
      "Epoch 6/10, Average Loss: 0.4181666473547618\n",
      "Epoch 7/10, Average Loss: 0.3660196488102277\n",
      "Epoch 8/10, Average Loss: 0.3583119064569473\n",
      "Epoch 9/10, Average Loss: 0.4804450323184331\n",
      "Epoch 10/10, Average Loss: 0.33964719374974567\n",
      "Epoch 1/15, Average Loss: 1.11462797721227\n",
      "Epoch 2/15, Average Loss: 0.7014776666959127\n",
      "Epoch 3/15, Average Loss: 0.6745800375938416\n",
      "Epoch 4/15, Average Loss: 0.6930985649426779\n",
      "Epoch 5/15, Average Loss: 0.6882595618565878\n",
      "Epoch 6/15, Average Loss: 0.6741661230723063\n",
      "Epoch 7/15, Average Loss: 0.677727073431015\n",
      "Epoch 8/15, Average Loss: 0.6851012706756592\n",
      "Epoch 9/15, Average Loss: 0.6838400562604269\n",
      "Epoch 10/15, Average Loss: 0.6799109478791555\n",
      "Epoch 11/15, Average Loss: 0.681117425362269\n",
      "Epoch 12/15, Average Loss: 0.6843588948249817\n",
      "Epoch 13/15, Average Loss: 0.6850345432758331\n",
      "Epoch 14/15, Average Loss: 0.6838367482026418\n",
      "Epoch 15/15, Average Loss: 0.6835077404975891\n",
      "Epoch 1/15, Average Loss: 1.2129787802696228\n",
      "Epoch 2/15, Average Loss: 0.7029037674268087\n",
      "Epoch 3/15, Average Loss: 0.7328406870365143\n",
      "Epoch 4/15, Average Loss: 0.692481130361557\n",
      "Epoch 5/15, Average Loss: 0.5450532684723536\n",
      "Epoch 6/15, Average Loss: 0.4590573435028394\n",
      "Epoch 7/15, Average Loss: 0.6903162201245626\n",
      "Epoch 8/15, Average Loss: 0.5223506391048431\n",
      "Epoch 9/15, Average Loss: 0.7110486825307211\n",
      "Epoch 10/15, Average Loss: 0.626443107922872\n",
      "Epoch 11/15, Average Loss: 0.5365189959605535\n",
      "Epoch 12/15, Average Loss: 0.636548121770223\n",
      "Epoch 13/15, Average Loss: 0.6660837531089783\n",
      "Epoch 14/15, Average Loss: 0.6527903278668722\n",
      "Epoch 15/15, Average Loss: 0.5911623487869898\n",
      "Epoch 1/15, Average Loss: 0.8481442431608835\n",
      "Epoch 2/15, Average Loss: 0.6754234631856283\n",
      "Epoch 3/15, Average Loss: 0.6504510243733724\n",
      "Epoch 4/15, Average Loss: 0.5186292777458826\n",
      "Epoch 5/15, Average Loss: 0.4977741489807765\n",
      "Epoch 6/15, Average Loss: 0.43642038603623706\n",
      "Epoch 7/15, Average Loss: 0.39244599143664044\n",
      "Epoch 8/15, Average Loss: 0.38190731902917224\n",
      "Epoch 9/15, Average Loss: 0.32074985653162\n",
      "Epoch 10/15, Average Loss: 0.35412438213825226\n",
      "Epoch 11/15, Average Loss: 0.32565219203631085\n",
      "Epoch 12/15, Average Loss: 0.36223281423250836\n",
      "Epoch 13/15, Average Loss: 0.3296263962984085\n",
      "Epoch 14/15, Average Loss: 0.2631446917851766\n",
      "Epoch 15/15, Average Loss: 0.3169063131014506\n",
      "Epoch 1/5, Average Loss: 0.7548961838086446\n",
      "Epoch 2/5, Average Loss: 0.5150155872106552\n",
      "Epoch 3/5, Average Loss: 0.4775835524002711\n",
      "Epoch 4/5, Average Loss: 0.5054318656524023\n",
      "Epoch 5/5, Average Loss: 0.4925027936697006\n",
      "Epoch 1/5, Average Loss: 0.8060840169588724\n",
      "Epoch 2/5, Average Loss: 0.6779743035634359\n",
      "Epoch 3/5, Average Loss: 0.6671185990174612\n",
      "Epoch 4/5, Average Loss: 0.664187878370285\n",
      "Epoch 5/5, Average Loss: 0.665601501862208\n",
      "Epoch 1/10, Average Loss: 52.66958683729172\n",
      "Epoch 2/10, Average Loss: 14.107722401618958\n",
      "Epoch 3/10, Average Loss: 4.324116557836533\n",
      "Epoch 4/10, Average Loss: 2.055916634698709\n",
      "Epoch 5/10, Average Loss: 0.9731544802586237\n",
      "Epoch 6/10, Average Loss: 0.5451400429010391\n",
      "Epoch 7/10, Average Loss: 0.34670622646808624\n",
      "Epoch 8/10, Average Loss: 0.33170417696237564\n",
      "Epoch 9/10, Average Loss: 0.29552264511585236\n",
      "Epoch 10/10, Average Loss: 0.2456433673699697\n",
      "Epoch 1/15, Average Loss: 0.9143760502338409\n",
      "Epoch 2/15, Average Loss: 0.7756132980187734\n",
      "Epoch 3/15, Average Loss: 0.6506229738394419\n",
      "Epoch 4/15, Average Loss: 0.6392970383167267\n",
      "Epoch 5/15, Average Loss: 0.6344469090302786\n",
      "Epoch 6/15, Average Loss: 0.5084701478481293\n",
      "Epoch 7/15, Average Loss: 0.484108900030454\n",
      "Epoch 8/15, Average Loss: 0.5053762296835581\n",
      "Epoch 9/15, Average Loss: 0.3502760777870814\n",
      "Epoch 10/15, Average Loss: 0.3392004420359929\n",
      "Epoch 11/15, Average Loss: 0.5068001747131348\n",
      "Epoch 12/15, Average Loss: 0.4339050104220708\n",
      "Epoch 13/15, Average Loss: 0.5105157842238744\n",
      "Epoch 14/15, Average Loss: 0.26575558880964917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/15, Average Loss: 0.31103335569302243\n",
      "Epoch 1/15, Average Loss: 0.8347045580546061\n",
      "Epoch 2/15, Average Loss: 0.6755234003067017\n",
      "Epoch 3/15, Average Loss: 0.5609065989653269\n",
      "Epoch 4/15, Average Loss: 0.5300098309914271\n",
      "Epoch 5/15, Average Loss: 0.5074907938639323\n",
      "Epoch 6/15, Average Loss: 0.4191334918141365\n",
      "Epoch 7/15, Average Loss: 0.45527692635854083\n",
      "Epoch 8/15, Average Loss: 0.3510527138908704\n",
      "Epoch 9/15, Average Loss: 0.33509618292252225\n",
      "Epoch 10/15, Average Loss: 0.3505646089712779\n",
      "Epoch 11/15, Average Loss: 0.29779554158449173\n",
      "Epoch 12/15, Average Loss: 0.2730310186743736\n",
      "Epoch 13/15, Average Loss: 0.2706012614071369\n",
      "Epoch 14/15, Average Loss: 0.3459014830489953\n",
      "Epoch 15/15, Average Loss: 0.21344163765509924\n",
      "Epoch 1/15, Average Loss: 0.6707229812939962\n",
      "Epoch 2/15, Average Loss: 0.6667693456013998\n",
      "Epoch 3/15, Average Loss: 0.6637280484040579\n",
      "Epoch 4/15, Average Loss: 0.6531555751959482\n",
      "Epoch 5/15, Average Loss: 0.6374999582767487\n",
      "Epoch 6/15, Average Loss: 0.6072030663490295\n",
      "Epoch 7/15, Average Loss: 0.5736695528030396\n",
      "Epoch 8/15, Average Loss: 0.5311366667350134\n",
      "Epoch 9/15, Average Loss: 0.4428994059562683\n",
      "Epoch 10/15, Average Loss: 0.366375391681989\n",
      "Epoch 11/15, Average Loss: 0.35849107553561527\n",
      "Epoch 12/15, Average Loss: 0.2747786045074463\n",
      "Epoch 13/15, Average Loss: 0.24546210716168085\n",
      "Epoch 14/15, Average Loss: 0.22470758482813835\n",
      "Epoch 15/15, Average Loss: 0.18188840771714845\n",
      "Epoch 1/15, Average Loss: 0.3294048147040953\n",
      "Epoch 2/15, Average Loss: 0.326548839624501\n",
      "Epoch 3/15, Average Loss: 0.33814167595893435\n",
      "Epoch 4/15, Average Loss: 0.3570674021411868\n",
      "Epoch 5/15, Average Loss: 0.35665579434954425\n",
      "Epoch 6/15, Average Loss: 0.3564055618875235\n",
      "Epoch 7/15, Average Loss: 0.357272311864258\n",
      "Epoch 8/15, Average Loss: 0.35756527824164597\n",
      "Epoch 9/15, Average Loss: 0.3566678948700428\n",
      "Epoch 10/15, Average Loss: 0.3570065429705439\n",
      "Epoch 11/15, Average Loss: 0.35818931712832264\n",
      "Epoch 12/15, Average Loss: 0.356812217672473\n",
      "Epoch 13/15, Average Loss: 0.35618980055295146\n",
      "Epoch 14/15, Average Loss: 0.3570469966357194\n",
      "Epoch 15/15, Average Loss: 0.35728411609397354\n",
      "Epoch 1/5, Average Loss: 14.119349980032416\n",
      "Epoch 2/5, Average Loss: 0.3244081878618708\n",
      "Epoch 3/5, Average Loss: 0.32403647412808195\n",
      "Epoch 4/5, Average Loss: 0.3235714914005937\n",
      "Epoch 5/5, Average Loss: 0.34758205624315347\n",
      "Epoch 1/10, Average Loss: 14.263036615922264\n",
      "Epoch 2/10, Average Loss: 3.2228309823126238\n",
      "Epoch 3/10, Average Loss: 1.6850471444933217\n",
      "Epoch 4/10, Average Loss: 0.7309572723012802\n",
      "Epoch 5/10, Average Loss: 0.4503695952085322\n",
      "Epoch 6/10, Average Loss: 0.34729798202203965\n",
      "Epoch 7/10, Average Loss: 0.3286192407198612\n",
      "Epoch 8/10, Average Loss: 0.5690084953801435\n",
      "Epoch 9/10, Average Loss: 0.31062202139314515\n",
      "Epoch 10/10, Average Loss: 0.3060755742117039\n",
      "Epoch 1/5, Average Loss: 10.332139423663177\n",
      "Epoch 2/5, Average Loss: 0.3512972356986652\n",
      "Epoch 3/5, Average Loss: 0.3514590824402652\n",
      "Epoch 4/5, Average Loss: 0.3515153434814759\n",
      "Epoch 5/5, Average Loss: 0.3515197404018305\n",
      "Epoch 1/5, Average Loss: 3.5632418342079353\n",
      "Epoch 2/5, Average Loss: 0.3540918233469852\n",
      "Epoch 3/5, Average Loss: 0.353967021912047\n",
      "Epoch 4/5, Average Loss: 0.3535476245564743\n",
      "Epoch 5/5, Average Loss: 0.35302728546186557\n",
      "Epoch 1/10, Average Loss: 0.3536243906877573\n",
      "Epoch 2/10, Average Loss: 0.351439647839486\n",
      "Epoch 3/10, Average Loss: 0.35093333232171325\n",
      "Epoch 4/10, Average Loss: 0.35076282568348266\n",
      "Epoch 5/10, Average Loss: 0.35070617557005973\n",
      "Epoch 6/10, Average Loss: 0.3506796334987705\n",
      "Epoch 7/10, Average Loss: 0.3506642426318914\n",
      "Epoch 8/10, Average Loss: 0.35065379108763434\n",
      "Epoch 9/10, Average Loss: 0.3506449962125241\n",
      "Epoch 10/10, Average Loss: 0.3506339927321499\n",
      "Epoch 1/15, Average Loss: 0.3546658393827457\n",
      "Epoch 2/15, Average Loss: 0.35152426200005615\n",
      "Epoch 3/15, Average Loss: 0.3511376556334565\n",
      "Epoch 4/15, Average Loss: 0.35105695651428215\n",
      "Epoch 5/15, Average Loss: 0.35101803018919475\n",
      "Epoch 6/15, Average Loss: 0.35096889330634795\n",
      "Epoch 7/15, Average Loss: 0.35071366327335535\n",
      "Epoch 8/15, Average Loss: 0.3505947920376236\n",
      "Epoch 9/15, Average Loss: 0.35059331093453666\n",
      "Epoch 10/15, Average Loss: 0.3505929629634885\n",
      "Epoch 11/15, Average Loss: 0.35059280375977164\n",
      "Epoch 12/15, Average Loss: 0.350592717412606\n",
      "Epoch 13/15, Average Loss: 0.35059266546831547\n",
      "Epoch 14/15, Average Loss: 0.3505926332572131\n",
      "Epoch 15/15, Average Loss: 0.35059261296703975\n",
      "Epoch 1/15, Average Loss: 0.33288687127958805\n",
      "Epoch 2/15, Average Loss: 0.3314973005898369\n",
      "Epoch 3/15, Average Loss: 0.3316602043120317\n",
      "Epoch 4/15, Average Loss: 0.33176944854407053\n",
      "Epoch 5/15, Average Loss: 0.3318037399136036\n",
      "Epoch 6/15, Average Loss: 0.33172880143505856\n",
      "Epoch 7/15, Average Loss: 0.3317566123872417\n",
      "Epoch 8/15, Average Loss: 0.3316625869787723\n",
      "Epoch 9/15, Average Loss: 0.33170207648094996\n",
      "Epoch 10/15, Average Loss: 0.3316595283201308\n",
      "Epoch 11/15, Average Loss: 0.3316825044241924\n",
      "Epoch 12/15, Average Loss: 0.33164824511023977\n",
      "Epoch 13/15, Average Loss: 0.33166666847554227\n",
      "Epoch 14/15, Average Loss: 0.33169869397522755\n",
      "Epoch 15/15, Average Loss: 0.33169310533088964\n",
      "Epoch 1/10, Average Loss: 0.36749287051085416\n",
      "Epoch 2/10, Average Loss: 0.3647446998150893\n",
      "Epoch 3/10, Average Loss: 0.3648410245052819\n",
      "Epoch 4/10, Average Loss: 0.3648609039418906\n",
      "Epoch 5/10, Average Loss: 0.36486689778388415\n",
      "Epoch 6/10, Average Loss: 0.3648689695932333\n",
      "Epoch 7/10, Average Loss: 0.3648697008803776\n",
      "Epoch 8/10, Average Loss: 0.36486993643807847\n",
      "Epoch 9/10, Average Loss: 0.36487002555931947\n",
      "Epoch 10/10, Average Loss: 0.3648700741092557\n",
      "Epoch 1/10, Average Loss: 0.3280840307835815\n",
      "Epoch 2/10, Average Loss: 0.32368755758676715\n",
      "Epoch 3/10, Average Loss: 0.3237242418296129\n",
      "Epoch 4/10, Average Loss: 0.3237330149244336\n",
      "Epoch 5/10, Average Loss: 0.3237355442374077\n",
      "Epoch 6/10, Average Loss: 0.3237363118714499\n",
      "Epoch 7/10, Average Loss: 0.3237365483731321\n",
      "Epoch 8/10, Average Loss: 0.32373662912874546\n",
      "Epoch 9/10, Average Loss: 0.3237366511043414\n",
      "Epoch 10/10, Average Loss: 0.3237366583451484\n"
     ]
    }
   ],
   "source": [
    "num_iterations = 10\n",
    "param_ranges = {\n",
    "    'min_hidden': 5,\n",
    "    'max_hidden': 50,\n",
    "    'min_layers': 1,\n",
    "    'max_layers': 3,\n",
    "    'activation_functions': [F.relu, F.tanh, F.sigmoid],\n",
    "    'min_lr': 0.001,\n",
    "    'max_lr': 0.1,\n",
    "    'batch_sizes': [32, 64, 128],\n",
    "    'num_epochs': [5, 10, 15]\n",
    "}\n",
    "\n",
    "initial_configuration = {\n",
    "    'Hidden Layer Sizes': [25],\n",
    "    'Activation Function': F.relu,\n",
    "    'Learning Rate': 0.01,\n",
    "    'Batch Size': 64,\n",
    "    'Number of Epochs': 10\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "all_random_results = []\n",
    "\n",
    "for dataset_name, dataset in datasets.items():\n",
    "    train_X, train_Y, test_X, test_Y = train_test_split(dataset, \"class\", return_torch=True)\n",
    "\n",
    "    train_data = TensorDataset(train_X, train_Y)\n",
    "    train_loader = DataLoader(train_data, batch_size=32, shuffle=False)\n",
    "\n",
    "    test_data = TensorDataset(test_X, test_Y)\n",
    "    test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n",
    "    \n",
    "    input_size = train_X.shape[1]\n",
    "\n",
    "    if dataset_name == 'wine_quality':\n",
    "        num_classes = 10\n",
    "    else:\n",
    "        num_classes = len(np.unique(train_Y))\n",
    "\n",
    "    best_config, best_accuracy, random_results = random_search(num_iterations, initial_configuration, param_ranges, train_loader, test_loader)\n",
    "\n",
    "    random_results['dataset'] = dataset_name\n",
    "    all_random_results.append(random_results)\n",
    "#all_random_results = pd.DataFrame(all_random_results)\n",
    "#random_results_df = pd.concat(all_random_results, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_results_df = pd.DataFrame(all_random_results)\n",
    "random_results_df = pd.concat(all_random_results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hidden Layer Sizes</th>\n",
       "      <th>Activation Function</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Batch Size</th>\n",
       "      <th>Number of Epochs</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Training Time</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[12, 38]</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.013719</td>\n",
       "      <td>128</td>\n",
       "      <td>10</td>\n",
       "      <td>0.456209</td>\n",
       "      <td>2.065076</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[32, 14, 10]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.073446</td>\n",
       "      <td>32</td>\n",
       "      <td>15</td>\n",
       "      <td>0.284967</td>\n",
       "      <td>2.933734</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[14, 15, 6]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.038363</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>0.458824</td>\n",
       "      <td>0.871133</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[36, 17, 24]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.075953</td>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>0.284967</td>\n",
       "      <td>1.847184</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[27, 36]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.036705</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>0.284967</td>\n",
       "      <td>0.806684</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[17, 20, 11]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.053805</td>\n",
       "      <td>128</td>\n",
       "      <td>15</td>\n",
       "      <td>0.458824</td>\n",
       "      <td>2.676784</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[34, 43]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.002514</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.397386</td>\n",
       "      <td>1.622344</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[5, 20, 27]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.046287</td>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>0.458824</td>\n",
       "      <td>1.786368</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[33]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.035976</td>\n",
       "      <td>128</td>\n",
       "      <td>10</td>\n",
       "      <td>0.418301</td>\n",
       "      <td>1.354204</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[34, 38, 13]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.085812</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>0.284967</td>\n",
       "      <td>0.880774</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[27, 47]</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.055599</td>\n",
       "      <td>128</td>\n",
       "      <td>10</td>\n",
       "      <td>0.767442</td>\n",
       "      <td>0.080141</td>\n",
       "      <td>cong_voting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[36, 12, 29]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.059259</td>\n",
       "      <td>128</td>\n",
       "      <td>15</td>\n",
       "      <td>0.627907</td>\n",
       "      <td>0.107670</td>\n",
       "      <td>cong_voting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[47, 31]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.062220</td>\n",
       "      <td>32</td>\n",
       "      <td>15</td>\n",
       "      <td>0.488372</td>\n",
       "      <td>0.122756</td>\n",
       "      <td>cong_voting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[14]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.011093</td>\n",
       "      <td>128</td>\n",
       "      <td>15</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.084962</td>\n",
       "      <td>cong_voting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[48]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.024729</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>0.697674</td>\n",
       "      <td>0.034977</td>\n",
       "      <td>cong_voting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[9, 45, 16]</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.095722</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>0.627907</td>\n",
       "      <td>0.048262</td>\n",
       "      <td>cong_voting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[27]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.073878</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.057730</td>\n",
       "      <td>cong_voting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[29]</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.096876</td>\n",
       "      <td>128</td>\n",
       "      <td>15</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.086123</td>\n",
       "      <td>cong_voting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[32]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.024027</td>\n",
       "      <td>128</td>\n",
       "      <td>15</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.097089</td>\n",
       "      <td>cong_voting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[9, 27]</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.011064</td>\n",
       "      <td>128</td>\n",
       "      <td>15</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.093420</td>\n",
       "      <td>cong_voting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[33, 5, 23]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.020559</td>\n",
       "      <td>64</td>\n",
       "      <td>15</td>\n",
       "      <td>0.883103</td>\n",
       "      <td>16.575967</td>\n",
       "      <td>bank_marketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[34, 36, 45]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.067875</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>0.883103</td>\n",
       "      <td>5.721892</td>\n",
       "      <td>bank_marketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[30, 25]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.005090</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.892814</td>\n",
       "      <td>10.238236</td>\n",
       "      <td>bank_marketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[37, 18, 36]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.032870</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>0.883103</td>\n",
       "      <td>9.501481</td>\n",
       "      <td>bank_marketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[25, 49, 15]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.087975</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>0.883103</td>\n",
       "      <td>6.594663</td>\n",
       "      <td>bank_marketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[6, 17]</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.016830</td>\n",
       "      <td>128</td>\n",
       "      <td>10</td>\n",
       "      <td>0.883103</td>\n",
       "      <td>11.631081</td>\n",
       "      <td>bank_marketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[33, 14, 32]</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.015914</td>\n",
       "      <td>128</td>\n",
       "      <td>15</td>\n",
       "      <td>0.883103</td>\n",
       "      <td>20.255146</td>\n",
       "      <td>bank_marketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[30, 35, 45]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.011525</td>\n",
       "      <td>128</td>\n",
       "      <td>15</td>\n",
       "      <td>0.892814</td>\n",
       "      <td>23.773424</td>\n",
       "      <td>bank_marketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[45]</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.095923</td>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>0.883103</td>\n",
       "      <td>9.437345</td>\n",
       "      <td>bank_marketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[34]</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.007167</td>\n",
       "      <td>128</td>\n",
       "      <td>10</td>\n",
       "      <td>0.892814</td>\n",
       "      <td>14.201142</td>\n",
       "      <td>bank_marketing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Hidden Layer Sizes Activation Function  Learning Rate  Batch Size  \\\n",
       "0            [12, 38]             sigmoid       0.013719         128   \n",
       "1        [32, 14, 10]                tanh       0.073446          32   \n",
       "2         [14, 15, 6]                relu       0.038363          64   \n",
       "3        [36, 17, 24]                tanh       0.075953          32   \n",
       "4            [27, 36]                tanh       0.036705          32   \n",
       "5        [17, 20, 11]                relu       0.053805         128   \n",
       "6            [34, 43]                relu       0.002514          64   \n",
       "7         [5, 20, 27]                relu       0.046287          32   \n",
       "8                [33]                relu       0.035976         128   \n",
       "9        [34, 38, 13]                tanh       0.085812          32   \n",
       "10           [27, 47]             sigmoid       0.055599         128   \n",
       "11       [36, 12, 29]                tanh       0.059259         128   \n",
       "12           [47, 31]                tanh       0.062220          32   \n",
       "13               [14]                tanh       0.011093         128   \n",
       "14               [48]                tanh       0.024729          64   \n",
       "15        [9, 45, 16]             sigmoid       0.095722          32   \n",
       "16               [27]                relu       0.073878          64   \n",
       "17               [29]             sigmoid       0.096876         128   \n",
       "18               [32]                tanh       0.024027         128   \n",
       "19            [9, 27]             sigmoid       0.011064         128   \n",
       "20        [33, 5, 23]                tanh       0.020559          64   \n",
       "21       [34, 36, 45]                relu       0.067875          32   \n",
       "22           [30, 25]                relu       0.005090          64   \n",
       "23       [37, 18, 36]                relu       0.032870          64   \n",
       "24       [25, 49, 15]                relu       0.087975          64   \n",
       "25            [6, 17]             sigmoid       0.016830         128   \n",
       "26       [33, 14, 32]             sigmoid       0.015914         128   \n",
       "27       [30, 35, 45]                tanh       0.011525         128   \n",
       "28               [45]             sigmoid       0.095923          32   \n",
       "29               [34]             sigmoid       0.007167         128   \n",
       "\n",
       "    Number of Epochs  Accuracy  Training Time         dataset  \n",
       "0                 10  0.456209       2.065076    wine_quality  \n",
       "1                 15  0.284967       2.933734    wine_quality  \n",
       "2                  5  0.458824       0.871133    wine_quality  \n",
       "3                 10  0.284967       1.847184    wine_quality  \n",
       "4                  5  0.284967       0.806684    wine_quality  \n",
       "5                 15  0.458824       2.676784    wine_quality  \n",
       "6                 10  0.397386       1.622344    wine_quality  \n",
       "7                 10  0.458824       1.786368    wine_quality  \n",
       "8                 10  0.418301       1.354204    wine_quality  \n",
       "9                  5  0.284967       0.880774    wine_quality  \n",
       "10                10  0.767442       0.080141     cong_voting  \n",
       "11                15  0.627907       0.107670     cong_voting  \n",
       "12                15  0.488372       0.122756     cong_voting  \n",
       "13                15  0.930233       0.084962     cong_voting  \n",
       "14                 5  0.697674       0.034977     cong_voting  \n",
       "15                 5  0.627907       0.048262     cong_voting  \n",
       "16                10  0.906977       0.057730     cong_voting  \n",
       "17                15  0.837209       0.086123     cong_voting  \n",
       "18                15  0.906977       0.097089     cong_voting  \n",
       "19                15  0.860465       0.093420     cong_voting  \n",
       "20                15  0.883103      16.575967  bank_marketing  \n",
       "21                 5  0.883103       5.721892  bank_marketing  \n",
       "22                10  0.892814      10.238236  bank_marketing  \n",
       "23                 5  0.883103       9.501481  bank_marketing  \n",
       "24                 5  0.883103       6.594663  bank_marketing  \n",
       "25                10  0.883103      11.631081  bank_marketing  \n",
       "26                15  0.883103      20.255146  bank_marketing  \n",
       "27                15  0.892814      23.773424  bank_marketing  \n",
       "28                10  0.883103       9.437345  bank_marketing  \n",
       "29                10  0.892814      14.201142  bank_marketing  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
