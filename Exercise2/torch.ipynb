{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as metrics\n",
    "import torch.nn.init as init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationModel(nn.Module): \n",
    "        \n",
    "    def __init__(self, nodes_per_layer, input_shape, num_classes):\n",
    "        super(ClassificationModel, self).__init__()\n",
    "\n",
    "        layers = []\n",
    "        # input layer with the input dimension of the data shape        \n",
    "        layers.append(nn.Linear(input_shape, nodes_per_layer[0]))\n",
    "        # He initialization for the first layer\n",
    "        #init.kaiming_uniform_(layers[0].weight, mode='fan_in', nonlinearity='relu')\n",
    "        # the activation function for each node\n",
    "        layers.append(nn.ReLU()) \n",
    "        # hidden layers with dimension of nodes_per_layer\n",
    "        for i in range(1, len(nodes_per_layer)):\n",
    "            layers.append(nn.Linear(nodes_per_layer[i - 1], nodes_per_layer[i]))\n",
    "            # He initialization for the hidden layers\n",
    "            #init.kaiming_uniform_(layers[-1].weight, mode='fan_in', nonlinearity='relu')\n",
    "            layers.append(nn.ReLU())\n",
    "        # output layer with the binary output\n",
    "        layers.append(nn.Linear(nodes_per_layer[-1], num_classes))\n",
    "        layers.append(nn.Softmax(dim=1))\n",
    "\n",
    "        self.model = nn.Sequential(*layers)\n",
    "                \n",
    "  \n",
    "    def forward(self, x):\n",
    "        x = x.to(self.model[0].weight.dtype)\n",
    "        return self.model(x)\n",
    "    \n",
    "    def train_model(self, train_loader, num_epochs=5, lr=0.001, val_loader=True) :\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(self.parameters(), lr=lr)\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            for inputs, labels in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            \n",
    "            if val_loader is not None:\n",
    "                self.eval()\n",
    "                correct = 0\n",
    "                total = 0\n",
    "                with torch.no_grad():\n",
    "                    for val_inputs, val_labels in val_loader:\n",
    "                        val_outputs = self(val_inputs)\n",
    "                        _, predicted = torch.max(val_outputs.data, 1)\n",
    "                        total += val_labels.size(0)\n",
    "                        correct += (predicted == val_labels).sum().item()\n",
    "\n",
    "                accuracy = correct / total\n",
    "            \n",
    "            print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item()}, Validation Accuracy: {accuracy}')\n",
    "            \n",
    "    def predict(self, input_data):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            outputs = self(input_data)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "        return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(data: pd.DataFrame, target_label : str, test_size=0.2, return_torch=None):\n",
    "        \n",
    "    # split the data into train and test\n",
    "    train = data.sample(frac=(1-test_size),random_state=123)\n",
    "    test = data.drop(train.index)\n",
    "    \n",
    "    # split the train and test into X and Y\n",
    "    train_X = train.drop([target_label], axis=1).values\n",
    "    train_Y = train[target_label].values\n",
    "    test_X = test.drop([target_label], axis=1).values\n",
    "    test_Y = test[target_label].values\n",
    "        \n",
    "    if return_torch:\n",
    "        train_X = torch.tensor(train_X)\n",
    "        train_Y = torch.tensor(train_Y)\n",
    "        test_X = torch.tensor(test_X)\n",
    "        test_Y = torch.tensor(test_Y)\n",
    "        \n",
    "    return train_X, train_Y, test_X, test_Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Congression Voting Dataset\n",
    "cong_voting = pd.read_csv('./preprocessed-datasets/CongressionVoting_prepro.csv')\n",
    "\n",
    "label2num = {\"democrat\": 0, \"republican\": 1}\n",
    "num2label = {0: \"democrat\", 1: \"republican\"}\n",
    "\n",
    "# convert the target label to numeric\n",
    "cong_voting[\"class\"] = cong_voting[\"class\"].apply(lambda x: label2num[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    137\n",
       "1     80\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cong_voting[\"class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>class</th>\n",
       "      <th>wine_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  class  wine_type  \n",
       "0      9.4      5          1  \n",
       "1      9.8      5          1  \n",
       "2      9.8      5          1  \n",
       "3      9.8      6          1  \n",
       "4      9.4      5          1  "
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wine Quality Dataset\n",
    "wine_quality = pd.read_csv('./preprocessed-datasets/wine_quality_prepro.csv', index_col=0)\n",
    "wine_quality.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'init_weights' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[213], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# in batch we have 32 samples, and we shuffle the data after the iteration over each batch\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mClassificationModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnodes_per_layer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain_model(train_loader, num_epochs\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m, lr\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0001\u001b[39m, val_loader\u001b[38;5;241m=\u001b[39mtrain_loader)\n\u001b[0;32m     14\u001b[0m Y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(test_X)\n",
      "Cell \u001b[1;32mIn[210], line 29\u001b[0m, in \u001b[0;36mClassificationModel.__init__\u001b[1;34m(self, nodes_per_layer, input_shape, num_classes)\u001b[0m\n\u001b[0;32m     25\u001b[0m layers\u001b[38;5;241m.\u001b[39mappend(nn\u001b[38;5;241m.\u001b[39mSoftmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequential(\u001b[38;5;241m*\u001b[39mlayers)\n\u001b[1;32m---> 29\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mapply(\u001b[43minit_weights\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'init_weights' is not defined"
     ]
    }
   ],
   "source": [
    "# run the model for cong_voting dataset\n",
    "train_X, train_Y, test_X, test_Y = train_test_split(cong_voting, \"class\", return_torch=True)\n",
    "\n",
    "nodes_per_layer = [15, 6, 12]\n",
    "input_shape = train_X.shape[1]\n",
    "num_classes = 2 # binary classification\n",
    "num_samples = train_X.shape[0] \n",
    "\n",
    "dataset = TensorDataset(train_X, train_Y) # wrap X and Y into a single dataset\n",
    "train_loader = DataLoader(dataset, batch_size=32, shuffle=True) \n",
    "# in batch we have 32 samples, and we shuffle the data after the iteration over each batch\n",
    "model = ClassificationModel(nodes_per_layer, input_shape, num_classes)\n",
    "model.train_model(train_loader, num_epochs= 10, lr= 0.0001, val_loader=train_loader)\n",
    "Y_pred = model.predict(test_X)\n",
    "print(f\"The f1 score is {metrics.f1_score(test_Y, Y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ClassificationModel.init_weights() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[206], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m dataset \u001b[38;5;241m=\u001b[39m TensorDataset(train_X, train_Y)\n\u001b[0;32m     10\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 11\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mClassificationModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnodes_per_layer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain_model(train_loader, lr\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.01\u001b[39m, val_loader\u001b[38;5;241m=\u001b[39mtrain_loader)\n\u001b[0;32m     13\u001b[0m Y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(test_X)\n",
      "Cell \u001b[1;32mIn[205], line 24\u001b[0m, in \u001b[0;36mClassificationModel.__init__\u001b[1;34m(self, nodes_per_layer, input_shape, num_classes)\u001b[0m\n\u001b[0;32m     20\u001b[0m layers\u001b[38;5;241m.\u001b[39mappend(nn\u001b[38;5;241m.\u001b[39mSoftmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequential(\u001b[38;5;241m*\u001b[39mlayers)\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_weights\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\zsomb\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:897\u001b[0m, in \u001b[0;36mModule.apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    862\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Applies ``fn`` recursively to every submodule (as returned by ``.children()``)\u001b[39;00m\n\u001b[0;32m    863\u001b[0m \u001b[38;5;124;03mas well as self. Typical use includes initializing the parameters of a model\u001b[39;00m\n\u001b[0;32m    864\u001b[0m \u001b[38;5;124;03m(see also :ref:`nn-init-doc`).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    894\u001b[0m \n\u001b[0;32m    895\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    896\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 897\u001b[0m     \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    898\u001b[0m fn(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    899\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\zsomb\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:898\u001b[0m, in \u001b[0;36mModule.apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    896\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m    897\u001b[0m     module\u001b[38;5;241m.\u001b[39mapply(fn)\n\u001b[1;32m--> 898\u001b[0m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    899\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[1;31mTypeError\u001b[0m: ClassificationModel.init_weights() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "# run the model for wine_quality dataset\n",
    "train_X, train_Y, test_X, test_Y = train_test_split(wine_quality, \"wine_type\", return_torch=True)\n",
    "\n",
    "nodes_per_layer = [5, 7, 5]\n",
    "input_shape = train_X.shape[1]\n",
    "num_classes = 10 # binary classification\n",
    "num_samples = train_X.shape[0] \n",
    "\n",
    "dataset = TensorDataset(train_X, train_Y)\n",
    "train_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "model = ClassificationModel(nodes_per_layer, input_shape, num_classes)\n",
    "model.train_model(train_loader, lr= 0.01, val_loader=train_loader)\n",
    "Y_pred = model.predict(test_X)\n",
    "print(f\"The f1 score is {metrics.f1_score(test_Y, Y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClassificationModel(\n",
      "  (model): Sequential(\n",
      "    (0): Linear(in_features=12, out_features=5, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=5, out_features=7, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=7, out_features=5, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=5, out_features=2, bias=True)\n",
      "    (7): Softmax(dim=1)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = ClassificationModel(nodes_per_layer, input_shape, num_classes)\n",
    "print(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
