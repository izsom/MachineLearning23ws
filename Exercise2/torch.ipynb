{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationModel(nn.Module):\n",
    "    def __init__(self, nodes_per_layer, input_shape, num_classes):\n",
    "        super(ClassificationModel, self).__init__()\n",
    "\n",
    "        layers = []\n",
    "        # input layer with the input dimension of the data shape\n",
    "        layers.append(nn.Linear(input_shape, nodes_per_layer[0]))\n",
    "        # the activation function for each node\n",
    "        layers.append(nn.ReLU()) \n",
    "        # hidden layers with dimension of nodes_per_layer\n",
    "        for i in range(1, len(nodes_per_layer)):\n",
    "            layers.append(nn.Linear(nodes_per_layer[i - 1], nodes_per_layer[i]))\n",
    "            layers.append(nn.ReLU())\n",
    "        # output layer with the binary output\n",
    "        layers.append(nn.Linear(nodes_per_layer[-1], num_classes))\n",
    "        layers.append(nn.Softmax(dim=1))\n",
    "\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(self.model[0].weight.dtype)\n",
    "        return self.model(x)\n",
    "    \n",
    "    def train_model(self, train_loader, num_epochs=5, lr=0.001, val_loader=True) :\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(self.parameters(), lr=lr)\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            for inputs, labels in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            \n",
    "            if val_loader is not None:\n",
    "                self.eval()\n",
    "                correct = 0\n",
    "                total = 0\n",
    "                with torch.no_grad():\n",
    "                    for val_inputs, val_labels in val_loader:\n",
    "                        val_outputs = self(val_inputs)\n",
    "                        _, predicted = torch.max(val_outputs.data, 1)\n",
    "                        total += val_labels.size(0)\n",
    "                        correct += (predicted == val_labels).sum().item()\n",
    "\n",
    "                accuracy = correct / total\n",
    "            \n",
    "            print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item()}, Validation Accuracy: {accuracy}')\n",
    "            \n",
    "    def predict(self, input_data):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            outputs = self(input_data)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "        return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(data: pd.DataFrame, target_label : str, test_size=0.2, return_torch=None):\n",
    "        \n",
    "    # split the data into train and test\n",
    "    train = data.sample(frac=(1-test_size),random_state=123)\n",
    "    test = data.drop(train.index)\n",
    "    \n",
    "    # split the train and test into X and Y\n",
    "    train_X = train.drop([target_label], axis=1).values\n",
    "    train_Y = train[target_label].values\n",
    "    test_X = test.drop([target_label], axis=1).values\n",
    "    test_Y = test[target_label].values\n",
    "        \n",
    "    if return_torch:\n",
    "        train_X = torch.tensor(train_X)\n",
    "        train_Y = torch.tensor(train_Y)\n",
    "        test_X = torch.tensor(test_X)\n",
    "        test_Y = torch.tensor(test_Y)\n",
    "        \n",
    "    return train_X, train_Y, test_X, test_Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Congression Voting Dataset\n",
    "cong_voting = pd.read_csv('./preprocessed-datasets/CongressionVoting_prepro.csv')\n",
    "\n",
    "label2num = {\"democrat\": 0, \"republican\": 1}\n",
    "num2label = {0: \"democrat\", 1: \"republican\"}\n",
    "\n",
    "# convert the target label to numeric\n",
    "cong_voting[\"class\"] = cong_voting[\"class\"].apply(lambda x: label2num[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>class</th>\n",
       "      <th>wine_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  class  wine_type  \n",
       "0      9.4      5          1  \n",
       "1      9.8      5          1  \n",
       "2      9.8      5          1  \n",
       "3      9.8      6          1  \n",
       "4      9.4      5          1  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wine Quality Dataset\n",
    "wine_quality = pd.read_csv('./preprocessed-datasets/wine_quality_prepro.csv', index_col=0)\n",
    "wine_quality.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 0.7605882883071899, Validation Accuracy: 0.6206896551724138\n",
      "Epoch 2/5, Loss: 0.6138724684715271, Validation Accuracy: 0.6206896551724138\n",
      "Epoch 3/5, Loss: 0.665496826171875, Validation Accuracy: 0.6206896551724138\n",
      "Epoch 4/5, Loss: 0.7569994926452637, Validation Accuracy: 0.6206896551724138\n",
      "Epoch 5/5, Loss: 0.673559308052063, Validation Accuracy: 0.6206896551724138\n",
      "The f1 score is 0.0\n"
     ]
    }
   ],
   "source": [
    "# run the model for cong_voting dataset\n",
    "train_X, train_Y, test_X, test_Y = train_test_split(cong_voting, \"class\", return_torch=True)\n",
    "\n",
    "nodes_per_layer = [10, 10, 10]\n",
    "input_shape = train_X.shape[1]\n",
    "num_classes = 2 # binary classification\n",
    "num_samples = train_X.shape[0] \n",
    "\n",
    "dataset = TensorDataset(train_X, train_Y) # wrap X and Y into a single dataset\n",
    "train_loader = DataLoader(dataset, batch_size=32, shuffle=True) \n",
    "# in batch we have 32 samples, and we shuffle the data after the iteration over each batch\n",
    "model = ClassificationModel(nodes_per_layer, input_shape, num_classes)\n",
    "model.train_model(train_loader, num_epochs= 5, lr= 0.001, val_loader=train_loader)\n",
    "Y_pred = model.predict(test_X)\n",
    "print(f\"The f1 score is {metrics.f1_score(test_Y, Y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 1.6059741973876953, Validation Accuracy: 0.934397845325125\n",
      "Epoch 2/5, Loss: 1.4616745710372925, Validation Accuracy: 0.9390150057714506\n",
      "Epoch 3/5, Loss: 1.5248098373413086, Validation Accuracy: 0.9378607156598692\n",
      "Epoch 4/5, Loss: 1.4616385698318481, Validation Accuracy: 0.9409388226240862\n",
      "Epoch 5/5, Loss: 1.532624363899231, Validation Accuracy: 0.9420931127356675\n",
      "The f1 score is 0.8671328671328671\n"
     ]
    }
   ],
   "source": [
    "# run the model for wine_quality dataset\n",
    "train_X, train_Y, test_X, test_Y = train_test_split(wine_quality, \"wine_type\", return_torch=True)\n",
    "\n",
    "nodes_per_layer = [5, 7, 5]\n",
    "input_shape = train_X.shape[1]\n",
    "num_classes = 10 # binary classification\n",
    "num_samples = train_X.shape[0] \n",
    "\n",
    "dataset = TensorDataset(train_X, train_Y)\n",
    "train_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "model = ClassificationModel(nodes_per_layer, input_shape, num_classes)\n",
    "model.train_model(train_loader, lr= 0.01, val_loader=train_loader)\n",
    "Y_pred = model.predict(test_X)\n",
    "print(f\"The f1 score is {metrics.f1_score(test_Y, Y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClassificationModel(\n",
      "  (model): Sequential(\n",
      "    (0): Linear(in_features=12, out_features=5, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=5, out_features=7, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=7, out_features=5, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=5, out_features=2, bias=True)\n",
      "    (7): Softmax(dim=1)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = ClassificationModel(nodes_per_layer, input_shape, num_classes)\n",
    "print(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
