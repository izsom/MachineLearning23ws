{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F  \n",
    "from torch import optim \n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn.init as init\n",
    "import random\n",
    "import time\n",
    "from sklearn.model_selection import KFold\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score\n",
    "from nn_implementation import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_cv(hidden_layer_sizes_list, activation_functions, learning_rates, batch_sizes, num_epochs_list, train_loader, NumbOfClasses, k_folds=5, use_scaling=True):\n",
    "    best_f1 = 0.0\n",
    "    best_combination = None\n",
    "    results = []\n",
    "\n",
    "    kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "    if use_scaling:\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(train_loader.dataset.tensors[0].numpy())\n",
    "\n",
    "    for hidden_layer_sizes in hidden_layer_sizes_list:\n",
    "        for activation_function in activation_functions:\n",
    "            for learning_rate in learning_rates:\n",
    "                for batch_size in batch_sizes:\n",
    "                    for num_epochs in num_epochs_list:\n",
    "\n",
    "                        fold_accuracies = []\n",
    "                        fold_f1s = []\n",
    "                        fold_training_times = []\n",
    "\n",
    "                        for train_index, test_index in kf.split(train_loader.dataset):\n",
    "                            X_train, X_test = train_loader.dataset.tensors[0][train_index], train_loader.dataset.tensors[0][test_index]\n",
    "                            y_train, y_test = train_loader.dataset.tensors[1][train_index], train_loader.dataset.tensors[1][test_index]\n",
    "\n",
    "                            model = NN(input_size=train_loader.dataset.tensors[0].shape[1],\n",
    "                                       num_classes=NumbOfClasses,\n",
    "                                       hidden_layer_sizes=hidden_layer_sizes,\n",
    "                                       activation_function=activation_function)\n",
    "                            criterion = nn.CrossEntropyLoss()\n",
    "                            optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "                        \n",
    "                            if use_scaling:\n",
    "                                X_train_scaled = torch.tensor(scaler.transform(X_train.numpy()))\n",
    "                                X_test_scaled = torch.tensor(scaler.transform(X_test.numpy()))\n",
    "                            else:\n",
    "                                X_train_scaled, X_test_scaled = X_train, X_test\n",
    "\n",
    "                            train_start_time = time.time()\n",
    "                            train_model(model, DataLoader(TensorDataset(X_train_scaled, y_train), batch_size=batch_size, shuffle=True), optimizer, criterion, num_epochs)\n",
    "                            train_end_time = time.time()\n",
    "                            fold_training_times.append(train_end_time - train_start_time)\n",
    "\n",
    "                            accuracy_test, f1_test = check_accuracy(DataLoader(TensorDataset(X_test_scaled, y_test), batch_size=batch_size, shuffle=False), model)\n",
    "                            fold_accuracies.append(accuracy_test.item())\n",
    "                            fold_f1s.append(f1_test)\n",
    "\n",
    "                        avg_accuracy = np.mean(fold_accuracies)\n",
    "                        avg_f1 = np.mean(fold_f1s)\n",
    "                        avg_training_time = np.mean(fold_training_times)\n",
    "\n",
    "                        result = {\n",
    "                            'Hidden Layer Sizes': hidden_layer_sizes,\n",
    "                            'Activation Function': activation_function.__name__,\n",
    "                            'Learning Rate': learning_rate,\n",
    "                            'Batch Size': batch_size,\n",
    "                            'Number of Epochs': num_epochs,\n",
    "                            'Average Accuracy': avg_accuracy,\n",
    "                            'Average F1': avg_f1,\n",
    "                            'Average Training Time': avg_training_time\n",
    "                        }\n",
    "\n",
    "                        results.append(result)\n",
    "\n",
    "                        if avg_f1 > best_f1:\n",
    "                            best_f1 = avg_f1\n",
    "                            best_combination = result\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    return results_df, best_f1, best_combination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the model on the wine quality dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>class</th>\n",
       "      <th>wine_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  class  wine_type  \n",
       "0      9.4      5          1  \n",
       "1      9.8      5          1  \n",
       "2      9.8      5          1  \n",
       "3      9.8      6          1  \n",
       "4      9.4      5          1  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_quality = pd.read_csv('./preprocessed-datasets/wine_quality_prepro.csv', index_col=0)\n",
    "wine_quality.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting the dataset into training and testing sets, converting to PyTorch tensors and creating PyTorch DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_Y, test_X, test_Y = train_test_split(wine_quality, \"class\", return_torch=True)\n",
    "\n",
    "dataset = TensorDataset(train_X, train_Y)\n",
    "train_loader = DataLoader(dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "dataset = TensorDataset(test_X, test_Y)\n",
    "test_loader = DataLoader(dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the model, training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25, Average Loss: 1.333803896523692\n",
      "Epoch 2/25, Average Loss: 1.2906058975523966\n",
      "Epoch 3/25, Average Loss: 1.2820148658167365\n",
      "Epoch 4/25, Average Loss: 1.2806553131232232\n",
      "Epoch 5/25, Average Loss: 1.2760694824113437\n",
      "Epoch 6/25, Average Loss: 1.2697672090647412\n",
      "Epoch 7/25, Average Loss: 1.2612591437035543\n",
      "Epoch 8/25, Average Loss: 1.2699610020485392\n",
      "Epoch 9/25, Average Loss: 1.2569536347330714\n",
      "Epoch 10/25, Average Loss: 1.257002458981941\n",
      "Epoch 11/25, Average Loss: 1.2446364515398178\n",
      "Epoch 12/25, Average Loss: 1.2357006083968227\n",
      "Epoch 13/25, Average Loss: 1.234742837815197\n",
      "Epoch 14/25, Average Loss: 1.2384484194539076\n",
      "Epoch 15/25, Average Loss: 1.214447842785186\n",
      "Epoch 16/25, Average Loss: 1.2177743955623883\n",
      "Epoch 17/25, Average Loss: 1.213762878274625\n",
      "Epoch 18/25, Average Loss: 1.2058143838782984\n",
      "Epoch 19/25, Average Loss: 1.205070620665521\n",
      "Epoch 20/25, Average Loss: 1.217559916841472\n",
      "Epoch 21/25, Average Loss: 1.192050176164124\n",
      "Epoch 22/25, Average Loss: 1.18902153581198\n",
      "Epoch 23/25, Average Loss: 1.2038913058357004\n",
      "Epoch 24/25, Average Loss: 1.182511218486388\n",
      "Epoch 25/25, Average Loss: 1.172539707707481\n",
      "Training set accuracy: 0.4774913428241631, F1 Score: 0.40664215447661384\n",
      "Test set accuracy: 0.47581699346405226, F1 Score: 0.3853186112028968\n"
     ]
    }
   ],
   "source": [
    "input_size = train_X.shape[1] # number of features in wine quality dataset\n",
    "NumbOfClasses = 10 # 10 classes in wine quality dataset\n",
    "learning_rate = 0.01\n",
    "batch_size = 32\n",
    "num_epochs = 10\n",
    "hidden_layer_sizes = [25,30]\n",
    "activation_function = F.tanh\n",
    "\n",
    "model = NN(input_size=train_X.shape[1], num_classes=NumbOfClasses, hidden_layer_sizes=hidden_layer_sizes, activation_function=activation_function)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "train_model(model, train_loader, optimizer, criterion, num_epochs)\n",
    "accuracy, f1 = check_accuracy(train_loader, model)\n",
    "print(f\"Training set accuracy: {accuracy}, F1 Score: {f1}\")\n",
    "accuracy, f1 = check_accuracy(test_loader, model)\n",
    "print(f\"Test set accuracy: {accuracy}, F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the model on the congressional voting dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>handicapped-infants</th>\n",
       "      <th>water-project-cost-sharing</th>\n",
       "      <th>adoption-of-the-budget-resolution</th>\n",
       "      <th>physician-fee-freeze</th>\n",
       "      <th>el-salvador-aid</th>\n",
       "      <th>religious-groups-in-schools</th>\n",
       "      <th>anti-satellite-test-ban</th>\n",
       "      <th>aid-to-nicaraguan-contras</th>\n",
       "      <th>mx-missile</th>\n",
       "      <th>immigration</th>\n",
       "      <th>synfuels-crporation-cutback</th>\n",
       "      <th>education-spending</th>\n",
       "      <th>superfund-right-to-sue</th>\n",
       "      <th>crime</th>\n",
       "      <th>duty-free-exports</th>\n",
       "      <th>export-administration-act-south-africa</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>140</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>383</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>297</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>309</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID  handicapped-infants  water-project-cost-sharing  \\\n",
       "0  140                  1.0                         0.0   \n",
       "1  383                  1.0                         1.0   \n",
       "2  201                  0.0                         0.0   \n",
       "3  297                  0.0                         0.0   \n",
       "4  309                  0.0                         0.0   \n",
       "\n",
       "   adoption-of-the-budget-resolution  physician-fee-freeze  el-salvador-aid  \\\n",
       "0                                1.0                   0.0              0.0   \n",
       "1                                0.0                   1.0              1.0   \n",
       "2                                1.0                   0.0              0.0   \n",
       "3                                1.0                   1.0              1.0   \n",
       "4                                0.0                   1.0              1.0   \n",
       "\n",
       "   religious-groups-in-schools  anti-satellite-test-ban  \\\n",
       "0                          1.0                      1.0   \n",
       "1                          1.0                      0.0   \n",
       "2                          0.0                      1.0   \n",
       "3                          1.0                      0.0   \n",
       "4                          1.0                      0.0   \n",
       "\n",
       "   aid-to-nicaraguan-contras  mx-missile  immigration  \\\n",
       "0                        1.0         1.0          0.0   \n",
       "1                        0.0         0.0          0.0   \n",
       "2                        1.0         1.0          0.0   \n",
       "3                        0.0         0.0          1.0   \n",
       "4                        0.0         0.0          1.0   \n",
       "\n",
       "   synfuels-crporation-cutback  education-spending  superfund-right-to-sue  \\\n",
       "0                          0.0                 0.0                     0.0   \n",
       "1                          1.0                 0.0                     1.0   \n",
       "2                          0.0                 0.0                     0.0   \n",
       "3                          0.0                 1.0                     1.0   \n",
       "4                          0.0                 1.0                     1.0   \n",
       "\n",
       "   crime  duty-free-exports  export-administration-act-south-africa  class  \n",
       "0    0.0                1.0                                     1.0      1  \n",
       "1    1.0                0.0                                     1.0      1  \n",
       "2    1.0                1.0                                     1.0      1  \n",
       "3    1.0                1.0                                     1.0      0  \n",
       "4    1.0                0.0                                     0.0      0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cong_voting = pd.read_csv('./preprocessed-datasets/CongressionVoting_prepro.csv')\n",
    "# encode class value democrat as 1 and republican as 0\n",
    "cong_voting['class'] = cong_voting['class'].map({'democrat': 1, 'republican': 0})\n",
    "cong_voting.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting the dataset into training and testing sets, converting to PyTorch tensors and creating PyTorch DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_Y, test_X, test_Y = train_test_split(cong_voting, \"class\", return_torch=True)\n",
    "\n",
    "dataset = TensorDataset(train_X, train_Y)\n",
    "train_loader = DataLoader(dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "dataset = TensorDataset(test_X, test_Y)\n",
    "test_loader = DataLoader(dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the model, training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Average Loss: 0.8204039831956228\n",
      "Epoch 2/10, Average Loss: 0.6987561484177908\n",
      "Epoch 3/10, Average Loss: 0.6630964974562327\n",
      "Epoch 4/10, Average Loss: 0.5736254205306371\n",
      "Epoch 5/10, Average Loss: 0.4424210687478383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Average Loss: 0.396044726173083\n",
      "Epoch 7/10, Average Loss: 0.2974789614478747\n",
      "Epoch 8/10, Average Loss: 0.2279231697320938\n",
      "Epoch 9/10, Average Loss: 0.22331865628560385\n",
      "Epoch 10/10, Average Loss: 0.37387768800059956\n",
      "Training set accuracy: 0.9597701149425287, F1 Score: 0.9592267251527329\n",
      "Test set accuracy: 0.8604651162790697, F1 Score: 0.8583056478405315\n"
     ]
    }
   ],
   "source": [
    "input_size = train_X.shape[1] # number of features in congr voting dataset\n",
    "NumbOfClasses = 2 # 2 classes in congr voting dataset\n",
    "learning_rate = 0.01\n",
    "batch_size = 64\n",
    "num_epochs = 10\n",
    "hidden_layer_sizes = [25,30]\n",
    "activation_function = F.tanh\n",
    "\n",
    "model = NN(input_size=train_X.shape[1], num_classes=NumbOfClasses, hidden_layer_sizes=hidden_layer_sizes, activation_function=activation_function)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "train_model(model, train_loader, optimizer, criterion, num_epochs)\n",
    "\n",
    "accuracy, f1 = check_accuracy(train_loader, model)\n",
    "print(f\"Training set accuracy: {accuracy}, F1 Score: {f1}\")\n",
    "accuracy, f1 = check_accuracy(test_loader, model)\n",
    "print(f\"Test set accuracy: {accuracy}, F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the model on bank marketing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading and preparing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_marketing = pd.read_csv('./preprocessed-datasets/bank_marketing_prepro.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>...</th>\n",
       "      <th>education_basic.9y</th>\n",
       "      <th>education_high.school</th>\n",
       "      <th>education_illiterate</th>\n",
       "      <th>education_professional.course</th>\n",
       "      <th>education_university.degree</th>\n",
       "      <th>education_unknown</th>\n",
       "      <th>poutcome_failure</th>\n",
       "      <th>poutcome_nonexistent</th>\n",
       "      <th>poutcome_success</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  default  housing  loan  campaign  pdays  previous  emp.var.rate  \\\n",
       "0   56      0.0      0.0   0.0         1    999         0           1.1   \n",
       "1   57      0.0      0.0   0.0         1    999         0           1.1   \n",
       "2   37      0.0      1.0   0.0         1    999         0           1.1   \n",
       "3   40      0.0      0.0   0.0         1    999         0           1.1   \n",
       "4   56      0.0      0.0   1.0         1    999         0           1.1   \n",
       "\n",
       "   cons.price.idx  cons.conf.idx  ...  education_basic.9y  \\\n",
       "0          93.994          -36.4  ...                   0   \n",
       "1          93.994          -36.4  ...                   0   \n",
       "2          93.994          -36.4  ...                   0   \n",
       "3          93.994          -36.4  ...                   0   \n",
       "4          93.994          -36.4  ...                   0   \n",
       "\n",
       "   education_high.school  education_illiterate  education_professional.course  \\\n",
       "0                      0                     0                              0   \n",
       "1                      1                     0                              0   \n",
       "2                      1                     0                              0   \n",
       "3                      0                     0                              0   \n",
       "4                      1                     0                              0   \n",
       "\n",
       "   education_university.degree  education_unknown  poutcome_failure  \\\n",
       "0                            0                  0                 0   \n",
       "1                            0                  0                 0   \n",
       "2                            0                  0                 0   \n",
       "3                            0                  0                 0   \n",
       "4                            0                  0                 0   \n",
       "\n",
       "   poutcome_nonexistent  poutcome_success  class  \n",
       "0                     1                 0      0  \n",
       "1                     1                 0      0  \n",
       "2                     1                 0      0  \n",
       "3                     1                 0      0  \n",
       "4                     1                 0      0  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_to_move = 'class'\n",
    "\n",
    "# Move class to the last index\n",
    "columns = [col for col in bank_marketing.columns if col != column_to_move] + [column_to_move]\n",
    "bank_marketing = bank_marketing[columns]\n",
    "\n",
    "bank_marketing.drop('Unnamed: 0', axis=1,inplace=True)\n",
    "\n",
    "bank_marketing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'default', 'housing', 'loan', 'campaign', 'pdays', 'previous',\n",
       "       'emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m',\n",
       "       'nr.employed', 'job_blue-collar', 'job_management', 'job_other',\n",
       "       'job_self-employed', 'job_serivces', 'job_technician',\n",
       "       'marital_divorced', 'marital_married', 'marital_single',\n",
       "       'marital_unknown', 'education_basic.4y', 'education_basic.6y',\n",
       "       'education_basic.9y', 'education_high.school', 'education_illiterate',\n",
       "       'education_professional.course', 'education_university.degree',\n",
       "       'education_unknown', 'poutcome_failure', 'poutcome_nonexistent',\n",
       "       'poutcome_success', 'class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank_marketing.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting the dataset into training and testing sets, converting to PyTorch tensors and creating PyTorch DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_Y, test_X, test_Y = train_test_split(bank_marketing, \"class\", return_torch=True)\n",
    "\n",
    "dataset = TensorDataset(train_X, train_Y)\n",
    "train_loader = DataLoader(dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "dataset = TensorDataset(test_X, test_Y)\n",
    "test_loader = DataLoader(dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the model, training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25, Average Loss: 0.3309118606186318\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m criterion \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m     12\u001b[0m optimizer \u001b[39m=\u001b[39m optim\u001b[39m.\u001b[39mAdam(model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39mlearning_rate)\n\u001b[0;32m---> 14\u001b[0m train_model(model, train_loader, optimizer, criterion, num_epochs)\n\u001b[1;32m     16\u001b[0m accuracy, f1 \u001b[39m=\u001b[39m check_accuracy(train_loader, model)\n\u001b[1;32m     17\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTraining set accuracy: \u001b[39m\u001b[39m{\u001b[39;00maccuracy\u001b[39m}\u001b[39;00m\u001b[39m, F1 Score: \u001b[39m\u001b[39m{\u001b[39;00mf1\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/MachineLearning23ws/Exercise2/nn_implementation.py:58\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, optimizer, criterion, num_epochs)\u001b[0m\n\u001b[1;32m     55\u001b[0m total_loss \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m  \u001b[39m# Initialize total loss for the epoch\u001b[39;00m\n\u001b[1;32m     56\u001b[0m num_batches \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(train_loader)\n\u001b[0;32m---> 58\u001b[0m \u001b[39mfor\u001b[39;49;00m batch_idx, (data, targets) \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(train_loader):\n\u001b[1;32m     59\u001b[0m     data \u001b[39m=\u001b[39;49m data\u001b[39m.\u001b[39;49mreshape(data\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39;49m], \u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     61\u001b[0m     scores \u001b[39m=\u001b[39;49m model(data)\n",
      "File \u001b[0;32m~/MachineLearning23ws/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    631\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/MachineLearning23ws/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/MachineLearning23ws/.venv/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;49;00m idx \u001b[39min\u001b[39;49;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/MachineLearning23ws/.venv/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "input_size = train_X.shape[1] \n",
    "NumbOfClasses = 2 \n",
    "learning_rate = 0.01\n",
    "batch_size = 64\n",
    "num_epochs = 10\n",
    "hidden_layer_sizes = [25,30]\n",
    "activation_function = F.tanh\n",
    "\n",
    "model = NN(input_size=train_X.shape[1], num_classes=NumbOfClasses, hidden_layer_sizes=hidden_layer_sizes, activation_function=activation_function)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "train_model(model, train_loader, optimizer, criterion, num_epochs)\n",
    "\n",
    "accuracy, f1 = check_accuracy(train_loader, model)\n",
    "print(f\"Training set accuracy: {accuracy}, F1 Score: {f1}\")\n",
    "accuracy, f1 = check_accuracy(test_loader, model)\n",
    "print(f\"Test set accuracy: {accuracy}, F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Grid search over all three datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It was not possible for us to iterate over all datasets because of the large amount of runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bank Marketing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Average Loss: 0.30895951283209533\n",
      "Epoch 2/10, Average Loss: 0.28735410527696886\n",
      "Epoch 3/10, Average Loss: 0.28536031419791064\n",
      "Epoch 4/10, Average Loss: 0.283694635852448\n",
      "Epoch 5/10, Average Loss: 0.28263048726378137\n",
      "Epoch 6/10, Average Loss: 0.28143955136387094\n",
      "Epoch 7/10, Average Loss: 0.28098883524681756\n",
      "Epoch 8/10, Average Loss: 0.2809191710306603\n",
      "Epoch 9/10, Average Loss: 0.2809496916468861\n",
      "Epoch 10/10, Average Loss: 0.2810058439385544\n",
      "Epoch 1/10, Average Loss: 0.3128876335412553\n",
      "Epoch 2/10, Average Loss: 0.29042269303960705\n",
      "Epoch 3/10, Average Loss: 0.2876893164752756\n",
      "Epoch 4/10, Average Loss: 0.2868161084727176\n",
      "Epoch 5/10, Average Loss: 0.28492116279972407\n",
      "Epoch 6/10, Average Loss: 0.28500315247519503\n",
      "Epoch 7/10, Average Loss: 0.2842394628137061\n",
      "Epoch 8/10, Average Loss: 0.2834020783600298\n",
      "Epoch 9/10, Average Loss: 0.28343992003248736\n",
      "Epoch 10/10, Average Loss: 0.28344538245096945\n",
      "Epoch 1/10, Average Loss: 0.3112315728681759\n",
      "Epoch 2/10, Average Loss: 0.28723683377492776\n",
      "Epoch 3/10, Average Loss: 0.2850546772763567\n",
      "Epoch 4/10, Average Loss: 0.2832905932392889\n",
      "Epoch 5/10, Average Loss: 0.2811239642136305\n",
      "Epoch 6/10, Average Loss: 0.28109776108588985\n",
      "Epoch 7/10, Average Loss: 0.2810682715142815\n",
      "Epoch 8/10, Average Loss: 0.27998942411640315\n",
      "Epoch 9/10, Average Loss: 0.2802820530475922\n",
      "Epoch 10/10, Average Loss: 0.27942993285007844\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 26\u001b[0m\n\u001b[1;32m     22\u001b[0m input_size \u001b[39m=\u001b[39m train_X\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n\u001b[1;32m     24\u001b[0m NumbOfClasses \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m\n\u001b[0;32m---> 26\u001b[0m grid_results_bank, best_accuracy, best_combination \u001b[39m=\u001b[39m grid_search_cv(\n\u001b[1;32m     27\u001b[0m     hidden_layer_sizes_list, activation_functions, learning_rates, batch_sizes, num_epochs_list, data_loader, NumbOfClasses,\n\u001b[1;32m     28\u001b[0m     k_folds\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m, use_scaling\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     30\u001b[0m grid_results_bank[\u001b[39m'\u001b[39m\u001b[39mdataset\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mbank_marketing\u001b[39m\u001b[39m'\u001b[39m\n",
      "Cell \u001b[0;32mIn[7], line 40\u001b[0m, in \u001b[0;36mgrid_search_cv\u001b[0;34m(hidden_layer_sizes_list, activation_functions, learning_rates, batch_sizes, num_epochs_list, train_loader, NumbOfClasses, k_folds, use_scaling)\u001b[0m\n\u001b[1;32m     37\u001b[0m     X_train_scaled, X_test_scaled \u001b[39m=\u001b[39m X_train, X_test\n\u001b[1;32m     39\u001b[0m train_start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m---> 40\u001b[0m train_model(model, DataLoader(TensorDataset(X_train_scaled, y_train), batch_size\u001b[39m=\u001b[39;49mbatch_size, shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m), optimizer, criterion, num_epochs)\n\u001b[1;32m     41\u001b[0m train_end_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m     42\u001b[0m fold_training_times\u001b[39m.\u001b[39mappend(train_end_time \u001b[39m-\u001b[39m train_start_time)\n",
      "Cell \u001b[0;32mIn[4], line 6\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, optimizer, criterion, num_epochs)\u001b[0m\n\u001b[1;32m      3\u001b[0m total_loss \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m  \u001b[39m# Initialize total loss for the epoch\u001b[39;00m\n\u001b[1;32m      4\u001b[0m num_batches \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(train_loader)\n\u001b[0;32m----> 6\u001b[0m \u001b[39mfor\u001b[39;49;00m batch_idx, (data, targets) \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(train_loader):\n\u001b[1;32m      7\u001b[0m     data \u001b[39m=\u001b[39;49m data\u001b[39m.\u001b[39;49mreshape(data\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39;49m], \u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m      9\u001b[0m     scores \u001b[39m=\u001b[39;49m model(data)\n",
      "File \u001b[0;32m~/MachineLearning23ws/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:626\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__next__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m--> 626\u001b[0m     \u001b[39mwith\u001b[39;49;00m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mprofiler\u001b[39m.\u001b[39;49mrecord_function(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_profile_name):\n\u001b[1;32m    627\u001b[0m         \u001b[39mif\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sampler_iter \u001b[39mis\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m:\n\u001b[1;32m    628\u001b[0m             \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;49;00m\n\u001b[1;32m    629\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;49;00m\n",
      "File \u001b[0;32m~/MachineLearning23ws/.venv/lib/python3.11/site-packages/torch/autograd/profiler.py:636\u001b[0m, in \u001b[0;36mrecord_function.__exit__\u001b[0;34m(self, exc_type, exc_value, traceback)\u001b[0m\n\u001b[1;32m    631\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrecord \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39m_record_function_enter_new(\n\u001b[1;32m    632\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\n\u001b[1;32m    633\u001b[0m     )\n\u001b[1;32m    634\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n\u001b[0;32m--> 636\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__exit__\u001b[39m(\u001b[39mself\u001b[39m, exc_type: Any, exc_value: Any, traceback: Any):\n\u001b[1;32m    637\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_callbacks_on_exit:\n\u001b[1;32m    638\u001b[0m         \u001b[39mreturn\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hidden_layer_sizes_list = [[5],[10],[25, 30], [20, 25, 30]]\n",
    "activation_functions = [F.tanh, F.relu, F.sigmoid]\n",
    "learning_rates = [0.01, 0.001, 0.0001]\n",
    "batch_sizes = [64]\n",
    "num_epochs_list = [10]\n",
    "\n",
    "dataset = bank_marketing\n",
    "\n",
    "X = dataset.drop([\"class\"], axis=1).values\n",
    "Y = dataset[\"class\"].values\n",
    "data = TensorDataset(torch.tensor(X), torch.tensor(Y))\n",
    "data_loader = DataLoader(data, batch_size=32, shuffle=False)\n",
    "\n",
    "input_size = X.shape[1]\n",
    "\n",
    "NumbOfClasses = 2\n",
    "\n",
    "grid_results_bank, best_f1, best_combination = grid_search_cv(\n",
    "    hidden_layer_sizes_list, activation_functions, learning_rates, batch_sizes, num_epochs_list, data_loader, NumbOfClasses,\n",
    "    k_folds=5, use_scaling=True)\n",
    "\n",
    "grid_results_bank['dataset'] = 'bank_marketing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hidden Layer Sizes</th>\n",
       "      <th>Activation Function</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Batch Size</th>\n",
       "      <th>Number of Epochs</th>\n",
       "      <th>Average Accuracy</th>\n",
       "      <th>Average Training Time</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[5]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.795699</td>\n",
       "      <td>12.364878</td>\n",
       "      <td>bank_marketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[5]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.755577</td>\n",
       "      <td>12.158159</td>\n",
       "      <td>bank_marketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[5]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.718461</td>\n",
       "      <td>11.684069</td>\n",
       "      <td>bank_marketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[5]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.770642</td>\n",
       "      <td>11.399968</td>\n",
       "      <td>bank_marketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[5]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.744679</td>\n",
       "      <td>11.911103</td>\n",
       "      <td>bank_marketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[5]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.731579</td>\n",
       "      <td>11.358967</td>\n",
       "      <td>bank_marketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[5]</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.754432</td>\n",
       "      <td>11.386674</td>\n",
       "      <td>bank_marketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[5]</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.743364</td>\n",
       "      <td>11.465565</td>\n",
       "      <td>bank_marketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[5]</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.735661</td>\n",
       "      <td>11.650078</td>\n",
       "      <td>bank_marketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[10]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.820842</td>\n",
       "      <td>11.603699</td>\n",
       "      <td>bank_marketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[10]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.789909</td>\n",
       "      <td>11.624668</td>\n",
       "      <td>bank_marketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[10]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.739316</td>\n",
       "      <td>12.741981</td>\n",
       "      <td>bank_marketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[10]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.828306</td>\n",
       "      <td>13.050930</td>\n",
       "      <td>bank_marketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[10]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.787347</td>\n",
       "      <td>12.218218</td>\n",
       "      <td>bank_marketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[10]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.743689</td>\n",
       "      <td>12.164853</td>\n",
       "      <td>bank_marketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[10]</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.800021</td>\n",
       "      <td>11.437619</td>\n",
       "      <td>bank_marketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[10]</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.745875</td>\n",
       "      <td>11.027652</td>\n",
       "      <td>bank_marketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[10]</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.737984</td>\n",
       "      <td>11.467428</td>\n",
       "      <td>bank_marketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[25, 30]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.841219</td>\n",
       "      <td>13.201574</td>\n",
       "      <td>bank_marketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[25, 30]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.829553</td>\n",
       "      <td>13.100218</td>\n",
       "      <td>bank_marketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[25, 30]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.742766</td>\n",
       "      <td>13.141413</td>\n",
       "      <td>bank_marketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[25, 30]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.852202</td>\n",
       "      <td>14.773023</td>\n",
       "      <td>bank_marketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[25, 30]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.822550</td>\n",
       "      <td>13.486950</td>\n",
       "      <td>bank_marketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[25, 30]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.748574</td>\n",
       "      <td>13.379348</td>\n",
       "      <td>bank_marketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[25, 30]</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.839425</td>\n",
       "      <td>13.288525</td>\n",
       "      <td>bank_marketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[25, 30]</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.749838</td>\n",
       "      <td>13.303207</td>\n",
       "      <td>bank_marketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[25, 30]</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.740375</td>\n",
       "      <td>287.427189</td>\n",
       "      <td>bank_marketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[20, 25, 30]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.830287</td>\n",
       "      <td>15.945419</td>\n",
       "      <td>bank_marketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[20, 25, 30]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.819424</td>\n",
       "      <td>16.959366</td>\n",
       "      <td>bank_marketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[20, 25, 30]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.741468</td>\n",
       "      <td>17.706601</td>\n",
       "      <td>bank_marketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[20, 25, 30]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.841663</td>\n",
       "      <td>17.163013</td>\n",
       "      <td>bank_marketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[20, 25, 30]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.827725</td>\n",
       "      <td>17.058871</td>\n",
       "      <td>bank_marketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[20, 25, 30]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.747481</td>\n",
       "      <td>17.138449</td>\n",
       "      <td>bank_marketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[20, 25, 30]</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.832132</td>\n",
       "      <td>17.476922</td>\n",
       "      <td>bank_marketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[20, 25, 30]</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.748727</td>\n",
       "      <td>18.439620</td>\n",
       "      <td>bank_marketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[20, 25, 30]</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.742869</td>\n",
       "      <td>18.202122</td>\n",
       "      <td>bank_marketing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Hidden Layer Sizes Activation Function  Learning Rate  Batch Size  \\\n",
       "0                 [5]                tanh         0.0100          64   \n",
       "1                 [5]                tanh         0.0010          64   \n",
       "2                 [5]                tanh         0.0001          64   \n",
       "3                 [5]                relu         0.0100          64   \n",
       "4                 [5]                relu         0.0010          64   \n",
       "5                 [5]                relu         0.0001          64   \n",
       "6                 [5]             sigmoid         0.0100          64   \n",
       "7                 [5]             sigmoid         0.0010          64   \n",
       "8                 [5]             sigmoid         0.0001          64   \n",
       "9                [10]                tanh         0.0100          64   \n",
       "10               [10]                tanh         0.0010          64   \n",
       "11               [10]                tanh         0.0001          64   \n",
       "12               [10]                relu         0.0100          64   \n",
       "13               [10]                relu         0.0010          64   \n",
       "14               [10]                relu         0.0001          64   \n",
       "15               [10]             sigmoid         0.0100          64   \n",
       "16               [10]             sigmoid         0.0010          64   \n",
       "17               [10]             sigmoid         0.0001          64   \n",
       "18           [25, 30]                tanh         0.0100          64   \n",
       "19           [25, 30]                tanh         0.0010          64   \n",
       "20           [25, 30]                tanh         0.0001          64   \n",
       "21           [25, 30]                relu         0.0100          64   \n",
       "22           [25, 30]                relu         0.0010          64   \n",
       "23           [25, 30]                relu         0.0001          64   \n",
       "24           [25, 30]             sigmoid         0.0100          64   \n",
       "25           [25, 30]             sigmoid         0.0010          64   \n",
       "26           [25, 30]             sigmoid         0.0001          64   \n",
       "27       [20, 25, 30]                tanh         0.0100          64   \n",
       "28       [20, 25, 30]                tanh         0.0010          64   \n",
       "29       [20, 25, 30]                tanh         0.0001          64   \n",
       "30       [20, 25, 30]                relu         0.0100          64   \n",
       "31       [20, 25, 30]                relu         0.0010          64   \n",
       "32       [20, 25, 30]                relu         0.0001          64   \n",
       "33       [20, 25, 30]             sigmoid         0.0100          64   \n",
       "34       [20, 25, 30]             sigmoid         0.0010          64   \n",
       "35       [20, 25, 30]             sigmoid         0.0001          64   \n",
       "\n",
       "    Number of Epochs  Average Accuracy  Average Training Time         dataset  \n",
       "0                 10          0.795699              12.364878  bank_marketing  \n",
       "1                 10          0.755577              12.158159  bank_marketing  \n",
       "2                 10          0.718461              11.684069  bank_marketing  \n",
       "3                 10          0.770642              11.399968  bank_marketing  \n",
       "4                 10          0.744679              11.911103  bank_marketing  \n",
       "5                 10          0.731579              11.358967  bank_marketing  \n",
       "6                 10          0.754432              11.386674  bank_marketing  \n",
       "7                 10          0.743364              11.465565  bank_marketing  \n",
       "8                 10          0.735661              11.650078  bank_marketing  \n",
       "9                 10          0.820842              11.603699  bank_marketing  \n",
       "10                10          0.789909              11.624668  bank_marketing  \n",
       "11                10          0.739316              12.741981  bank_marketing  \n",
       "12                10          0.828306              13.050930  bank_marketing  \n",
       "13                10          0.787347              12.218218  bank_marketing  \n",
       "14                10          0.743689              12.164853  bank_marketing  \n",
       "15                10          0.800021              11.437619  bank_marketing  \n",
       "16                10          0.745875              11.027652  bank_marketing  \n",
       "17                10          0.737984              11.467428  bank_marketing  \n",
       "18                10          0.841219              13.201574  bank_marketing  \n",
       "19                10          0.829553              13.100218  bank_marketing  \n",
       "20                10          0.742766              13.141413  bank_marketing  \n",
       "21                10          0.852202              14.773023  bank_marketing  \n",
       "22                10          0.822550              13.486950  bank_marketing  \n",
       "23                10          0.748574              13.379348  bank_marketing  \n",
       "24                10          0.839425              13.288525  bank_marketing  \n",
       "25                10          0.749838              13.303207  bank_marketing  \n",
       "26                10          0.740375             287.427189  bank_marketing  \n",
       "27                10          0.830287              15.945419  bank_marketing  \n",
       "28                10          0.819424              16.959366  bank_marketing  \n",
       "29                10          0.741468              17.706601  bank_marketing  \n",
       "30                10          0.841663              17.163013  bank_marketing  \n",
       "31                10          0.827725              17.058871  bank_marketing  \n",
       "32                10          0.747481              17.138449  bank_marketing  \n",
       "33                10          0.832132              17.476922  bank_marketing  \n",
       "34                10          0.748727              18.439620  bank_marketing  \n",
       "35                10          0.742869              18.202122  bank_marketing  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_results_bank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wine quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Average Loss: 2.139833171193193\n",
      "Epoch 2/10, Average Loss: 2.036203986260949\n",
      "Epoch 3/10, Average Loss: 2.009973778957274\n",
      "Epoch 4/10, Average Loss: 1.9749669040121682\n",
      "Epoch 5/10, Average Loss: 1.948377251625061\n",
      "Epoch 6/10, Average Loss: 1.9383421961854144\n",
      "Epoch 7/10, Average Loss: 1.9312357059339198\n",
      "Epoch 8/10, Average Loss: 1.9251614968951156\n",
      "Epoch 9/10, Average Loss: 1.9228179382114876\n",
      "Epoch 10/10, Average Loss: 1.919748586852376\n",
      "Epoch 1/10, Average Loss: 2.1393754496807005\n",
      "Epoch 2/10, Average Loss: 2.0301392601757513\n",
      "Epoch 3/10, Average Loss: 1.999662078008419\n",
      "Epoch 4/10, Average Loss: 1.9640896393031608\n",
      "Epoch 5/10, Average Loss: 1.9477385820412054\n",
      "Epoch 6/10, Average Loss: 1.9411988360125845\n",
      "Epoch 7/10, Average Loss: 1.9298798936169321\n",
      "Epoch 8/10, Average Loss: 1.9242776675922115\n",
      "Epoch 9/10, Average Loss: 1.9181502490508846\n",
      "Epoch 10/10, Average Loss: 1.9116715294558828\n",
      "Epoch 1/10, Average Loss: 2.135673844232792\n",
      "Epoch 2/10, Average Loss: 2.030358060104091\n",
      "Epoch 3/10, Average Loss: 1.9975956402173856\n",
      "Epoch 4/10, Average Loss: 1.9596018355067184\n",
      "Epoch 5/10, Average Loss: 1.9465302737747752\n",
      "Epoch 6/10, Average Loss: 1.9364163861042116\n",
      "Epoch 7/10, Average Loss: 1.9290874236967506\n",
      "Epoch 8/10, Average Loss: 1.9251694533883073\n",
      "Epoch 9/10, Average Loss: 1.9226782888900944\n",
      "Epoch 10/10, Average Loss: 1.9204572875325272\n",
      "Epoch 1/10, Average Loss: 2.133174330722995\n",
      "Epoch 2/10, Average Loss: 2.0237901196247194\n",
      "Epoch 3/10, Average Loss: 2.003518902673954\n",
      "Epoch 4/10, Average Loss: 1.977966629877323\n",
      "Epoch 5/10, Average Loss: 1.9537079959380916\n",
      "Epoch 6/10, Average Loss: 1.9386484826483377\n",
      "Epoch 7/10, Average Loss: 1.9283050792973215\n",
      "Epoch 8/10, Average Loss: 1.9260853659815904\n",
      "Epoch 9/10, Average Loss: 1.9259573570111903\n",
      "Epoch 10/10, Average Loss: 1.9216290857733749\n",
      "Epoch 1/10, Average Loss: 2.1423318168012107\n",
      "Epoch 2/10, Average Loss: 2.028897070303196\n",
      "Epoch 3/10, Average Loss: 1.9945186769090049\n",
      "Epoch 4/10, Average Loss: 1.964112358849223\n",
      "Epoch 5/10, Average Loss: 1.9566596164935972\n",
      "Epoch 6/10, Average Loss: 1.9523183630733956\n",
      "Epoch 7/10, Average Loss: 1.9441523929921591\n",
      "Epoch 8/10, Average Loss: 1.9413257299399957\n",
      "Epoch 9/10, Average Loss: 1.9373273907638178\n",
      "Epoch 10/10, Average Loss: 1.935850499606714\n",
      "Epoch 1/10, Average Loss: 2.256925100233497\n",
      "Epoch 2/10, Average Loss: 2.2121608635274375\n",
      "Epoch 3/10, Average Loss: 2.1700063275127874\n",
      "Epoch 4/10, Average Loss: 2.143970754088425\n",
      "Epoch 5/10, Average Loss: 2.1237589382543796\n",
      "Epoch 6/10, Average Loss: 2.1108849688274103\n",
      "Epoch 7/10, Average Loss: 2.099570246731363\n",
      "Epoch 8/10, Average Loss: 2.085001356718017\n",
      "Epoch 9/10, Average Loss: 2.0611675527037643\n",
      "Epoch 10/10, Average Loss: 2.043860394780229\n",
      "Epoch 1/10, Average Loss: 2.2584884341170146\n",
      "Epoch 2/10, Average Loss: 2.209671561310931\n",
      "Epoch 3/10, Average Loss: 2.1696449954335284\n",
      "Epoch 4/10, Average Loss: 2.1402993289435783\n",
      "Epoch 5/10, Average Loss: 2.1209336504703615\n",
      "Epoch 6/10, Average Loss: 2.106861261332907\n",
      "Epoch 7/10, Average Loss: 2.092308502371718\n",
      "Epoch 8/10, Average Loss: 2.070544271934323\n",
      "Epoch 9/10, Average Loss: 2.051489728253062\n",
      "Epoch 10/10, Average Loss: 2.0356142826196626\n",
      "Epoch 1/10, Average Loss: 2.2592653414098227\n",
      "Epoch 2/10, Average Loss: 2.2116186182673383\n",
      "Epoch 3/10, Average Loss: 2.1681389139919744\n",
      "Epoch 4/10, Average Loss: 2.136755562410122\n",
      "Epoch 5/10, Average Loss: 2.1167214934418843\n",
      "Epoch 6/10, Average Loss: 2.100023368509804\n",
      "Epoch 7/10, Average Loss: 2.0844524619055957\n",
      "Epoch 8/10, Average Loss: 2.0588704638364836\n",
      "Epoch 9/10, Average Loss: 2.042944362977656\n",
      "Epoch 10/10, Average Loss: 2.0312177786012975\n",
      "Epoch 1/10, Average Loss: 2.2607121758344695\n",
      "Epoch 2/10, Average Loss: 2.2129154786830996\n",
      "Epoch 3/10, Average Loss: 2.1681255421987395\n",
      "Epoch 4/10, Average Loss: 2.1389380315454996\n",
      "Epoch 5/10, Average Loss: 2.116177739166632\n",
      "Epoch 6/10, Average Loss: 2.103889895648491\n",
      "Epoch 7/10, Average Loss: 2.0900048090190424\n",
      "Epoch 8/10, Average Loss: 2.0678913520603643\n",
      "Epoch 9/10, Average Loss: 2.0491603830965555\n",
      "Epoch 10/10, Average Loss: 2.0362022577262504\n",
      "Epoch 1/10, Average Loss: 2.25894416541588\n",
      "Epoch 2/10, Average Loss: 2.2121130518796965\n",
      "Epoch 3/10, Average Loss: 2.1705428652647063\n",
      "Epoch 4/10, Average Loss: 2.1401886765549825\n",
      "Epoch 5/10, Average Loss: 2.1218973107454255\n",
      "Epoch 6/10, Average Loss: 2.1033335880535406\n",
      "Epoch 7/10, Average Loss: 2.0828923873785063\n",
      "Epoch 8/10, Average Loss: 2.057573148390142\n",
      "Epoch 9/10, Average Loss: 2.0409154935580927\n",
      "Epoch 10/10, Average Loss: 2.033539255944694\n",
      "Epoch 1/10, Average Loss: 2.2783004510693434\n",
      "Epoch 2/10, Average Loss: 2.2748669298683724\n",
      "Epoch 3/10, Average Loss: 2.2701326230677163\n",
      "Epoch 4/10, Average Loss: 2.266365647315979\n",
      "Epoch 5/10, Average Loss: 2.2615148265187335\n",
      "Epoch 6/10, Average Loss: 2.2564315708672127\n",
      "Epoch 7/10, Average Loss: 2.2514657828865983\n",
      "Epoch 8/10, Average Loss: 2.24758147902605\n",
      "Epoch 9/10, Average Loss: 2.242864867536033\n",
      "Epoch 10/10, Average Loss: 2.238173205678056\n",
      "Epoch 1/10, Average Loss: 2.2797924919826227\n",
      "Epoch 2/10, Average Loss: 2.274265580061005\n",
      "Epoch 3/10, Average Loss: 2.2699901388912664\n",
      "Epoch 4/10, Average Loss: 2.2659514182951392\n",
      "Epoch 5/10, Average Loss: 2.2612223799635722\n",
      "Epoch 6/10, Average Loss: 2.2564802402403297\n",
      "Epoch 7/10, Average Loss: 2.251098856693361\n",
      "Epoch 8/10, Average Loss: 2.246028911776659\n",
      "Epoch 9/10, Average Loss: 2.2423551460591757\n",
      "Epoch 10/10, Average Loss: 2.2361491976714714\n",
      "Epoch 1/10, Average Loss: 2.2806725327561543\n",
      "Epoch 2/10, Average Loss: 2.275928936353544\n",
      "Epoch 3/10, Average Loss: 2.270652916373276\n",
      "Epoch 4/10, Average Loss: 2.26568880895289\n",
      "Epoch 5/10, Average Loss: 2.260951841749796\n",
      "Epoch 6/10, Average Loss: 2.2553356042722377\n",
      "Epoch 7/10, Average Loss: 2.2516800543157065\n",
      "Epoch 8/10, Average Loss: 2.2462650043208425\n",
      "Epoch 9/10, Average Loss: 2.24186792024752\n",
      "Epoch 10/10, Average Loss: 2.235896119257299\n",
      "Epoch 1/10, Average Loss: 2.281148954135616\n",
      "Epoch 2/10, Average Loss: 2.276836683110493\n",
      "Epoch 3/10, Average Loss: 2.2710644646388727\n",
      "Epoch 4/10, Average Loss: 2.2671943873893925\n",
      "Epoch 5/10, Average Loss: 2.261253941349867\n",
      "Epoch 6/10, Average Loss: 2.2572789599255816\n",
      "Epoch 7/10, Average Loss: 2.2524512424701597\n",
      "Epoch 8/10, Average Loss: 2.2470359162586493\n",
      "Epoch 9/10, Average Loss: 2.243115050036733\n",
      "Epoch 10/10, Average Loss: 2.2372278178610454\n",
      "Epoch 1/10, Average Loss: 2.280100604382957\n",
      "Epoch 2/10, Average Loss: 2.2753476776727815\n",
      "Epoch 3/10, Average Loss: 2.2706406378164523\n",
      "Epoch 4/10, Average Loss: 2.2658152027827936\n",
      "Epoch 5/10, Average Loss: 2.2617747405680215\n",
      "Epoch 6/10, Average Loss: 2.255683233098286\n",
      "Epoch 7/10, Average Loss: 2.2512235408876\n",
      "Epoch 8/10, Average Loss: 2.2465993776554014\n",
      "Epoch 9/10, Average Loss: 2.2418784978913098\n",
      "Epoch 10/10, Average Loss: 2.2375767405440166\n",
      "Epoch 1/10, Average Loss: 2.178384366558819\n",
      "Epoch 2/10, Average Loss: 1.966825232273195\n",
      "Epoch 3/10, Average Loss: 1.9294656660498641\n",
      "Epoch 4/10, Average Loss: 1.9178598232385589\n",
      "Epoch 5/10, Average Loss: 1.9062747446502126\n",
      "Epoch 6/10, Average Loss: 1.9063944235080625\n",
      "Epoch 7/10, Average Loss: 1.9015133061060092\n",
      "Epoch 8/10, Average Loss: 1.8984926633718537\n",
      "Epoch 9/10, Average Loss: 1.897157560034496\n",
      "Epoch 10/10, Average Loss: 1.8954281821483518\n",
      "Epoch 1/10, Average Loss: 2.1763673570097946\n",
      "Epoch 2/10, Average Loss: 1.9683369252739884\n",
      "Epoch 3/10, Average Loss: 1.9367936631528342\n",
      "Epoch 4/10, Average Loss: 1.9174788637859066\n",
      "Epoch 5/10, Average Loss: 1.9072906563921672\n",
      "Epoch 6/10, Average Loss: 1.904077929694478\n",
      "Epoch 7/10, Average Loss: 1.8991094260680965\n",
      "Epoch 8/10, Average Loss: 1.8987730930491191\n",
      "Epoch 9/10, Average Loss: 1.8977762504321773\n",
      "Epoch 10/10, Average Loss: 1.8939885395329172\n",
      "Epoch 1/10, Average Loss: 2.180752398037329\n",
      "Epoch 2/10, Average Loss: 1.9666241145715482\n",
      "Epoch 3/10, Average Loss: 1.9307014084443814\n",
      "Epoch 4/10, Average Loss: 1.9202846332294186\n",
      "Epoch 5/10, Average Loss: 1.9153875868494918\n",
      "Epoch 6/10, Average Loss: 1.908324775172443\n",
      "Epoch 7/10, Average Loss: 1.9059160177300616\n",
      "Epoch 8/10, Average Loss: 1.9033927612188386\n",
      "Epoch 9/10, Average Loss: 1.9001629512484481\n",
      "Epoch 10/10, Average Loss: 1.901101414750262\n",
      "Epoch 1/10, Average Loss: 2.1842575102317623\n",
      "Epoch 2/10, Average Loss: 1.9758279890548893\n",
      "Epoch 3/10, Average Loss: 1.9387481212615967\n",
      "Epoch 4/10, Average Loss: 1.9209357354699113\n",
      "Epoch 5/10, Average Loss: 1.9094559085078355\n",
      "Epoch 6/10, Average Loss: 1.906647222798045\n",
      "Epoch 7/10, Average Loss: 1.9025021762382694\n",
      "Epoch 8/10, Average Loss: 1.9012277635132395\n",
      "Epoch 9/10, Average Loss: 1.8994985731636607\n",
      "Epoch 10/10, Average Loss: 1.8971834895087452\n",
      "Epoch 1/10, Average Loss: 2.1804028444173857\n",
      "Epoch 2/10, Average Loss: 1.9752407684558775\n",
      "Epoch 3/10, Average Loss: 1.9478649947701432\n",
      "Epoch 4/10, Average Loss: 1.9340804262859066\n",
      "Epoch 5/10, Average Loss: 1.9252554352690534\n",
      "Epoch 6/10, Average Loss: 1.9162436665558233\n",
      "Epoch 7/10, Average Loss: 1.9129664781616955\n",
      "Epoch 8/10, Average Loss: 1.9084420233238033\n",
      "Epoch 9/10, Average Loss: 1.903303879063304\n",
      "Epoch 10/10, Average Loss: 1.9032933639317025\n",
      "Epoch 1/10, Average Loss: 2.332506842729522\n",
      "Epoch 2/10, Average Loss: 2.3053453928086816\n",
      "Epoch 3/10, Average Loss: 2.26719920809676\n",
      "Epoch 4/10, Average Loss: 2.2067924214572443\n",
      "Epoch 5/10, Average Loss: 2.1583236339615612\n",
      "Epoch 6/10, Average Loss: 2.117305962050833\n",
      "Epoch 7/10, Average Loss: 2.080842547300385\n",
      "Epoch 8/10, Average Loss: 2.0484919911477624\n",
      "Epoch 9/10, Average Loss: 2.0197759227054877\n",
      "Epoch 10/10, Average Loss: 1.999461969224418\n",
      "Epoch 1/10, Average Loss: 2.333057511143568\n",
      "Epoch 2/10, Average Loss: 2.304838974301408\n",
      "Epoch 3/10, Average Loss: 2.2644584644131545\n",
      "Epoch 4/10, Average Loss: 2.202442419238207\n",
      "Epoch 5/10, Average Loss: 2.1570826507196195\n",
      "Epoch 6/10, Average Loss: 2.119050281803782\n",
      "Epoch 7/10, Average Loss: 2.0823616647138827\n",
      "Epoch 8/10, Average Loss: 2.0501281822600017\n",
      "Epoch 9/10, Average Loss: 2.0250300532434045\n",
      "Epoch 10/10, Average Loss: 2.002947961411825\n",
      "Epoch 1/10, Average Loss: 2.332743670882248\n",
      "Epoch 2/10, Average Loss: 2.3051883970818867\n",
      "Epoch 3/10, Average Loss: 2.267084720658093\n",
      "Epoch 4/10, Average Loss: 2.208579874620205\n",
      "Epoch 5/10, Average Loss: 2.1590935980401387\n",
      "Epoch 6/10, Average Loss: 2.1185112610095884\n",
      "Epoch 7/10, Average Loss: 2.080973866509228\n",
      "Epoch 8/10, Average Loss: 2.044950982419456\n",
      "Epoch 9/10, Average Loss: 2.0182164703927388\n",
      "Epoch 10/10, Average Loss: 1.9992940745702603\n",
      "Epoch 1/10, Average Loss: 2.3336767772348916\n",
      "Epoch 2/10, Average Loss: 2.3058016707257525\n",
      "Epoch 3/10, Average Loss: 2.267137129132341\n",
      "Epoch 4/10, Average Loss: 2.2083061642763093\n",
      "Epoch 5/10, Average Loss: 2.159834070903499\n",
      "Epoch 6/10, Average Loss: 2.121218916846485\n",
      "Epoch 7/10, Average Loss: 2.08262491807705\n",
      "Epoch 8/10, Average Loss: 2.048898906242557\n",
      "Epoch 9/10, Average Loss: 2.0223213216153586\n",
      "Epoch 10/10, Average Loss: 2.0050585051862204\n",
      "Epoch 1/10, Average Loss: 2.3339249273625815\n",
      "Epoch 2/10, Average Loss: 2.305631721892008\n",
      "Epoch 3/10, Average Loss: 2.265473979275401\n",
      "Epoch 4/10, Average Loss: 2.206003872359671\n",
      "Epoch 5/10, Average Loss: 2.1580409189549887\n",
      "Epoch 6/10, Average Loss: 2.119614269675278\n",
      "Epoch 7/10, Average Loss: 2.0824415959962983\n",
      "Epoch 8/10, Average Loss: 2.0516147235544717\n",
      "Epoch 9/10, Average Loss: 2.023419665127266\n",
      "Epoch 10/10, Average Loss: 2.0071093803498803\n",
      "Epoch 1/10, Average Loss: 2.3441622606137904\n",
      "Epoch 2/10, Average Loss: 2.3418704155014782\n",
      "Epoch 3/10, Average Loss: 2.339751766949165\n",
      "Epoch 4/10, Average Loss: 2.3370940307291543\n",
      "Epoch 5/10, Average Loss: 2.334425571488171\n",
      "Epoch 6/10, Average Loss: 2.331447275673471\n",
      "Epoch 7/10, Average Loss: 2.3290873039059523\n",
      "Epoch 8/10, Average Loss: 2.326233282321837\n",
      "Epoch 9/10, Average Loss: 2.323965758812137\n",
      "Epoch 10/10, Average Loss: 2.3210747823482607\n",
      "Epoch 1/10, Average Loss: 2.344931457100845\n",
      "Epoch 2/10, Average Loss: 2.3425136688278942\n",
      "Epoch 3/10, Average Loss: 2.34005797490841\n",
      "Epoch 4/10, Average Loss: 2.3369189675261333\n",
      "Epoch 5/10, Average Loss: 2.3343052224415106\n",
      "Epoch 6/10, Average Loss: 2.3320570893403962\n",
      "Epoch 7/10, Average Loss: 2.3293743278922103\n",
      "Epoch 8/10, Average Loss: 2.3257703257770075\n",
      "Epoch 9/10, Average Loss: 2.3238186516412873\n",
      "Epoch 10/10, Average Loss: 2.321315884590149\n",
      "Epoch 1/10, Average Loss: 2.344178542858217\n",
      "Epoch 2/10, Average Loss: 2.3415372022768346\n",
      "Epoch 3/10, Average Loss: 2.338690932204084\n",
      "Epoch 4/10, Average Loss: 2.336509181231987\n",
      "Epoch 5/10, Average Loss: 2.333855570816412\n",
      "Epoch 6/10, Average Loss: 2.331279475514482\n",
      "Epoch 7/10, Average Loss: 2.329005514703146\n",
      "Epoch 8/10, Average Loss: 2.3260703203154773\n",
      "Epoch 9/10, Average Loss: 2.3236139140477996\n",
      "Epoch 10/10, Average Loss: 2.3207419616420095\n",
      "Epoch 1/10, Average Loss: 2.345298104169892\n",
      "Epoch 2/10, Average Loss: 2.342932203920876\n",
      "Epoch 3/10, Average Loss: 2.3401426338567966\n",
      "Epoch 4/10, Average Loss: 2.3374632160838056\n",
      "Epoch 5/10, Average Loss: 2.3347235656366117\n",
      "Epoch 6/10, Average Loss: 2.3322380926550887\n",
      "Epoch 7/10, Average Loss: 2.3295007566126382\n",
      "Epoch 8/10, Average Loss: 2.3266508259424348\n",
      "Epoch 9/10, Average Loss: 2.3242770927708323\n",
      "Epoch 10/10, Average Loss: 2.3215003478817824\n",
      "Epoch 1/10, Average Loss: 2.34538496412882\n",
      "Epoch 2/10, Average Loss: 2.342451999827129\n",
      "Epoch 3/10, Average Loss: 2.339819707521578\n",
      "Epoch 4/10, Average Loss: 2.3375934246109753\n",
      "Epoch 5/10, Average Loss: 2.335028020347037\n",
      "Epoch 6/10, Average Loss: 2.332343999932452\n",
      "Epoch 7/10, Average Loss: 2.3298191791627465\n",
      "Epoch 8/10, Average Loss: 2.3273087943472515\n",
      "Epoch 9/10, Average Loss: 2.324652256035223\n",
      "Epoch 10/10, Average Loss: 2.3218280803866502\n",
      "Epoch 1/10, Average Loss: 2.14910722069624\n",
      "Epoch 2/10, Average Loss: 1.9792091017816125\n",
      "Epoch 3/10, Average Loss: 1.946107253795717\n",
      "Epoch 4/10, Average Loss: 1.9359792180177642\n",
      "Epoch 5/10, Average Loss: 1.928136985476424\n",
      "Epoch 6/10, Average Loss: 1.92744145887654\n",
      "Epoch 7/10, Average Loss: 1.9251432753190763\n",
      "Epoch 8/10, Average Loss: 1.9240420155408906\n",
      "Epoch 9/10, Average Loss: 1.9225509399321021\n",
      "Epoch 10/10, Average Loss: 1.9214920619638955\n",
      "Epoch 1/10, Average Loss: 2.15148378145404\n",
      "Epoch 2/10, Average Loss: 1.9797134195886008\n",
      "Epoch 3/10, Average Loss: 1.9517734021675297\n",
      "Epoch 4/10, Average Loss: 1.9372008282963822\n",
      "Epoch 5/10, Average Loss: 1.9318444496247826\n",
      "Epoch 6/10, Average Loss: 1.928982080482855\n",
      "Epoch 7/10, Average Loss: 1.9244736738321258\n",
      "Epoch 8/10, Average Loss: 1.9250483963547684\n",
      "Epoch 9/10, Average Loss: 1.9245961177639845\n",
      "Epoch 10/10, Average Loss: 1.9223525262460477\n",
      "Epoch 1/10, Average Loss: 2.1531409984681664\n",
      "Epoch 2/10, Average Loss: 1.9810353183164828\n",
      "Epoch 3/10, Average Loss: 1.949412630825508\n",
      "Epoch 4/10, Average Loss: 1.9372669996284857\n",
      "Epoch 5/10, Average Loss: 1.9306970573053128\n",
      "Epoch 6/10, Average Loss: 1.9279733285671328\n",
      "Epoch 7/10, Average Loss: 1.923757611251459\n",
      "Epoch 8/10, Average Loss: 1.9239853867670385\n",
      "Epoch 9/10, Average Loss: 1.9224838861605016\n",
      "Epoch 10/10, Average Loss: 1.9220436825984861\n",
      "Epoch 1/10, Average Loss: 2.1533602737798923\n",
      "Epoch 2/10, Average Loss: 1.97922189351989\n",
      "Epoch 3/10, Average Loss: 1.950605456422015\n",
      "Epoch 4/10, Average Loss: 1.9389037606192798\n",
      "Epoch 5/10, Average Loss: 1.9316315447411887\n",
      "Epoch 6/10, Average Loss: 1.9298073867472207\n",
      "Epoch 7/10, Average Loss: 1.9278739879770976\n",
      "Epoch 8/10, Average Loss: 1.9271788364503442\n",
      "Epoch 9/10, Average Loss: 1.9285493231401212\n",
      "Epoch 10/10, Average Loss: 1.9254046664005373\n",
      "Epoch 1/10, Average Loss: 2.153652525529629\n",
      "Epoch 2/10, Average Loss: 1.985125233487385\n",
      "Epoch 3/10, Average Loss: 1.955140653179913\n",
      "Epoch 4/10, Average Loss: 1.9437360647248059\n",
      "Epoch 5/10, Average Loss: 1.9382434647257736\n",
      "Epoch 6/10, Average Loss: 1.9324676481688894\n",
      "Epoch 7/10, Average Loss: 1.9311479489977768\n",
      "Epoch 8/10, Average Loss: 1.9289811471613443\n",
      "Epoch 9/10, Average Loss: 1.92647101820969\n",
      "Epoch 10/10, Average Loss: 1.9265440440759427\n",
      "Epoch 1/10, Average Loss: 2.31140555986544\n",
      "Epoch 2/10, Average Loss: 2.276463095734759\n",
      "Epoch 3/10, Average Loss: 2.2335681246548162\n",
      "Epoch 4/10, Average Loss: 2.1793206901085087\n",
      "Epoch 5/10, Average Loss: 2.126534706208764\n",
      "Epoch 6/10, Average Loss: 2.0880486616274205\n",
      "Epoch 7/10, Average Loss: 2.060880432768566\n",
      "Epoch 8/10, Average Loss: 2.039853596105808\n",
      "Epoch 9/10, Average Loss: 2.023232063142265\n",
      "Epoch 10/10, Average Loss: 2.009996409823255\n",
      "Epoch 1/10, Average Loss: 2.3120945808364124\n",
      "Epoch 2/10, Average Loss: 2.2770373879409416\n",
      "Epoch 3/10, Average Loss: 2.234321283131111\n",
      "Epoch 4/10, Average Loss: 2.1811279087531856\n",
      "Epoch 5/10, Average Loss: 2.128012200681175\n",
      "Epoch 6/10, Average Loss: 2.0888473900353035\n",
      "Epoch 7/10, Average Loss: 2.061172200412285\n",
      "Epoch 8/10, Average Loss: 2.0398105760899985\n",
      "Epoch 9/10, Average Loss: 2.024477929603763\n",
      "Epoch 10/10, Average Loss: 2.0101569105939165\n",
      "Epoch 1/10, Average Loss: 2.3118401475069\n",
      "Epoch 2/10, Average Loss: 2.2774733363128288\n",
      "Epoch 3/10, Average Loss: 2.2351377359250697\n",
      "Epoch 4/10, Average Loss: 2.182011267034019\n",
      "Epoch 5/10, Average Loss: 2.129149160734037\n",
      "Epoch 6/10, Average Loss: 2.089105768901546\n",
      "Epoch 7/10, Average Loss: 2.0605484974093553\n",
      "Epoch 8/10, Average Loss: 2.037981540691562\n",
      "Epoch 9/10, Average Loss: 2.0213337962220357\n",
      "Epoch 10/10, Average Loss: 2.008261916114063\n",
      "Epoch 1/10, Average Loss: 2.31216231788077\n",
      "Epoch 2/10, Average Loss: 2.2773881888971097\n",
      "Epoch 3/10, Average Loss: 2.2350378676158624\n",
      "Epoch 4/10, Average Loss: 2.18215207065024\n",
      "Epoch 5/10, Average Loss: 2.1294482801018693\n",
      "Epoch 6/10, Average Loss: 2.0896279114048655\n",
      "Epoch 7/10, Average Loss: 2.0612483431653277\n",
      "Epoch 8/10, Average Loss: 2.039160790966778\n",
      "Epoch 9/10, Average Loss: 2.023528013287521\n",
      "Epoch 10/10, Average Loss: 2.008950403550776\n",
      "Epoch 1/10, Average Loss: 2.312170107190202\n",
      "Epoch 2/10, Average Loss: 2.277236589571325\n",
      "Epoch 3/10, Average Loss: 2.2341462170205464\n",
      "Epoch 4/10, Average Loss: 2.181380734211061\n",
      "Epoch 5/10, Average Loss: 2.1288920001285834\n",
      "Epoch 6/10, Average Loss: 2.0903194939217915\n",
      "Epoch 7/10, Average Loss: 2.0617951779830745\n",
      "Epoch 8/10, Average Loss: 2.0406536256394734\n",
      "Epoch 9/10, Average Loss: 2.0233741809682146\n",
      "Epoch 10/10, Average Loss: 2.0113606598319076\n",
      "Epoch 1/10, Average Loss: 2.3251343471247976\n",
      "Epoch 2/10, Average Loss: 2.3222395414259376\n",
      "Epoch 3/10, Average Loss: 2.319766777317698\n",
      "Epoch 4/10, Average Loss: 2.3165097352935047\n",
      "Epoch 5/10, Average Loss: 2.3133073114767306\n",
      "Epoch 6/10, Average Loss: 2.310044445642611\n",
      "Epoch 7/10, Average Loss: 2.3067872960393023\n",
      "Epoch 8/10, Average Loss: 2.3034990240887896\n",
      "Epoch 9/10, Average Loss: 2.3000609932876213\n",
      "Epoch 10/10, Average Loss: 2.2965175146009864\n",
      "Epoch 1/10, Average Loss: 2.3257221681315725\n",
      "Epoch 2/10, Average Loss: 2.3229684248203184\n",
      "Epoch 3/10, Average Loss: 2.3199021699951916\n",
      "Epoch 4/10, Average Loss: 2.3167418590406093\n",
      "Epoch 5/10, Average Loss: 2.3135684844924183\n",
      "Epoch 6/10, Average Loss: 2.3105721415542977\n",
      "Epoch 7/10, Average Loss: 2.307329782625524\n",
      "Epoch 8/10, Average Loss: 2.3037635058891484\n",
      "Epoch 9/10, Average Loss: 2.300387184794356\n",
      "Epoch 10/10, Average Loss: 2.2970214936791398\n",
      "Epoch 1/10, Average Loss: 2.325408415096562\n",
      "Epoch 2/10, Average Loss: 2.3226690321433834\n",
      "Epoch 3/10, Average Loss: 2.319586785828195\n",
      "Epoch 4/10, Average Loss: 2.3167949653253324\n",
      "Epoch 5/10, Average Loss: 2.313646229302011\n",
      "Epoch 6/10, Average Loss: 2.310391074273644\n",
      "Epoch 7/10, Average Loss: 2.3073649173829613\n",
      "Epoch 8/10, Average Loss: 2.303934213591785\n",
      "Epoch 9/10, Average Loss: 2.3004590563657805\n",
      "Epoch 10/10, Average Loss: 2.29697674367486\n",
      "Epoch 1/10, Average Loss: 2.325870039986401\n",
      "Epoch 2/10, Average Loss: 2.3230987380190595\n",
      "Epoch 3/10, Average Loss: 2.320035803608778\n",
      "Epoch 4/10, Average Loss: 2.317002369136345\n",
      "Epoch 5/10, Average Loss: 2.313924062542799\n",
      "Epoch 6/10, Average Loss: 2.310708438477865\n",
      "Epoch 7/10, Average Loss: 2.3073991885999354\n",
      "Epoch 8/10, Average Loss: 2.303976463108528\n",
      "Epoch 9/10, Average Loss: 2.3003531665336796\n",
      "Epoch 10/10, Average Loss: 2.297296759558887\n",
      "Epoch 1/10, Average Loss: 2.3256981430984123\n",
      "Epoch 2/10, Average Loss: 2.3227909687088757\n",
      "Epoch 3/10, Average Loss: 2.3197642390320943\n",
      "Epoch 4/10, Average Loss: 2.3168584428182464\n",
      "Epoch 5/10, Average Loss: 2.3137059647862506\n",
      "Epoch 6/10, Average Loss: 2.3106542651246236\n",
      "Epoch 7/10, Average Loss: 2.3074868161503863\n",
      "Epoch 8/10, Average Loss: 2.3041617027143153\n",
      "Epoch 9/10, Average Loss: 2.300567379811915\n",
      "Epoch 10/10, Average Loss: 2.2970817903193033\n",
      "Epoch 1/10, Average Loss: 2.110765692664356\n",
      "Epoch 2/10, Average Loss: 1.9837458075546637\n",
      "Epoch 3/10, Average Loss: 1.946934346745654\n",
      "Epoch 4/10, Average Loss: 1.9274026053707773\n",
      "Epoch 5/10, Average Loss: 1.9173485520409375\n",
      "Epoch 6/10, Average Loss: 1.9052644255684643\n",
      "Epoch 7/10, Average Loss: 1.9034558185716954\n",
      "Epoch 8/10, Average Loss: 1.8957721213015115\n",
      "Epoch 9/10, Average Loss: 1.8967177809738531\n",
      "Epoch 10/10, Average Loss: 1.8924174468691757\n",
      "Epoch 1/10, Average Loss: 2.1030762370039775\n",
      "Epoch 2/10, Average Loss: 1.9624154902086026\n",
      "Epoch 3/10, Average Loss: 1.9271284341812134\n",
      "Epoch 4/10, Average Loss: 1.9109627459107377\n",
      "Epoch 5/10, Average Loss: 1.9063335119224176\n",
      "Epoch 6/10, Average Loss: 1.9008041198660688\n",
      "Epoch 7/10, Average Loss: 1.896502122646425\n",
      "Epoch 8/10, Average Loss: 1.8963920066996318\n",
      "Epoch 9/10, Average Loss: 1.8926678212677561\n",
      "Epoch 10/10, Average Loss: 1.8899726867675781\n",
      "Epoch 1/10, Average Loss: 2.104292913181026\n",
      "Epoch 2/10, Average Loss: 1.9679867029190063\n",
      "Epoch 3/10, Average Loss: 1.9410886284781665\n",
      "Epoch 4/10, Average Loss: 1.920108520403141\n",
      "Epoch 5/10, Average Loss: 1.9087126240497683\n",
      "Epoch 6/10, Average Loss: 1.9045317056702404\n",
      "Epoch 7/10, Average Loss: 1.899605573677435\n",
      "Epoch 8/10, Average Loss: 1.9008398463086384\n",
      "Epoch 9/10, Average Loss: 1.8955115705001644\n",
      "Epoch 10/10, Average Loss: 1.8961430191993713\n",
      "Epoch 1/10, Average Loss: 2.103784343091453\n",
      "Epoch 2/10, Average Loss: 1.958790626467728\n",
      "Epoch 3/10, Average Loss: 1.937375891499403\n",
      "Epoch 4/10, Average Loss: 1.922851133637312\n",
      "Epoch 5/10, Average Loss: 1.9120431367943926\n",
      "Epoch 6/10, Average Loss: 1.9084482265681755\n",
      "Epoch 7/10, Average Loss: 1.9088106039093762\n",
      "Epoch 8/10, Average Loss: 1.9057572120573463\n",
      "Epoch 9/10, Average Loss: 1.8990540446304693\n",
      "Epoch 10/10, Average Loss: 1.8993614170609452\n",
      "Epoch 1/10, Average Loss: 2.118124681275065\n",
      "Epoch 2/10, Average Loss: 1.96129526161566\n",
      "Epoch 3/10, Average Loss: 1.9384056489642074\n",
      "Epoch 4/10, Average Loss: 1.9210484216852886\n",
      "Epoch 5/10, Average Loss: 1.9154043095867808\n",
      "Epoch 6/10, Average Loss: 1.9097892234965068\n",
      "Epoch 7/10, Average Loss: 1.9070574379548795\n",
      "Epoch 8/10, Average Loss: 1.9076646464626963\n",
      "Epoch 9/10, Average Loss: 1.9038629313794577\n",
      "Epoch 10/10, Average Loss: 1.901787156012\n",
      "Epoch 1/10, Average Loss: 2.2721749485992806\n",
      "Epoch 2/10, Average Loss: 2.2201385730650367\n",
      "Epoch 3/10, Average Loss: 2.1739955181028785\n",
      "Epoch 4/10, Average Loss: 2.127917941023664\n",
      "Epoch 5/10, Average Loss: 2.079128954468704\n",
      "Epoch 6/10, Average Loss: 2.0381863640575872\n",
      "Epoch 7/10, Average Loss: 2.016761426518603\n",
      "Epoch 8/10, Average Loss: 1.9996542872452154\n",
      "Epoch 9/10, Average Loss: 1.9903579194371293\n",
      "Epoch 10/10, Average Loss: 1.9810091853141785\n",
      "Epoch 1/10, Average Loss: 2.2686714399151686\n",
      "Epoch 2/10, Average Loss: 2.217495578091319\n",
      "Epoch 3/10, Average Loss: 2.171718155465475\n",
      "Epoch 4/10, Average Loss: 2.1250623639036967\n",
      "Epoch 5/10, Average Loss: 2.07387443577371\n",
      "Epoch 6/10, Average Loss: 2.0371280981273188\n",
      "Epoch 7/10, Average Loss: 2.01627501627294\n",
      "Epoch 8/10, Average Loss: 2.003251748840983\n",
      "Epoch 9/10, Average Loss: 1.9930761267499226\n",
      "Epoch 10/10, Average Loss: 1.9841278137230292\n",
      "Epoch 1/10, Average Loss: 2.272084800208487\n",
      "Epoch 2/10, Average Loss: 2.221369528188938\n",
      "Epoch 3/10, Average Loss: 2.174756041387232\n",
      "Epoch 4/10, Average Loss: 2.1268535198234932\n",
      "Epoch 5/10, Average Loss: 2.076840753962354\n",
      "Epoch 6/10, Average Loss: 2.0355347671159882\n",
      "Epoch 7/10, Average Loss: 2.0140093405072284\n",
      "Epoch 8/10, Average Loss: 2.0015004451681926\n",
      "Epoch 9/10, Average Loss: 1.9918107172337973\n",
      "Epoch 10/10, Average Loss: 1.9849384223542563\n",
      "Epoch 1/10, Average Loss: 2.271286193917437\n",
      "Epoch 2/10, Average Loss: 2.217537414736864\n",
      "Epoch 3/10, Average Loss: 2.1696424280724873\n",
      "Epoch 4/10, Average Loss: 2.1249572184027694\n",
      "Epoch 5/10, Average Loss: 2.0751644707307584\n",
      "Epoch 6/10, Average Loss: 2.0354124307632446\n",
      "Epoch 7/10, Average Loss: 2.01265785606896\n",
      "Epoch 8/10, Average Loss: 1.999360953889242\n",
      "Epoch 9/10, Average Loss: 1.9879575807873795\n",
      "Epoch 10/10, Average Loss: 1.9799121429280537\n",
      "Epoch 1/10, Average Loss: 2.268042671971205\n",
      "Epoch 2/10, Average Loss: 2.2161393863398855\n",
      "Epoch 3/10, Average Loss: 2.1723723963993353\n",
      "Epoch 4/10, Average Loss: 2.1289738067766515\n",
      "Epoch 5/10, Average Loss: 2.0825632955969833\n",
      "Epoch 6/10, Average Loss: 2.0418383479118347\n",
      "Epoch 7/10, Average Loss: 2.0187753279034686\n",
      "Epoch 8/10, Average Loss: 2.0049343370809787\n",
      "Epoch 9/10, Average Loss: 1.9946065356091756\n",
      "Epoch 10/10, Average Loss: 1.9836644399456862\n",
      "Epoch 1/10, Average Loss: 2.2982897525880395\n",
      "Epoch 2/10, Average Loss: 2.292647940356557\n",
      "Epoch 3/10, Average Loss: 2.2865711450576782\n",
      "Epoch 4/10, Average Loss: 2.280887461290127\n",
      "Epoch 5/10, Average Loss: 2.275159478187561\n",
      "Epoch 6/10, Average Loss: 2.268735359354717\n",
      "Epoch 7/10, Average Loss: 2.2626175647828637\n",
      "Epoch 8/10, Average Loss: 2.2567868029198994\n",
      "Epoch 9/10, Average Loss: 2.2522920922535223\n",
      "Epoch 10/10, Average Loss: 2.246219716420988\n",
      "Epoch 1/10, Average Loss: 2.295808222235703\n",
      "Epoch 2/10, Average Loss: 2.290543242198665\n",
      "Epoch 3/10, Average Loss: 2.283884039739283\n",
      "Epoch 4/10, Average Loss: 2.2782859162586493\n",
      "Epoch 5/10, Average Loss: 2.270774030103916\n",
      "Epoch 6/10, Average Loss: 2.265424219573416\n",
      "Epoch 7/10, Average Loss: 2.2591911903241786\n",
      "Epoch 8/10, Average Loss: 2.253602379705848\n",
      "Epoch 9/10, Average Loss: 2.248465482781573\n",
      "Epoch 10/10, Average Loss: 2.2429980446652666\n",
      "Epoch 1/10, Average Loss: 2.2971341464577653\n",
      "Epoch 2/10, Average Loss: 2.29176972842798\n",
      "Epoch 3/10, Average Loss: 2.2848916635280703\n",
      "Epoch 4/10, Average Loss: 2.2785502090686705\n",
      "Epoch 5/10, Average Loss: 2.2726188869011112\n",
      "Epoch 6/10, Average Loss: 2.2675868563535735\n",
      "Epoch 7/10, Average Loss: 2.2612970166090056\n",
      "Epoch 8/10, Average Loss: 2.255230915255663\n",
      "Epoch 9/10, Average Loss: 2.250696365426226\n",
      "Epoch 10/10, Average Loss: 2.2455250170172714\n",
      "Epoch 1/10, Average Loss: 2.2969331654106697\n",
      "Epoch 2/10, Average Loss: 2.2908793745971305\n",
      "Epoch 3/10, Average Loss: 2.2839086724490656\n",
      "Epoch 4/10, Average Loss: 2.278271448321459\n",
      "Epoch 5/10, Average Loss: 2.27181727420993\n",
      "Epoch 6/10, Average Loss: 2.2663003031800435\n",
      "Epoch 7/10, Average Loss: 2.259648366672237\n",
      "Epoch 8/10, Average Loss: 2.2546158651026285\n",
      "Epoch 9/10, Average Loss: 2.2489791730555093\n",
      "Epoch 10/10, Average Loss: 2.242989339479586\n",
      "Epoch 1/10, Average Loss: 2.2948357390194403\n",
      "Epoch 2/10, Average Loss: 2.2897079194464336\n",
      "Epoch 3/10, Average Loss: 2.283123039617771\n",
      "Epoch 4/10, Average Loss: 2.276960320589019\n",
      "Epoch 5/10, Average Loss: 2.2709239256091234\n",
      "Epoch 6/10, Average Loss: 2.2658433652505643\n",
      "Epoch 7/10, Average Loss: 2.259182647960942\n",
      "Epoch 8/10, Average Loss: 2.25358485303274\n",
      "Epoch 9/10, Average Loss: 2.2488042494145835\n",
      "Epoch 10/10, Average Loss: 2.2415446188391708\n",
      "Epoch 1/10, Average Loss: 2.0327356879304097\n",
      "Epoch 2/10, Average Loss: 1.941821178285087\n",
      "Epoch 3/10, Average Loss: 1.9251413592478124\n",
      "Epoch 4/10, Average Loss: 1.9163805856937315\n",
      "Epoch 5/10, Average Loss: 1.9062248264870993\n",
      "Epoch 6/10, Average Loss: 1.9006908521419619\n",
      "Epoch 7/10, Average Loss: 1.898487637682659\n",
      "Epoch 8/10, Average Loss: 1.8944181131153572\n",
      "Epoch 9/10, Average Loss: 1.895390304123483\n",
      "Epoch 10/10, Average Loss: 1.8943597558068066\n",
      "Epoch 1/10, Average Loss: 2.0313768939274115\n",
      "Epoch 2/10, Average Loss: 1.942091925842006\n",
      "Epoch 3/10, Average Loss: 1.9266923244406537\n",
      "Epoch 4/10, Average Loss: 1.9163012097521526\n",
      "Epoch 5/10, Average Loss: 1.9107886901715907\n",
      "Epoch 6/10, Average Loss: 1.9025375290614803\n",
      "Epoch 7/10, Average Loss: 1.8955687357158195\n",
      "Epoch 8/10, Average Loss: 1.8961233554816828\n",
      "Epoch 9/10, Average Loss: 1.8899746333680503\n",
      "Epoch 10/10, Average Loss: 1.8877512042115374\n",
      "Epoch 1/10, Average Loss: 2.031973933301321\n",
      "Epoch 2/10, Average Loss: 1.9404503659504215\n",
      "Epoch 3/10, Average Loss: 1.9235805302131466\n",
      "Epoch 4/10, Average Loss: 1.913983263620516\n",
      "Epoch 5/10, Average Loss: 1.904559743113634\n",
      "Epoch 6/10, Average Loss: 1.9020376205444336\n",
      "Epoch 7/10, Average Loss: 1.8968066107936021\n",
      "Epoch 8/10, Average Loss: 1.896531062882121\n",
      "Epoch 9/10, Average Loss: 1.8919824303650274\n",
      "Epoch 10/10, Average Loss: 1.8925082843478134\n",
      "Epoch 1/10, Average Loss: 2.033009283426331\n",
      "Epoch 2/10, Average Loss: 1.9443033264904488\n",
      "Epoch 3/10, Average Loss: 1.9267858572122527\n",
      "Epoch 4/10, Average Loss: 1.913324097307717\n",
      "Epoch 5/10, Average Loss: 1.9015748122843301\n",
      "Epoch 6/10, Average Loss: 1.8978325491998254\n",
      "Epoch 7/10, Average Loss: 1.89842121484803\n",
      "Epoch 8/10, Average Loss: 1.895689689531559\n",
      "Epoch 9/10, Average Loss: 1.8894605767436143\n",
      "Epoch 10/10, Average Loss: 1.890909194946289\n",
      "Epoch 1/10, Average Loss: 2.030829906463623\n",
      "Epoch 2/10, Average Loss: 1.942271657106353\n",
      "Epoch 3/10, Average Loss: 1.9288749316843545\n",
      "Epoch 4/10, Average Loss: 1.9228910425814187\n",
      "Epoch 5/10, Average Loss: 1.9123162292852633\n",
      "Epoch 6/10, Average Loss: 1.9092683646737076\n",
      "Epoch 7/10, Average Loss: 1.9069393175404246\n",
      "Epoch 8/10, Average Loss: 1.9030734882122133\n",
      "Epoch 9/10, Average Loss: 1.901801908888468\n",
      "Epoch 10/10, Average Loss: 1.899635069253968\n",
      "Epoch 1/10, Average Loss: 2.2092375871611805\n",
      "Epoch 2/10, Average Loss: 2.120824630667524\n",
      "Epoch 3/10, Average Loss: 2.0518165012685263\n",
      "Epoch 4/10, Average Loss: 2.016339617531474\n",
      "Epoch 5/10, Average Loss: 2.0011309138158473\n",
      "Epoch 6/10, Average Loss: 1.9882400035858154\n",
      "Epoch 7/10, Average Loss: 1.9778762765047027\n",
      "Epoch 8/10, Average Loss: 1.9662659807903011\n",
      "Epoch 9/10, Average Loss: 1.9591917075761935\n",
      "Epoch 10/10, Average Loss: 1.9516056441679233\n",
      "Epoch 1/10, Average Loss: 2.20640230178833\n",
      "Epoch 2/10, Average Loss: 2.1199389783347526\n",
      "Epoch 3/10, Average Loss: 2.051044011988291\n",
      "Epoch 4/10, Average Loss: 2.0146478545374986\n",
      "Epoch 5/10, Average Loss: 1.99983766747684\n",
      "Epoch 6/10, Average Loss: 1.9881684576592795\n",
      "Epoch 7/10, Average Loss: 1.9776288300025753\n",
      "Epoch 8/10, Average Loss: 1.9688803161062844\n",
      "Epoch 9/10, Average Loss: 1.9589249346314408\n",
      "Epoch 10/10, Average Loss: 1.9525066556000128\n",
      "Epoch 1/10, Average Loss: 2.2105545299809153\n",
      "Epoch 2/10, Average Loss: 2.1247430821744406\n",
      "Epoch 3/10, Average Loss: 2.0532031553547556\n",
      "Epoch 4/10, Average Loss: 2.0124729479231487\n",
      "Epoch 5/10, Average Loss: 1.9948137068166965\n",
      "Epoch 6/10, Average Loss: 1.9865839248750268\n",
      "Epoch 7/10, Average Loss: 1.9790507278791287\n",
      "Epoch 8/10, Average Loss: 1.9719553124613878\n",
      "Epoch 9/10, Average Loss: 1.9622397350101937\n",
      "Epoch 10/10, Average Loss: 1.9557687465737505\n",
      "Epoch 1/10, Average Loss: 2.209123277082676\n",
      "Epoch 2/10, Average Loss: 2.119552965571241\n",
      "Epoch 3/10, Average Loss: 2.050484397062441\n",
      "Epoch 4/10, Average Loss: 2.013266707338938\n",
      "Epoch 5/10, Average Loss: 1.994167909389589\n",
      "Epoch 6/10, Average Loss: 1.9855057466320876\n",
      "Epoch 7/10, Average Loss: 1.9787801576823723\n",
      "Epoch 8/10, Average Loss: 1.9698691717008265\n",
      "Epoch 9/10, Average Loss: 1.9598580933198697\n",
      "Epoch 10/10, Average Loss: 1.9557905924029466\n",
      "Epoch 1/10, Average Loss: 2.206617558874735\n",
      "Epoch 2/10, Average Loss: 2.117806892569472\n",
      "Epoch 3/10, Average Loss: 2.050564623460537\n",
      "Epoch 4/10, Average Loss: 2.014495464359842\n",
      "Epoch 5/10, Average Loss: 1.9995213209128961\n",
      "Epoch 6/10, Average Loss: 1.9892096853837735\n",
      "Epoch 7/10, Average Loss: 1.9815000499167092\n",
      "Epoch 8/10, Average Loss: 1.9726648490603378\n",
      "Epoch 9/10, Average Loss: 1.9652767123245611\n",
      "Epoch 10/10, Average Loss: 1.9571769150292002\n",
      "Epoch 1/10, Average Loss: 2.253486019809072\n",
      "Epoch 2/10, Average Loss: 2.243016399988314\n",
      "Epoch 3/10, Average Loss: 2.2328184494158116\n",
      "Epoch 4/10, Average Loss: 2.22293974422827\n",
      "Epoch 5/10, Average Loss: 2.2138009245802714\n",
      "Epoch 6/10, Average Loss: 2.204671737624378\n",
      "Epoch 7/10, Average Loss: 2.194565778825341\n",
      "Epoch 8/10, Average Loss: 2.185183888528405\n",
      "Epoch 9/10, Average Loss: 2.176859823668875\n",
      "Epoch 10/10, Average Loss: 2.167757941455376\n",
      "Epoch 1/10, Average Loss: 2.2512069446284597\n",
      "Epoch 2/10, Average Loss: 2.241417085252157\n",
      "Epoch 3/10, Average Loss: 2.2306355877620416\n",
      "Epoch 4/10, Average Loss: 2.22118086058919\n",
      "Epoch 5/10, Average Loss: 2.211112612631263\n",
      "Epoch 6/10, Average Loss: 2.2017624959713076\n",
      "Epoch 7/10, Average Loss: 2.1928066480450514\n",
      "Epoch 8/10, Average Loss: 2.183945961114837\n",
      "Epoch 9/10, Average Loss: 2.1751223482736726\n",
      "Epoch 10/10, Average Loss: 2.1663540020221617\n",
      "Epoch 1/10, Average Loss: 2.2527381879527395\n",
      "Epoch 2/10, Average Loss: 2.2420778594365935\n",
      "Epoch 3/10, Average Loss: 2.2315976328966096\n",
      "Epoch 4/10, Average Loss: 2.220627371857806\n",
      "Epoch 5/10, Average Loss: 2.2107751136872826\n",
      "Epoch 6/10, Average Loss: 2.202954205071054\n",
      "Epoch 7/10, Average Loss: 2.1936473032323325\n",
      "Epoch 8/10, Average Loss: 2.184756947726738\n",
      "Epoch 9/10, Average Loss: 2.1767840443587883\n",
      "Epoch 10/10, Average Loss: 2.1671097831028265\n",
      "Epoch 1/10, Average Loss: 2.2528195410239986\n",
      "Epoch 2/10, Average Loss: 2.2409869635977397\n",
      "Epoch 3/10, Average Loss: 2.2311824211260167\n",
      "Epoch 4/10, Average Loss: 2.2212736257692662\n",
      "Epoch 5/10, Average Loss: 2.2107991707034227\n",
      "Epoch 6/10, Average Loss: 2.2028757973415094\n",
      "Epoch 7/10, Average Loss: 2.1932661765959205\n",
      "Epoch 8/10, Average Loss: 2.184559438286758\n",
      "Epoch 9/10, Average Loss: 2.1754480222376382\n",
      "Epoch 10/10, Average Loss: 2.1663222080323754\n",
      "Epoch 1/10, Average Loss: 2.2500321399874803\n",
      "Epoch 2/10, Average Loss: 2.2390647341565386\n",
      "Epoch 3/10, Average Loss: 2.229074513039938\n",
      "Epoch 4/10, Average Loss: 2.219430339045641\n",
      "Epoch 5/10, Average Loss: 2.2102338191939563\n",
      "Epoch 6/10, Average Loss: 2.2011573169289567\n",
      "Epoch 7/10, Average Loss: 2.1914489065728535\n",
      "Epoch 8/10, Average Loss: 2.1820682985026663\n",
      "Epoch 9/10, Average Loss: 2.1741844037684\n",
      "Epoch 10/10, Average Loss: 2.163952019156479\n",
      "Epoch 1/10, Average Loss: 2.0431309545912395\n",
      "Epoch 2/10, Average Loss: 1.9551766660155319\n",
      "Epoch 3/10, Average Loss: 1.936419766123702\n",
      "Epoch 4/10, Average Loss: 1.9286821760782382\n",
      "Epoch 5/10, Average Loss: 1.9272256435417547\n",
      "Epoch 6/10, Average Loss: 1.922837280645603\n",
      "Epoch 7/10, Average Loss: 1.9219614892471126\n",
      "Epoch 8/10, Average Loss: 1.9209448346277562\n",
      "Epoch 9/10, Average Loss: 1.920670416296982\n",
      "Epoch 10/10, Average Loss: 1.9203285400460406\n",
      "Epoch 1/10, Average Loss: 2.0421859142256946\n",
      "Epoch 2/10, Average Loss: 1.9551998376846313\n",
      "Epoch 3/10, Average Loss: 1.9382868845288346\n",
      "Epoch 4/10, Average Loss: 1.9304696525015481\n",
      "Epoch 5/10, Average Loss: 1.929660315920667\n",
      "Epoch 6/10, Average Loss: 1.9268755476649215\n",
      "Epoch 7/10, Average Loss: 1.9220841410683422\n",
      "Epoch 8/10, Average Loss: 1.9230224853608666\n",
      "Epoch 9/10, Average Loss: 1.9205728216869076\n",
      "Epoch 10/10, Average Loss: 1.9213916135997307\n",
      "Epoch 1/10, Average Loss: 2.0404749948803973\n",
      "Epoch 2/10, Average Loss: 1.9535410069837802\n",
      "Epoch 3/10, Average Loss: 1.9351296468478878\n",
      "Epoch 4/10, Average Loss: 1.9261274512221174\n",
      "Epoch 5/10, Average Loss: 1.9226318190737468\n",
      "Epoch 6/10, Average Loss: 1.9220267577869137\n",
      "Epoch 7/10, Average Loss: 1.9191773402981642\n",
      "Epoch 8/10, Average Loss: 1.92055247324269\n",
      "Epoch 9/10, Average Loss: 1.9167073906921759\n",
      "Epoch 10/10, Average Loss: 1.9182761573209994\n",
      "Epoch 1/10, Average Loss: 2.043458444316213\n",
      "Epoch 2/10, Average Loss: 1.9526048840546026\n",
      "Epoch 3/10, Average Loss: 1.9375195982979565\n",
      "Epoch 4/10, Average Loss: 1.9301992974630215\n",
      "Epoch 5/10, Average Loss: 1.9246659322482784\n",
      "Epoch 6/10, Average Loss: 1.9246326743102655\n",
      "Epoch 7/10, Average Loss: 1.9265408239713528\n",
      "Epoch 8/10, Average Loss: 1.9233104761053876\n",
      "Epoch 9/10, Average Loss: 1.9202004075050354\n",
      "Epoch 10/10, Average Loss: 1.9212341686574423\n",
      "Epoch 1/10, Average Loss: 2.0445017523881868\n",
      "Epoch 2/10, Average Loss: 1.9574397046391556\n",
      "Epoch 3/10, Average Loss: 1.9427675023311521\n",
      "Epoch 4/10, Average Loss: 1.9351965799564268\n",
      "Epoch 5/10, Average Loss: 1.9326777327351454\n",
      "Epoch 6/10, Average Loss: 1.9295742002929128\n",
      "Epoch 7/10, Average Loss: 1.929786576003563\n",
      "Epoch 8/10, Average Loss: 1.9283904142496062\n",
      "Epoch 9/10, Average Loss: 1.9272475795048039\n",
      "Epoch 10/10, Average Loss: 1.9253276470230847\n",
      "Epoch 1/10, Average Loss: 2.223191831170059\n",
      "Epoch 2/10, Average Loss: 2.132911725742061\n",
      "Epoch 3/10, Average Loss: 2.0709769376894323\n",
      "Epoch 4/10, Average Loss: 2.0381052043379806\n",
      "Epoch 5/10, Average Loss: 2.020007302121418\n",
      "Epoch 6/10, Average Loss: 2.0059119564730947\n",
      "Epoch 7/10, Average Loss: 1.9956154881454096\n",
      "Epoch 8/10, Average Loss: 1.9853237867355347\n",
      "Epoch 9/10, Average Loss: 1.9787825825737744\n",
      "Epoch 10/10, Average Loss: 1.9720307530426398\n",
      "Epoch 1/10, Average Loss: 2.2225038888977795\n",
      "Epoch 2/10, Average Loss: 2.1310495806903376\n",
      "Epoch 3/10, Average Loss: 2.0700819434189217\n",
      "Epoch 4/10, Average Loss: 2.036972865825746\n",
      "Epoch 5/10, Average Loss: 2.0201232128027007\n",
      "Epoch 6/10, Average Loss: 2.00645982637638\n",
      "Epoch 7/10, Average Loss: 1.9947052772452192\n",
      "Epoch 8/10, Average Loss: 1.9869936515645283\n",
      "Epoch 9/10, Average Loss: 1.9785729021560856\n",
      "Epoch 10/10, Average Loss: 1.9725513341950207\n",
      "Epoch 1/10, Average Loss: 2.2218104164774823\n",
      "Epoch 2/10, Average Loss: 2.1311329719496936\n",
      "Epoch 3/10, Average Loss: 2.0680771484607603\n",
      "Epoch 4/10, Average Loss: 2.0328059109245857\n",
      "Epoch 5/10, Average Loss: 2.0136444452332287\n",
      "Epoch 6/10, Average Loss: 2.000818867508958\n",
      "Epoch 7/10, Average Loss: 1.9917013368955472\n",
      "Epoch 8/10, Average Loss: 1.983368076929232\n",
      "Epoch 9/10, Average Loss: 1.975213497150235\n",
      "Epoch 10/10, Average Loss: 1.9692476537169479\n",
      "Epoch 1/10, Average Loss: 2.2222200661170772\n",
      "Epoch 2/10, Average Loss: 2.1303992344111933\n",
      "Epoch 3/10, Average Loss: 2.0684832959640316\n",
      "Epoch 4/10, Average Loss: 2.033873463549265\n",
      "Epoch 5/10, Average Loss: 2.013926772082724\n",
      "Epoch 6/10, Average Loss: 2.002713433126124\n",
      "Epoch 7/10, Average Loss: 1.9940694512390509\n",
      "Epoch 8/10, Average Loss: 1.985181807017908\n",
      "Epoch 9/10, Average Loss: 1.976690527869434\n",
      "Epoch 10/10, Average Loss: 1.9718378549668847\n",
      "Epoch 1/10, Average Loss: 2.2223962225565095\n",
      "Epoch 2/10, Average Loss: 2.1309916624208776\n",
      "Epoch 3/10, Average Loss: 2.069670164003605\n",
      "Epoch 4/10, Average Loss: 2.036950790300602\n",
      "Epoch 5/10, Average Loss: 2.0192679879142017\n",
      "Epoch 6/10, Average Loss: 2.006914239104201\n",
      "Epoch 7/10, Average Loss: 1.9971011746220473\n",
      "Epoch 8/10, Average Loss: 1.9890723388369491\n",
      "Epoch 9/10, Average Loss: 1.981933189601433\n",
      "Epoch 10/10, Average Loss: 1.9753736155789072\n",
      "Epoch 1/10, Average Loss: 2.263741690938066\n",
      "Epoch 2/10, Average Loss: 2.255224024377218\n",
      "Epoch 3/10, Average Loss: 2.2462451370750984\n",
      "Epoch 4/10, Average Loss: 2.2371270598434823\n",
      "Epoch 5/10, Average Loss: 2.2278651987634053\n",
      "Epoch 6/10, Average Loss: 2.2180568125189803\n",
      "Epoch 7/10, Average Loss: 2.2080999147601243\n",
      "Epoch 8/10, Average Loss: 2.1982200581852984\n",
      "Epoch 9/10, Average Loss: 2.188684367552036\n",
      "Epoch 10/10, Average Loss: 2.1791133386332815\n",
      "Epoch 1/10, Average Loss: 2.2633451223373413\n",
      "Epoch 2/10, Average Loss: 2.2545570396795505\n",
      "Epoch 3/10, Average Loss: 2.2456860425995617\n",
      "Epoch 4/10, Average Loss: 2.2364404666714552\n",
      "Epoch 5/10, Average Loss: 2.227258818905528\n",
      "Epoch 6/10, Average Loss: 2.2174255324573053\n",
      "Epoch 7/10, Average Loss: 2.207327371690331\n",
      "Epoch 8/10, Average Loss: 2.197803043737644\n",
      "Epoch 9/10, Average Loss: 2.187759239499162\n",
      "Epoch 10/10, Average Loss: 2.1781912431484316\n",
      "Epoch 1/10, Average Loss: 2.2626818185899316\n",
      "Epoch 2/10, Average Loss: 2.2542897811750087\n",
      "Epoch 3/10, Average Loss: 2.2453143887403533\n",
      "Epoch 4/10, Average Loss: 2.235583014604522\n",
      "Epoch 5/10, Average Loss: 2.2260628299015326\n",
      "Epoch 6/10, Average Loss: 2.2165113222308275\n",
      "Epoch 7/10, Average Loss: 2.2069622976023977\n",
      "Epoch 8/10, Average Loss: 2.1971381059507045\n",
      "Epoch 9/10, Average Loss: 2.187498993989898\n",
      "Epoch 10/10, Average Loss: 2.1777137866834315\n",
      "Epoch 1/10, Average Loss: 2.262780677981493\n",
      "Epoch 2/10, Average Loss: 2.2538554406747586\n",
      "Epoch 3/10, Average Loss: 2.2451571458723487\n",
      "Epoch 4/10, Average Loss: 2.235741586219974\n",
      "Epoch 5/10, Average Loss: 2.2259943950466994\n",
      "Epoch 6/10, Average Loss: 2.2168208360671997\n",
      "Epoch 7/10, Average Loss: 2.2071521776478464\n",
      "Epoch 8/10, Average Loss: 2.197186382805429\n",
      "Epoch 9/10, Average Loss: 2.187298571191183\n",
      "Epoch 10/10, Average Loss: 2.1776638408986533\n",
      "Epoch 1/10, Average Loss: 2.2629502662798253\n",
      "Epoch 2/10, Average Loss: 2.2539948603002036\n",
      "Epoch 3/10, Average Loss: 2.2450720449773276\n",
      "Epoch 4/10, Average Loss: 2.235832938333837\n",
      "Epoch 5/10, Average Loss: 2.2266204415298088\n",
      "Epoch 6/10, Average Loss: 2.2169482969656222\n",
      "Epoch 7/10, Average Loss: 2.207156850070488\n",
      "Epoch 8/10, Average Loss: 2.1975707310002024\n",
      "Epoch 9/10, Average Loss: 2.187720702915657\n",
      "Epoch 10/10, Average Loss: 2.178023704668371\n",
      "Epoch 1/10, Average Loss: 1.9955178789976167\n",
      "Epoch 2/10, Average Loss: 1.9316388543059186\n",
      "Epoch 3/10, Average Loss: 1.9304121718174074\n",
      "Epoch 4/10, Average Loss: 1.919635444152646\n",
      "Epoch 5/10, Average Loss: 1.9178687959182552\n",
      "Epoch 6/10, Average Loss: 1.9179704799884703\n",
      "Epoch 7/10, Average Loss: 1.9081391634010687\n",
      "Epoch 8/10, Average Loss: 1.9010807711903641\n",
      "Epoch 9/10, Average Loss: 1.9041431444447214\n",
      "Epoch 10/10, Average Loss: 1.8979706124561588\n",
      "Epoch 1/10, Average Loss: 2.005914262155207\n",
      "Epoch 2/10, Average Loss: 1.9513701752918522\n",
      "Epoch 3/10, Average Loss: 1.9357694038530675\n",
      "Epoch 4/10, Average Loss: 1.9280847252869024\n",
      "Epoch 5/10, Average Loss: 1.9168742735211441\n",
      "Epoch 6/10, Average Loss: 1.90946861011226\n",
      "Epoch 7/10, Average Loss: 1.9017654221232345\n",
      "Epoch 8/10, Average Loss: 1.9003111560170243\n",
      "Epoch 9/10, Average Loss: 1.8996713757514954\n",
      "Epoch 10/10, Average Loss: 1.8932559853646813\n",
      "Epoch 1/10, Average Loss: 2.0004916510930877\n",
      "Epoch 2/10, Average Loss: 1.9403467759853457\n",
      "Epoch 3/10, Average Loss: 1.9251684226640842\n",
      "Epoch 4/10, Average Loss: 1.9132981125901385\n",
      "Epoch 5/10, Average Loss: 1.9190618861012343\n",
      "Epoch 6/10, Average Loss: 1.9096463918685913\n",
      "Epoch 7/10, Average Loss: 1.9071424734301683\n",
      "Epoch 8/10, Average Loss: 1.905868130486186\n",
      "Epoch 9/10, Average Loss: 1.9062902593031161\n",
      "Epoch 10/10, Average Loss: 1.9050769980360822\n",
      "Epoch 1/10, Average Loss: 2.013952154938768\n",
      "Epoch 2/10, Average Loss: 1.964272116742483\n",
      "Epoch 3/10, Average Loss: 1.9373713906218366\n",
      "Epoch 4/10, Average Loss: 1.921883365003074\n",
      "Epoch 5/10, Average Loss: 1.9126381030896815\n",
      "Epoch 6/10, Average Loss: 1.9096107003165455\n",
      "Epoch 7/10, Average Loss: 1.9091434217080838\n",
      "Epoch 8/10, Average Loss: 1.9028827097357772\n",
      "Epoch 9/10, Average Loss: 1.902868497662428\n",
      "Epoch 10/10, Average Loss: 1.8961486118595774\n",
      "Epoch 1/10, Average Loss: 2.006397852083532\n",
      "Epoch 2/10, Average Loss: 1.948940064848923\n",
      "Epoch 3/10, Average Loss: 1.933048632086777\n",
      "Epoch 4/10, Average Loss: 1.9259636111375762\n",
      "Epoch 5/10, Average Loss: 1.9158607546876116\n",
      "Epoch 6/10, Average Loss: 1.9100033102965936\n",
      "Epoch 7/10, Average Loss: 1.9101046818058665\n",
      "Epoch 8/10, Average Loss: 1.893801475443491\n",
      "Epoch 9/10, Average Loss: 1.8912433095094634\n",
      "Epoch 10/10, Average Loss: 1.8865256556650487\n",
      "Epoch 1/10, Average Loss: 2.17974497196151\n",
      "Epoch 2/10, Average Loss: 2.021627210989231\n",
      "Epoch 3/10, Average Loss: 1.9859534472953984\n",
      "Epoch 4/10, Average Loss: 1.9713413918890603\n",
      "Epoch 5/10, Average Loss: 1.9620928735267826\n",
      "Epoch 6/10, Average Loss: 1.9566398670033711\n",
      "Epoch 7/10, Average Loss: 1.9477162593748512\n",
      "Epoch 8/10, Average Loss: 1.946402238636482\n",
      "Epoch 9/10, Average Loss: 1.9418018431198307\n",
      "Epoch 10/10, Average Loss: 1.9398082276669943\n",
      "Epoch 1/10, Average Loss: 2.1821905403602413\n",
      "Epoch 2/10, Average Loss: 2.024675878082834\n",
      "Epoch 3/10, Average Loss: 1.9900228657373569\n",
      "Epoch 4/10, Average Loss: 1.976531719289175\n",
      "Epoch 5/10, Average Loss: 1.9681209064111478\n",
      "Epoch 6/10, Average Loss: 1.9616117884473103\n",
      "Epoch 7/10, Average Loss: 1.9565965693171432\n",
      "Epoch 8/10, Average Loss: 1.9516730831890572\n",
      "Epoch 9/10, Average Loss: 1.9469200227318741\n",
      "Epoch 10/10, Average Loss: 1.9413347433253032\n",
      "Epoch 1/10, Average Loss: 2.1776486097312553\n",
      "Epoch 2/10, Average Loss: 2.0267219441693003\n",
      "Epoch 3/10, Average Loss: 1.9892625023679036\n",
      "Epoch 4/10, Average Loss: 1.9714842249707478\n",
      "Epoch 5/10, Average Loss: 1.9629061134850108\n",
      "Epoch 6/10, Average Loss: 1.9556621269481937\n",
      "Epoch 7/10, Average Loss: 1.9499395286164634\n",
      "Epoch 8/10, Average Loss: 1.9439918471545707\n",
      "Epoch 9/10, Average Loss: 1.9398842831937277\n",
      "Epoch 10/10, Average Loss: 1.9348887495878266\n",
      "Epoch 1/10, Average Loss: 2.1751957201376193\n",
      "Epoch 2/10, Average Loss: 2.0297569908746858\n",
      "Epoch 3/10, Average Loss: 1.9984865770107363\n",
      "Epoch 4/10, Average Loss: 1.9822384162646969\n",
      "Epoch 5/10, Average Loss: 1.9723998453558944\n",
      "Epoch 6/10, Average Loss: 1.967657884446586\n",
      "Epoch 7/10, Average Loss: 1.964023885203571\n",
      "Epoch 8/10, Average Loss: 1.9577883612818834\n",
      "Epoch 9/10, Average Loss: 1.9515286771262563\n",
      "Epoch 10/10, Average Loss: 1.9471882000202085\n",
      "Epoch 1/10, Average Loss: 2.180065748168201\n",
      "Epoch 2/10, Average Loss: 2.0274890210570358\n",
      "Epoch 3/10, Average Loss: 1.993632270068657\n",
      "Epoch 4/10, Average Loss: 1.980234311848152\n",
      "Epoch 5/10, Average Loss: 1.9691232689997045\n",
      "Epoch 6/10, Average Loss: 1.96298017298303\n",
      "Epoch 7/10, Average Loss: 1.9567567284514265\n",
      "Epoch 8/10, Average Loss: 1.9507115657736616\n",
      "Epoch 9/10, Average Loss: 1.947225560502308\n",
      "Epoch 10/10, Average Loss: 1.945467018499607\n",
      "Epoch 1/10, Average Loss: 2.2979187093129974\n",
      "Epoch 2/10, Average Loss: 2.2714169025421143\n",
      "Epoch 3/10, Average Loss: 2.241056814426329\n",
      "Epoch 4/10, Average Loss: 2.2082825317615415\n",
      "Epoch 5/10, Average Loss: 2.1783410863178534\n",
      "Epoch 6/10, Average Loss: 2.149966879588802\n",
      "Epoch 7/10, Average Loss: 2.1201318691416486\n",
      "Epoch 8/10, Average Loss: 2.0993069337635504\n",
      "Epoch 9/10, Average Loss: 2.0803358525764652\n",
      "Epoch 10/10, Average Loss: 2.066914312723206\n",
      "Epoch 1/10, Average Loss: 2.2988572266043685\n",
      "Epoch 2/10, Average Loss: 2.2721582505761124\n",
      "Epoch 3/10, Average Loss: 2.2414112759799494\n",
      "Epoch 4/10, Average Loss: 2.209584672276567\n",
      "Epoch 5/10, Average Loss: 2.178572012156975\n",
      "Epoch 6/10, Average Loss: 2.1482429882375205\n",
      "Epoch 7/10, Average Loss: 2.122066675162897\n",
      "Epoch 8/10, Average Loss: 2.0978567891004607\n",
      "Epoch 9/10, Average Loss: 2.081231077996696\n",
      "Epoch 10/10, Average Loss: 2.0648943752777287\n",
      "Epoch 1/10, Average Loss: 2.297279581791017\n",
      "Epoch 2/10, Average Loss: 2.2721411367742026\n",
      "Epoch 3/10, Average Loss: 2.2411115256751457\n",
      "Epoch 4/10, Average Loss: 2.208279164825998\n",
      "Epoch 5/10, Average Loss: 2.1764625310897827\n",
      "Epoch 6/10, Average Loss: 2.1446843961390054\n",
      "Epoch 7/10, Average Loss: 2.1180675146056385\n",
      "Epoch 8/10, Average Loss: 2.095023396538525\n",
      "Epoch 9/10, Average Loss: 2.0792498123355028\n",
      "Epoch 10/10, Average Loss: 2.0639645006598495\n",
      "Epoch 1/10, Average Loss: 2.2978502046771165\n",
      "Epoch 2/10, Average Loss: 2.2695036981163956\n",
      "Epoch 3/10, Average Loss: 2.238296799543427\n",
      "Epoch 4/10, Average Loss: 2.2062386797695623\n",
      "Epoch 5/10, Average Loss: 2.1738002183960705\n",
      "Epoch 6/10, Average Loss: 2.1431028901076896\n",
      "Epoch 7/10, Average Loss: 2.1181704038526954\n",
      "Epoch 8/10, Average Loss: 2.0961638223834154\n",
      "Epoch 9/10, Average Loss: 2.078667182747911\n",
      "Epoch 10/10, Average Loss: 2.0670558519479707\n",
      "Epoch 1/10, Average Loss: 2.297967651995217\n",
      "Epoch 2/10, Average Loss: 2.271005802038239\n",
      "Epoch 3/10, Average Loss: 2.2402594002281746\n",
      "Epoch 4/10, Average Loss: 2.2089391539736494\n",
      "Epoch 5/10, Average Loss: 2.1763625406637424\n",
      "Epoch 6/10, Average Loss: 2.1456523523098086\n",
      "Epoch 7/10, Average Loss: 2.1189233180953235\n",
      "Epoch 8/10, Average Loss: 2.0973435771174547\n",
      "Epoch 9/10, Average Loss: 2.0799597152849523\n",
      "Epoch 10/10, Average Loss: 2.0676056800819023\n",
      "Epoch 1/10, Average Loss: 1.9628012863601125\n",
      "Epoch 2/10, Average Loss: 1.9189217381361054\n",
      "Epoch 3/10, Average Loss: 1.914558651970654\n",
      "Epoch 4/10, Average Loss: 1.9114791445615815\n",
      "Epoch 5/10, Average Loss: 1.90816448083738\n",
      "Epoch 6/10, Average Loss: 1.9073695525890444\n",
      "Epoch 7/10, Average Loss: 1.9025117536870444\n",
      "Epoch 8/10, Average Loss: 1.9001432817156723\n",
      "Epoch 9/10, Average Loss: 1.901815455134322\n",
      "Epoch 10/10, Average Loss: 1.9080708041423704\n",
      "Epoch 1/10, Average Loss: 1.9703308271198738\n",
      "Epoch 2/10, Average Loss: 1.9299689676703475\n",
      "Epoch 3/10, Average Loss: 1.9213436376757738\n",
      "Epoch 4/10, Average Loss: 1.9247687778821805\n",
      "Epoch 5/10, Average Loss: 1.9102945574899999\n",
      "Epoch 6/10, Average Loss: 1.9056118087070744\n",
      "Epoch 7/10, Average Loss: 1.907428428894136\n",
      "Epoch 8/10, Average Loss: 1.9093953196595355\n",
      "Epoch 9/10, Average Loss: 1.9106174998167085\n",
      "Epoch 10/10, Average Loss: 1.9036609690363815\n",
      "Epoch 1/10, Average Loss: 1.9630397543674563\n",
      "Epoch 2/10, Average Loss: 1.9191877115063551\n",
      "Epoch 3/10, Average Loss: 1.9143969925438487\n",
      "Epoch 4/10, Average Loss: 1.9060517258760405\n",
      "Epoch 5/10, Average Loss: 1.9099967101725137\n",
      "Epoch 6/10, Average Loss: 1.9081079625501864\n",
      "Epoch 7/10, Average Loss: 1.9051945224040892\n",
      "Epoch 8/10, Average Loss: 1.913453576041431\n",
      "Epoch 9/10, Average Loss: 1.905773062531541\n",
      "Epoch 10/10, Average Loss: 1.9035852173479593\n",
      "Epoch 1/10, Average Loss: 1.9666467236309517\n",
      "Epoch 2/10, Average Loss: 1.922874103232128\n",
      "Epoch 3/10, Average Loss: 1.9161665497756586\n",
      "Epoch 4/10, Average Loss: 1.9146189965852878\n",
      "Epoch 5/10, Average Loss: 1.9066567406421755\n",
      "Epoch 6/10, Average Loss: 1.9079240138937787\n",
      "Epoch 7/10, Average Loss: 1.9044097254915935\n",
      "Epoch 8/10, Average Loss: 1.9009426483293859\n",
      "Epoch 9/10, Average Loss: 1.9081170558929443\n",
      "Epoch 10/10, Average Loss: 1.9010595025085821\n",
      "Epoch 1/10, Average Loss: 1.973404355165435\n",
      "Epoch 2/10, Average Loss: 1.9331692878792925\n",
      "Epoch 3/10, Average Loss: 1.9252483292323788\n",
      "Epoch 4/10, Average Loss: 1.9256987266424226\n",
      "Epoch 5/10, Average Loss: 1.9165250629913517\n",
      "Epoch 6/10, Average Loss: 1.9210638898174937\n",
      "Epoch 7/10, Average Loss: 1.9150638638473139\n",
      "Epoch 8/10, Average Loss: 1.9123663989509023\n",
      "Epoch 9/10, Average Loss: 1.9163225191395457\n",
      "Epoch 10/10, Average Loss: 1.9106247788522301\n",
      "Epoch 1/10, Average Loss: 2.1392277028502487\n",
      "Epoch 2/10, Average Loss: 1.9707844010213527\n",
      "Epoch 3/10, Average Loss: 1.9455814623251193\n",
      "Epoch 4/10, Average Loss: 1.934293517252294\n",
      "Epoch 5/10, Average Loss: 1.9254081801670353\n",
      "Epoch 6/10, Average Loss: 1.9218835045651692\n",
      "Epoch 7/10, Average Loss: 1.9145174535309397\n",
      "Epoch 8/10, Average Loss: 1.9140379298024062\n",
      "Epoch 9/10, Average Loss: 1.9111651574693076\n",
      "Epoch 10/10, Average Loss: 1.9107634061720313\n",
      "Epoch 1/10, Average Loss: 2.1446653473667983\n",
      "Epoch 2/10, Average Loss: 1.9746740198716886\n",
      "Epoch 3/10, Average Loss: 1.9483491444006198\n",
      "Epoch 4/10, Average Loss: 1.9369487965979226\n",
      "Epoch 5/10, Average Loss: 1.9297493449071559\n",
      "Epoch 6/10, Average Loss: 1.9263087511062622\n",
      "Epoch 7/10, Average Loss: 1.9212640262231595\n",
      "Epoch 8/10, Average Loss: 1.9178662721703692\n",
      "Epoch 9/10, Average Loss: 1.9160549727881826\n",
      "Epoch 10/10, Average Loss: 1.9119587729616863\n",
      "Epoch 1/10, Average Loss: 2.1388622100760295\n",
      "Epoch 2/10, Average Loss: 1.9766828156099088\n",
      "Epoch 3/10, Average Loss: 1.943864248147825\n",
      "Epoch 4/10, Average Loss: 1.9313434885769356\n",
      "Epoch 5/10, Average Loss: 1.9262492322340243\n",
      "Epoch 6/10, Average Loss: 1.9193972145638816\n",
      "Epoch 7/10, Average Loss: 1.9170183117796735\n",
      "Epoch 8/10, Average Loss: 1.9159506602985104\n",
      "Epoch 9/10, Average Loss: 1.9143321223375274\n",
      "Epoch 10/10, Average Loss: 1.9109815620794528\n",
      "Epoch 1/10, Average Loss: 2.1422287036732928\n",
      "Epoch 2/10, Average Loss: 1.973957622923502\n",
      "Epoch 3/10, Average Loss: 1.9465247567107038\n",
      "Epoch 4/10, Average Loss: 1.9371624385438315\n",
      "Epoch 5/10, Average Loss: 1.9284024849170591\n",
      "Epoch 6/10, Average Loss: 1.923954600241126\n",
      "Epoch 7/10, Average Loss: 1.9198457933053739\n",
      "Epoch 8/10, Average Loss: 1.917286109633562\n",
      "Epoch 9/10, Average Loss: 1.915455922847841\n",
      "Epoch 10/10, Average Loss: 1.9131822106314869\n",
      "Epoch 1/10, Average Loss: 2.142183565511936\n",
      "Epoch 2/10, Average Loss: 1.9797961144912533\n",
      "Epoch 3/10, Average Loss: 1.9520639733570377\n",
      "Epoch 4/10, Average Loss: 1.9405510294728163\n",
      "Epoch 5/10, Average Loss: 1.9319649207882765\n",
      "Epoch 6/10, Average Loss: 1.9295864206988638\n",
      "Epoch 7/10, Average Loss: 1.9257531733047673\n",
      "Epoch 8/10, Average Loss: 1.921596067707713\n",
      "Epoch 9/10, Average Loss: 1.9202059405605967\n",
      "Epoch 10/10, Average Loss: 1.9200776859027584\n",
      "Epoch 1/10, Average Loss: 2.2924959659576416\n",
      "Epoch 2/10, Average Loss: 2.2565923841988167\n",
      "Epoch 3/10, Average Loss: 2.215480124078146\n",
      "Epoch 4/10, Average Loss: 2.1733699542720144\n",
      "Epoch 5/10, Average Loss: 2.127408231176981\n",
      "Epoch 6/10, Average Loss: 2.0911160445794827\n",
      "Epoch 7/10, Average Loss: 2.0580215759393647\n",
      "Epoch 8/10, Average Loss: 2.037396612690716\n",
      "Epoch 9/10, Average Loss: 2.016728524754687\n",
      "Epoch 10/10, Average Loss: 2.0040664512936663\n",
      "Epoch 1/10, Average Loss: 2.2934835102499984\n",
      "Epoch 2/10, Average Loss: 2.256441665858757\n",
      "Epoch 3/10, Average Loss: 2.2162685859494093\n",
      "Epoch 4/10, Average Loss: 2.1737942695617676\n",
      "Epoch 5/10, Average Loss: 2.1304189490108953\n",
      "Epoch 6/10, Average Loss: 2.092345400554378\n",
      "Epoch 7/10, Average Loss: 2.063337520855229\n",
      "Epoch 8/10, Average Loss: 2.0391026299174237\n",
      "Epoch 9/10, Average Loss: 2.0221322862113396\n",
      "Epoch 10/10, Average Loss: 2.0058341825880657\n",
      "Epoch 1/10, Average Loss: 2.291888885381745\n",
      "Epoch 2/10, Average Loss: 2.2567707707242266\n",
      "Epoch 3/10, Average Loss: 2.217018863049949\n",
      "Epoch 4/10, Average Loss: 2.172204953868215\n",
      "Epoch 5/10, Average Loss: 2.1290660282460654\n",
      "Epoch 6/10, Average Loss: 2.091232073016283\n",
      "Epoch 7/10, Average Loss: 2.061736912262149\n",
      "Epoch 8/10, Average Loss: 2.0388922502354876\n",
      "Epoch 9/10, Average Loss: 2.0211913483898813\n",
      "Epoch 10/10, Average Loss: 2.0060114831459233\n",
      "Epoch 1/10, Average Loss: 2.2934236468338387\n",
      "Epoch 2/10, Average Loss: 2.257701740032289\n",
      "Epoch 3/10, Average Loss: 2.219341126883902\n",
      "Epoch 4/10, Average Loss: 2.1758324809190706\n",
      "Epoch 5/10, Average Loss: 2.1308424996166693\n",
      "Epoch 6/10, Average Loss: 2.091976219561042\n",
      "Epoch 7/10, Average Loss: 2.0632444881811374\n",
      "Epoch 8/10, Average Loss: 2.0385647852246356\n",
      "Epoch 9/10, Average Loss: 2.019457963908591\n",
      "Epoch 10/10, Average Loss: 2.0060523283190843\n",
      "Epoch 1/10, Average Loss: 2.2928840648837205\n",
      "Epoch 2/10, Average Loss: 2.2571277851011695\n",
      "Epoch 3/10, Average Loss: 2.2191764145362667\n",
      "Epoch 4/10, Average Loss: 2.1751184870557085\n",
      "Epoch 5/10, Average Loss: 2.1303867814017505\n",
      "Epoch 6/10, Average Loss: 2.094622741385204\n",
      "Epoch 7/10, Average Loss: 2.0647354402193208\n",
      "Epoch 8/10, Average Loss: 2.041604845989041\n",
      "Epoch 9/10, Average Loss: 2.0233725803654368\n",
      "Epoch 10/10, Average Loss: 2.0102948488258736\n",
      "Epoch 1/10, Average Loss: 2.0174960406815132\n",
      "Epoch 2/10, Average Loss: 1.9302202114244786\n",
      "Epoch 3/10, Average Loss: 1.9258935320668105\n",
      "Epoch 4/10, Average Loss: 1.9229334156687667\n",
      "Epoch 5/10, Average Loss: 1.9200982843957297\n",
      "Epoch 6/10, Average Loss: 1.924535491117617\n",
      "Epoch 7/10, Average Loss: 1.9174666884468823\n",
      "Epoch 8/10, Average Loss: 1.9179878278476437\n",
      "Epoch 9/10, Average Loss: 1.9177237938090068\n",
      "Epoch 10/10, Average Loss: 1.9163768465926008\n",
      "Epoch 1/10, Average Loss: 2.0198610991966435\n",
      "Epoch 2/10, Average Loss: 1.9312538911656636\n",
      "Epoch 3/10, Average Loss: 1.9268587580541285\n",
      "Epoch 4/10, Average Loss: 1.9257887063956842\n",
      "Epoch 5/10, Average Loss: 1.926474169987004\n",
      "Epoch 6/10, Average Loss: 1.9263834124658166\n",
      "Epoch 7/10, Average Loss: 1.9232540377756444\n",
      "Epoch 8/10, Average Loss: 1.9237089607773759\n",
      "Epoch 9/10, Average Loss: 1.9209692027510665\n",
      "Epoch 10/10, Average Loss: 1.9199350447189518\n",
      "Epoch 1/10, Average Loss: 2.0219585692010273\n",
      "Epoch 2/10, Average Loss: 1.9359442460827712\n",
      "Epoch 3/10, Average Loss: 1.9239905651022748\n",
      "Epoch 4/10, Average Loss: 1.921435008688671\n",
      "Epoch 5/10, Average Loss: 1.9222952650814522\n",
      "Epoch 6/10, Average Loss: 1.9206288849435202\n",
      "Epoch 7/10, Average Loss: 1.9180664143911221\n",
      "Epoch 8/10, Average Loss: 1.9202946889691237\n",
      "Epoch 9/10, Average Loss: 1.9211939878580047\n",
      "Epoch 10/10, Average Loss: 1.9167003050083067\n",
      "Epoch 1/10, Average Loss: 2.023893430465605\n",
      "Epoch 2/10, Average Loss: 1.9367794031050147\n",
      "Epoch 3/10, Average Loss: 1.9303871407741453\n",
      "Epoch 4/10, Average Loss: 1.9281671207125595\n",
      "Epoch 5/10, Average Loss: 1.9231948271030332\n",
      "Epoch 6/10, Average Loss: 1.9232752570291844\n",
      "Epoch 7/10, Average Loss: 1.921257594736611\n",
      "Epoch 8/10, Average Loss: 1.9208185149402153\n",
      "Epoch 9/10, Average Loss: 1.9237748195485371\n",
      "Epoch 10/10, Average Loss: 1.9189432030770837\n",
      "Epoch 1/10, Average Loss: 2.027509513424664\n",
      "Epoch 2/10, Average Loss: 1.9462599986936988\n",
      "Epoch 3/10, Average Loss: 1.9315610615218557\n",
      "Epoch 4/10, Average Loss: 1.9302867214854171\n",
      "Epoch 5/10, Average Loss: 1.9287857413291931\n",
      "Epoch 6/10, Average Loss: 1.928878481795148\n",
      "Epoch 7/10, Average Loss: 1.928893836533151\n",
      "Epoch 8/10, Average Loss: 1.9267568442879655\n",
      "Epoch 9/10, Average Loss: 1.9255466824624596\n",
      "Epoch 10/10, Average Loss: 1.927149963088152\n",
      "Epoch 1/10, Average Loss: 2.18751569492061\n",
      "Epoch 2/10, Average Loss: 2.040375574332912\n",
      "Epoch 3/10, Average Loss: 2.018796916415052\n",
      "Epoch 4/10, Average Loss: 1.9995586581346465\n",
      "Epoch 5/10, Average Loss: 1.978592606579385\n",
      "Epoch 6/10, Average Loss: 1.9634944127827156\n",
      "Epoch 7/10, Average Loss: 1.948517968014973\n",
      "Epoch 8/10, Average Loss: 1.9429912683440418\n",
      "Epoch 9/10, Average Loss: 1.937047036682687\n",
      "Epoch 10/10, Average Loss: 1.9351622564036672\n",
      "Epoch 1/10, Average Loss: 2.188629603967434\n",
      "Epoch 2/10, Average Loss: 2.0396450510839137\n",
      "Epoch 3/10, Average Loss: 2.0172126961917414\n",
      "Epoch 4/10, Average Loss: 1.9999776366280346\n",
      "Epoch 5/10, Average Loss: 1.981282082999625\n",
      "Epoch 6/10, Average Loss: 1.9647231596272166\n",
      "Epoch 7/10, Average Loss: 1.9535070294287147\n",
      "Epoch 8/10, Average Loss: 1.945023123810931\n",
      "Epoch 9/10, Average Loss: 1.9399247852767385\n",
      "Epoch 10/10, Average Loss: 1.933771928636039\n",
      "Epoch 1/10, Average Loss: 2.1878404849913062\n",
      "Epoch 2/10, Average Loss: 2.036856300947143\n",
      "Epoch 3/10, Average Loss: 2.014598500437853\n",
      "Epoch 4/10, Average Loss: 1.9994195685154055\n",
      "Epoch 5/10, Average Loss: 1.9800659796086753\n",
      "Epoch 6/10, Average Loss: 1.9626378911297495\n",
      "Epoch 7/10, Average Loss: 1.951499515917243\n",
      "Epoch 8/10, Average Loss: 1.9446137576568416\n",
      "Epoch 9/10, Average Loss: 1.9400621187396165\n",
      "Epoch 10/10, Average Loss: 1.935208880319828\n",
      "Epoch 1/10, Average Loss: 2.1879319766672647\n",
      "Epoch 2/10, Average Loss: 2.0371567839529456\n",
      "Epoch 3/10, Average Loss: 2.013934061294649\n",
      "Epoch 4/10, Average Loss: 2.000919959894041\n",
      "Epoch 5/10, Average Loss: 1.9810520207009665\n",
      "Epoch 6/10, Average Loss: 1.9644895733856573\n",
      "Epoch 7/10, Average Loss: 1.9546957088679802\n",
      "Epoch 8/10, Average Loss: 1.945985528027139\n",
      "Epoch 9/10, Average Loss: 1.9408372974977262\n",
      "Epoch 10/10, Average Loss: 1.9378557510492278\n",
      "Epoch 1/10, Average Loss: 2.1875899303250197\n",
      "Epoch 2/10, Average Loss: 2.0425864806989344\n",
      "Epoch 3/10, Average Loss: 2.0175617104623376\n",
      "Epoch 4/10, Average Loss: 2.0031509617479837\n",
      "Epoch 5/10, Average Loss: 1.9838260644819679\n",
      "Epoch 6/10, Average Loss: 1.9701128761942794\n",
      "Epoch 7/10, Average Loss: 1.959401796503765\n",
      "Epoch 8/10, Average Loss: 1.9505790064974529\n",
      "Epoch 9/10, Average Loss: 1.945532227434763\n",
      "Epoch 10/10, Average Loss: 1.9430846789988077\n",
      "Epoch 1/10, Average Loss: 2.2992728047254607\n",
      "Epoch 2/10, Average Loss: 2.275544596881401\n",
      "Epoch 3/10, Average Loss: 2.2476847578839556\n",
      "Epoch 4/10, Average Loss: 2.2182599480559184\n",
      "Epoch 5/10, Average Loss: 2.18707867657266\n",
      "Epoch 6/10, Average Loss: 2.158915034154566\n",
      "Epoch 7/10, Average Loss: 2.133338864256696\n",
      "Epoch 8/10, Average Loss: 2.112913085193169\n",
      "Epoch 9/10, Average Loss: 2.0940038954339375\n",
      "Epoch 10/10, Average Loss: 2.080056071281433\n",
      "Epoch 1/10, Average Loss: 2.2996045874386297\n",
      "Epoch 2/10, Average Loss: 2.2757096319663814\n",
      "Epoch 3/10, Average Loss: 2.2478283149440115\n",
      "Epoch 4/10, Average Loss: 2.217881060228115\n",
      "Epoch 5/10, Average Loss: 2.1873122308312394\n",
      "Epoch 6/10, Average Loss: 2.1586837972082744\n",
      "Epoch 7/10, Average Loss: 2.1335824466333158\n",
      "Epoch 8/10, Average Loss: 2.111899000842397\n",
      "Epoch 9/10, Average Loss: 2.0938418812868074\n",
      "Epoch 10/10, Average Loss: 2.0776427126512296\n",
      "Epoch 1/10, Average Loss: 2.2999561821542134\n",
      "Epoch 2/10, Average Loss: 2.2764517563145334\n",
      "Epoch 3/10, Average Loss: 2.248797727794182\n",
      "Epoch 4/10, Average Loss: 2.2182599306106567\n",
      "Epoch 5/10, Average Loss: 2.187850536369696\n",
      "Epoch 6/10, Average Loss: 2.159079432487488\n",
      "Epoch 7/10, Average Loss: 2.133068093439428\n",
      "Epoch 8/10, Average Loss: 2.1111300427739215\n",
      "Epoch 9/10, Average Loss: 2.092129483455565\n",
      "Epoch 10/10, Average Loss: 2.075836140935014\n",
      "Epoch 1/10, Average Loss: 2.3000153681127036\n",
      "Epoch 2/10, Average Loss: 2.2765110498521386\n",
      "Epoch 3/10, Average Loss: 2.249367737188572\n",
      "Epoch 4/10, Average Loss: 2.2194682766751543\n",
      "Epoch 5/10, Average Loss: 2.188260662846449\n",
      "Epoch 6/10, Average Loss: 2.158709764480591\n",
      "Epoch 7/10, Average Loss: 2.1333085705594317\n",
      "Epoch 8/10, Average Loss: 2.11037962901883\n",
      "Epoch 9/10, Average Loss: 2.0913515730601984\n",
      "Epoch 10/10, Average Loss: 2.0759826724122212\n",
      "Epoch 1/10, Average Loss: 2.299691261314764\n",
      "Epoch 2/10, Average Loss: 2.2757036744094474\n",
      "Epoch 3/10, Average Loss: 2.2487315753611123\n",
      "Epoch 4/10, Average Loss: 2.218629429980022\n",
      "Epoch 5/10, Average Loss: 2.187722848682869\n",
      "Epoch 6/10, Average Loss: 2.1597695641401335\n",
      "Epoch 7/10, Average Loss: 2.134071187275212\n",
      "Epoch 8/10, Average Loss: 2.1122319989088103\n",
      "Epoch 9/10, Average Loss: 2.092853156531729\n",
      "Epoch 10/10, Average Loss: 2.078174012463267\n",
      "Epoch 1/10, Average Loss: 2.0023118897182184\n",
      "Epoch 2/10, Average Loss: 1.9634360016846075\n",
      "Epoch 3/10, Average Loss: 1.9470132313123563\n",
      "Epoch 4/10, Average Loss: 1.9410477018937833\n",
      "Epoch 5/10, Average Loss: 1.9526743132893631\n",
      "Epoch 6/10, Average Loss: 1.9515962440793106\n",
      "Epoch 7/10, Average Loss: 1.9366080412050573\n",
      "Epoch 8/10, Average Loss: 1.933517624692219\n",
      "Epoch 9/10, Average Loss: 1.927499615564579\n",
      "Epoch 10/10, Average Loss: 1.9274403845391623\n",
      "Epoch 1/10, Average Loss: 2.0181274777505456\n",
      "Epoch 2/10, Average Loss: 1.9621882307820204\n",
      "Epoch 3/10, Average Loss: 1.9547160267829895\n",
      "Epoch 4/10, Average Loss: 1.9346094087856571\n",
      "Epoch 5/10, Average Loss: 1.9345097469120491\n",
      "Epoch 6/10, Average Loss: 1.9279351801407048\n",
      "Epoch 7/10, Average Loss: 1.9312380915734826\n",
      "Epoch 8/10, Average Loss: 1.9329124834479354\n",
      "Epoch 9/10, Average Loss: 1.9264940561317816\n",
      "Epoch 10/10, Average Loss: 1.9183043634019248\n",
      "Epoch 1/10, Average Loss: 2.008557710705734\n",
      "Epoch 2/10, Average Loss: 1.9343003834166177\n",
      "Epoch 3/10, Average Loss: 1.9253128737938114\n",
      "Epoch 4/10, Average Loss: 1.9227234168750484\n",
      "Epoch 5/10, Average Loss: 1.9276517484246232\n",
      "Epoch 6/10, Average Loss: 1.9261694579589657\n",
      "Epoch 7/10, Average Loss: 1.9280121646276334\n",
      "Epoch 8/10, Average Loss: 1.915651492956208\n",
      "Epoch 9/10, Average Loss: 1.9192365829537554\n",
      "Epoch 10/10, Average Loss: 1.9196033899377032\n",
      "Epoch 1/10, Average Loss: 2.0265823093856254\n",
      "Epoch 2/10, Average Loss: 1.9523073187688502\n",
      "Epoch 3/10, Average Loss: 1.934258445007045\n",
      "Epoch 4/10, Average Loss: 1.9403279191110192\n",
      "Epoch 5/10, Average Loss: 1.932197423969827\n",
      "Epoch 6/10, Average Loss: 1.9259836426595363\n",
      "Epoch 7/10, Average Loss: 1.9230771849795085\n",
      "Epoch 8/10, Average Loss: 1.9233428763180245\n",
      "Epoch 9/10, Average Loss: 1.9289645538097475\n",
      "Epoch 10/10, Average Loss: 1.9223019378941233\n",
      "Epoch 1/10, Average Loss: 2.0014463750327507\n",
      "Epoch 2/10, Average Loss: 1.9390361934173397\n",
      "Epoch 3/10, Average Loss: 1.9373760921199148\n",
      "Epoch 4/10, Average Loss: 1.930622720136875\n",
      "Epoch 5/10, Average Loss: 1.9254121082585032\n",
      "Epoch 6/10, Average Loss: 1.928309192017811\n",
      "Epoch 7/10, Average Loss: 1.9137600689399532\n",
      "Epoch 8/10, Average Loss: 1.912889277062765\n",
      "Epoch 9/10, Average Loss: 1.914194181198027\n",
      "Epoch 10/10, Average Loss: 1.9083600712985527\n",
      "Epoch 1/10, Average Loss: 2.151982886035268\n",
      "Epoch 2/10, Average Loss: 2.024744791228597\n",
      "Epoch 3/10, Average Loss: 2.0007880562689246\n",
      "Epoch 4/10, Average Loss: 1.9754323174313801\n",
      "Epoch 5/10, Average Loss: 1.9549942336431363\n",
      "Epoch 6/10, Average Loss: 1.943703606361296\n",
      "Epoch 7/10, Average Loss: 1.9356562989514048\n",
      "Epoch 8/10, Average Loss: 1.9321419436757157\n",
      "Epoch 9/10, Average Loss: 1.9291854050101302\n",
      "Epoch 10/10, Average Loss: 1.9277305981008017\n",
      "Epoch 1/10, Average Loss: 2.1503298108170674\n",
      "Epoch 2/10, Average Loss: 2.0220113483870903\n",
      "Epoch 3/10, Average Loss: 2.001936451690953\n",
      "Epoch 4/10, Average Loss: 1.9803607318459489\n",
      "Epoch 5/10, Average Loss: 1.9626541457525113\n",
      "Epoch 6/10, Average Loss: 1.9484525090310632\n",
      "Epoch 7/10, Average Loss: 1.939846255430361\n",
      "Epoch 8/10, Average Loss: 1.93184184882699\n",
      "Epoch 9/10, Average Loss: 1.9267126772461869\n",
      "Epoch 10/10, Average Loss: 1.9228326242144516\n",
      "Epoch 1/10, Average Loss: 2.149981721145351\n",
      "Epoch 2/10, Average Loss: 2.0188386992710394\n",
      "Epoch 3/10, Average Loss: 1.9929534705673777\n",
      "Epoch 4/10, Average Loss: 1.9722351141092254\n",
      "Epoch 5/10, Average Loss: 1.9570650109430638\n",
      "Epoch 6/10, Average Loss: 1.9461868841473648\n",
      "Epoch 7/10, Average Loss: 1.9407317929151582\n",
      "Epoch 8/10, Average Loss: 1.9308478585103663\n",
      "Epoch 9/10, Average Loss: 1.9292134787978195\n",
      "Epoch 10/10, Average Loss: 1.9258000908828363\n",
      "Epoch 1/10, Average Loss: 2.1482517733806517\n",
      "Epoch 2/10, Average Loss: 2.0221528861580826\n",
      "Epoch 3/10, Average Loss: 1.9980978631391757\n",
      "Epoch 4/10, Average Loss: 1.9797965186398203\n",
      "Epoch 5/10, Average Loss: 1.9724384488129034\n",
      "Epoch 6/10, Average Loss: 1.9603625230672883\n",
      "Epoch 7/10, Average Loss: 1.953958395050793\n",
      "Epoch 8/10, Average Loss: 1.9507800108048974\n",
      "Epoch 9/10, Average Loss: 1.9450326329324303\n",
      "Epoch 10/10, Average Loss: 1.940724467358938\n",
      "Epoch 1/10, Average Loss: 2.14881270251623\n",
      "Epoch 2/10, Average Loss: 2.0222074781976094\n",
      "Epoch 3/10, Average Loss: 2.001223895607925\n",
      "Epoch 4/10, Average Loss: 1.985578881531227\n",
      "Epoch 5/10, Average Loss: 1.9713321589842074\n",
      "Epoch 6/10, Average Loss: 1.9612901952208541\n",
      "Epoch 7/10, Average Loss: 1.947542915983898\n",
      "Epoch 8/10, Average Loss: 1.9414824698029496\n",
      "Epoch 9/10, Average Loss: 1.9385062267140645\n",
      "Epoch 10/10, Average Loss: 1.9365712854920365\n",
      "Epoch 1/10, Average Loss: 2.292469684670611\n",
      "Epoch 2/10, Average Loss: 2.2557512027461355\n",
      "Epoch 3/10, Average Loss: 2.2137401859934736\n",
      "Epoch 4/10, Average Loss: 2.173136879758137\n",
      "Epoch 5/10, Average Loss: 2.1362856597435185\n",
      "Epoch 6/10, Average Loss: 2.105442901936973\n",
      "Epoch 7/10, Average Loss: 2.0810482821813445\n",
      "Epoch 8/10, Average Loss: 2.063833591414661\n",
      "Epoch 9/10, Average Loss: 2.0524719372028257\n",
      "Epoch 10/10, Average Loss: 2.0451534550364423\n",
      "Epoch 1/10, Average Loss: 2.2919904982171406\n",
      "Epoch 2/10, Average Loss: 2.254807559455313\n",
      "Epoch 3/10, Average Loss: 2.2134021433388313\n",
      "Epoch 4/10, Average Loss: 2.1734323501586914\n",
      "Epoch 5/10, Average Loss: 2.136668490200508\n",
      "Epoch 6/10, Average Loss: 2.1043169876424277\n",
      "Epoch 7/10, Average Loss: 2.080792871917166\n",
      "Epoch 8/10, Average Loss: 2.0637718410026737\n",
      "Epoch 9/10, Average Loss: 2.052117333179567\n",
      "Epoch 10/10, Average Loss: 2.04370585883536\n",
      "Epoch 1/10, Average Loss: 2.292214259868715\n",
      "Epoch 2/10, Average Loss: 2.25428590832687\n",
      "Epoch 3/10, Average Loss: 2.2110745121793047\n",
      "Epoch 4/10, Average Loss: 2.1683343387231595\n",
      "Epoch 5/10, Average Loss: 2.130511717098515\n",
      "Epoch 6/10, Average Loss: 2.0974650819127154\n",
      "Epoch 7/10, Average Loss: 2.074684022403345\n",
      "Epoch 8/10, Average Loss: 2.0563591980352633\n",
      "Epoch 9/10, Average Loss: 2.0468354530450776\n",
      "Epoch 10/10, Average Loss: 2.037426769733429\n",
      "Epoch 1/10, Average Loss: 2.2903620818766153\n",
      "Epoch 2/10, Average Loss: 2.2528850770578153\n",
      "Epoch 3/10, Average Loss: 2.210461081528082\n",
      "Epoch 4/10, Average Loss: 2.169544717160667\n",
      "Epoch 5/10, Average Loss: 2.1349857347767527\n",
      "Epoch 6/10, Average Loss: 2.1038372196802277\n",
      "Epoch 7/10, Average Loss: 2.079553436942217\n",
      "Epoch 8/10, Average Loss: 2.065542045162945\n",
      "Epoch 9/10, Average Loss: 2.051853274426809\n",
      "Epoch 10/10, Average Loss: 2.0448172906549966\n",
      "Epoch 1/10, Average Loss: 2.2912060458485675\n",
      "Epoch 2/10, Average Loss: 2.2538714467025383\n",
      "Epoch 3/10, Average Loss: 2.212317129460777\n",
      "Epoch 4/10, Average Loss: 2.1726624558611616\n",
      "Epoch 5/10, Average Loss: 2.136307088340201\n",
      "Epoch 6/10, Average Loss: 2.1031720740039175\n",
      "Epoch 7/10, Average Loss: 2.0779879689216614\n",
      "Epoch 8/10, Average Loss: 2.061818582255666\n",
      "Epoch 9/10, Average Loss: 2.0514755903220756\n",
      "Epoch 10/10, Average Loss: 2.0419353566518645\n",
      "Epoch 1/10, Average Loss: 1.9908380261281642\n",
      "Epoch 2/10, Average Loss: 1.929708546254693\n",
      "Epoch 3/10, Average Loss: 1.9206387967598149\n",
      "Epoch 4/10, Average Loss: 1.9131892977691278\n",
      "Epoch 5/10, Average Loss: 1.916824913606411\n",
      "Epoch 6/10, Average Loss: 1.9078118190532778\n",
      "Epoch 7/10, Average Loss: 1.911171389789116\n",
      "Epoch 8/10, Average Loss: 1.9124831033916008\n",
      "Epoch 9/10, Average Loss: 1.915420543856737\n",
      "Epoch 10/10, Average Loss: 1.909534827965062\n",
      "Epoch 1/10, Average Loss: 1.9944192549077475\n",
      "Epoch 2/10, Average Loss: 1.929834848496972\n",
      "Epoch 3/10, Average Loss: 1.9241646004886162\n",
      "Epoch 4/10, Average Loss: 1.9171300137915261\n",
      "Epoch 5/10, Average Loss: 1.9213781167821187\n",
      "Epoch 6/10, Average Loss: 1.912565398507002\n",
      "Epoch 7/10, Average Loss: 1.9131942362320133\n",
      "Epoch 8/10, Average Loss: 1.9128296084520293\n",
      "Epoch 9/10, Average Loss: 1.924168207296511\n",
      "Epoch 10/10, Average Loss: 1.9163844207438028\n",
      "Epoch 1/10, Average Loss: 1.9974720885113972\n",
      "Epoch 2/10, Average Loss: 1.9317325208245255\n",
      "Epoch 3/10, Average Loss: 1.9341678604847048\n",
      "Epoch 4/10, Average Loss: 1.9291175560253422\n",
      "Epoch 5/10, Average Loss: 1.9207472219699766\n",
      "Epoch 6/10, Average Loss: 1.9164675023497604\n",
      "Epoch 7/10, Average Loss: 1.932172831965656\n",
      "Epoch 8/10, Average Loss: 1.9170631010357926\n",
      "Epoch 9/10, Average Loss: 1.9177328595301\n",
      "Epoch 10/10, Average Loss: 1.9183659538990114\n",
      "Epoch 1/10, Average Loss: 1.9832631073346951\n",
      "Epoch 2/10, Average Loss: 1.9273982367864468\n",
      "Epoch 3/10, Average Loss: 1.9225370215206612\n",
      "Epoch 4/10, Average Loss: 1.9223354705950109\n",
      "Epoch 5/10, Average Loss: 1.9316460388462717\n",
      "Epoch 6/10, Average Loss: 1.9361709065553618\n",
      "Epoch 7/10, Average Loss: 1.9211086063850216\n",
      "Epoch 8/10, Average Loss: 1.9190107162405805\n",
      "Epoch 9/10, Average Loss: 1.9151458667545784\n",
      "Epoch 10/10, Average Loss: 1.9093013682016513\n",
      "Epoch 1/10, Average Loss: 1.9931439684658516\n",
      "Epoch 2/10, Average Loss: 1.9351131494452314\n",
      "Epoch 3/10, Average Loss: 1.9316916611136459\n",
      "Epoch 4/10, Average Loss: 1.9255780156065778\n",
      "Epoch 5/10, Average Loss: 1.929998895017112\n",
      "Epoch 6/10, Average Loss: 1.939374705640281\n",
      "Epoch 7/10, Average Loss: 1.9285262750416268\n",
      "Epoch 8/10, Average Loss: 1.9261416327662584\n",
      "Epoch 9/10, Average Loss: 1.9322089552879333\n",
      "Epoch 10/10, Average Loss: 1.9214573895058982\n",
      "Epoch 1/10, Average Loss: 2.18664578693669\n",
      "Epoch 2/10, Average Loss: 1.9965860727356701\n",
      "Epoch 3/10, Average Loss: 1.947563828491583\n",
      "Epoch 4/10, Average Loss: 1.932018857176711\n",
      "Epoch 5/10, Average Loss: 1.927194364187194\n",
      "Epoch 6/10, Average Loss: 1.921951852193693\n",
      "Epoch 7/10, Average Loss: 1.9166759499689427\n",
      "Epoch 8/10, Average Loss: 1.9119315278239366\n",
      "Epoch 9/10, Average Loss: 1.9108515352737614\n",
      "Epoch 10/10, Average Loss: 1.9093848190656522\n",
      "Epoch 1/10, Average Loss: 2.190009736433262\n",
      "Epoch 2/10, Average Loss: 2.0037608713638493\n",
      "Epoch 3/10, Average Loss: 1.9518898958113136\n",
      "Epoch 4/10, Average Loss: 1.9379380548872598\n",
      "Epoch 5/10, Average Loss: 1.9289939461684809\n",
      "Epoch 6/10, Average Loss: 1.9221666164514495\n",
      "Epoch 7/10, Average Loss: 1.9193685854353555\n",
      "Epoch 8/10, Average Loss: 1.91587942984046\n",
      "Epoch 9/10, Average Loss: 1.9135594411594112\n",
      "Epoch 10/10, Average Loss: 1.9089586574856827\n",
      "Epoch 1/10, Average Loss: 2.1943945564874787\n",
      "Epoch 2/10, Average Loss: 2.001659013876101\n",
      "Epoch 3/10, Average Loss: 1.9431540544440107\n",
      "Epoch 4/10, Average Loss: 1.9327367936692588\n",
      "Epoch 5/10, Average Loss: 1.9245722250240604\n",
      "Epoch 6/10, Average Loss: 1.9201149766038104\n",
      "Epoch 7/10, Average Loss: 1.9185277165436163\n",
      "Epoch 8/10, Average Loss: 1.911932110786438\n",
      "Epoch 9/10, Average Loss: 1.9097013764265107\n",
      "Epoch 10/10, Average Loss: 1.9080081087786978\n",
      "Epoch 1/10, Average Loss: 2.191909900525721\n",
      "Epoch 2/10, Average Loss: 2.0003194852573114\n",
      "Epoch 3/10, Average Loss: 1.951486811405275\n",
      "Epoch 4/10, Average Loss: 1.9366724185827302\n",
      "Epoch 5/10, Average Loss: 1.9321521477001469\n",
      "Epoch 6/10, Average Loss: 1.9258659452926823\n",
      "Epoch 7/10, Average Loss: 1.9208679184681032\n",
      "Epoch 8/10, Average Loss: 1.9190903902053833\n",
      "Epoch 9/10, Average Loss: 1.9142576470607664\n",
      "Epoch 10/10, Average Loss: 1.9104239678964383\n",
      "Epoch 1/10, Average Loss: 2.189948131398457\n",
      "Epoch 2/10, Average Loss: 2.0073275377110735\n",
      "Epoch 3/10, Average Loss: 1.9515928204466657\n",
      "Epoch 4/10, Average Loss: 1.9401365925626057\n",
      "Epoch 5/10, Average Loss: 1.92957181465335\n",
      "Epoch 6/10, Average Loss: 1.926097233120988\n",
      "Epoch 7/10, Average Loss: 1.921329115949026\n",
      "Epoch 8/10, Average Loss: 1.9182717116867625\n",
      "Epoch 9/10, Average Loss: 1.916878912507034\n",
      "Epoch 10/10, Average Loss: 1.916113018989563\n",
      "Epoch 1/10, Average Loss: 2.3266399866197167\n",
      "Epoch 2/10, Average Loss: 2.287250271657618\n",
      "Epoch 3/10, Average Loss: 2.240851402282715\n",
      "Epoch 4/10, Average Loss: 2.1973415002590273\n",
      "Epoch 5/10, Average Loss: 2.167032753548971\n",
      "Epoch 6/10, Average Loss: 2.1415472815676435\n",
      "Epoch 7/10, Average Loss: 2.122728318702884\n",
      "Epoch 8/10, Average Loss: 2.1049693982775617\n",
      "Epoch 9/10, Average Loss: 2.085538372760866\n",
      "Epoch 10/10, Average Loss: 2.0633583257837995\n",
      "Epoch 1/10, Average Loss: 2.3270631476146417\n",
      "Epoch 2/10, Average Loss: 2.2862551822894956\n",
      "Epoch 3/10, Average Loss: 2.238310860424507\n",
      "Epoch 4/10, Average Loss: 2.1970520542889105\n",
      "Epoch 5/10, Average Loss: 2.1651049794220345\n",
      "Epoch 6/10, Average Loss: 2.1407399555531943\n",
      "Epoch 7/10, Average Loss: 2.1218963221805853\n",
      "Epoch 8/10, Average Loss: 2.103542008051058\n",
      "Epoch 9/10, Average Loss: 2.0826604976886656\n",
      "Epoch 10/10, Average Loss: 2.0562853769558234\n",
      "Epoch 1/10, Average Loss: 2.3261601023557708\n",
      "Epoch 2/10, Average Loss: 2.287452444797609\n",
      "Epoch 3/10, Average Loss: 2.241218133670528\n",
      "Epoch 4/10, Average Loss: 2.2013048049880237\n",
      "Epoch 5/10, Average Loss: 2.171856874372901\n",
      "Epoch 6/10, Average Loss: 2.1493763458438035\n",
      "Epoch 7/10, Average Loss: 2.1276350922700837\n",
      "Epoch 8/10, Average Loss: 2.108078058173017\n",
      "Epoch 9/10, Average Loss: 2.0835759174533006\n",
      "Epoch 10/10, Average Loss: 2.052051695381723\n",
      "Epoch 1/10, Average Loss: 2.3277212817494464\n",
      "Epoch 2/10, Average Loss: 2.2883247805804743\n",
      "Epoch 3/10, Average Loss: 2.2423705211499843\n",
      "Epoch 4/10, Average Loss: 2.202074992947462\n",
      "Epoch 5/10, Average Loss: 2.1706484236368317\n",
      "Epoch 6/10, Average Loss: 2.147073678854035\n",
      "Epoch 7/10, Average Loss: 2.126454190510075\n",
      "Epoch 8/10, Average Loss: 2.1088539361953735\n",
      "Epoch 9/10, Average Loss: 2.085134538208566\n",
      "Epoch 10/10, Average Loss: 2.0548645287025264\n",
      "Epoch 1/10, Average Loss: 2.327030321446861\n",
      "Epoch 2/10, Average Loss: 2.287701173526485\n",
      "Epoch 3/10, Average Loss: 2.2392811077397043\n",
      "Epoch 4/10, Average Loss: 2.198990455487879\n",
      "Epoch 5/10, Average Loss: 2.1683735992850326\n",
      "Epoch 6/10, Average Loss: 2.1449795030966037\n",
      "Epoch 7/10, Average Loss: 2.1242614839135148\n",
      "Epoch 8/10, Average Loss: 2.1050051726946015\n",
      "Epoch 9/10, Average Loss: 2.0855706232350046\n",
      "Epoch 10/10, Average Loss: 2.058623715144832\n",
      "Epoch 1/10, Average Loss: 2.0491009310978217\n",
      "Epoch 2/10, Average Loss: 1.9424960366109523\n",
      "Epoch 3/10, Average Loss: 1.9274927726606044\n",
      "Epoch 4/10, Average Loss: 1.9216957964548251\n",
      "Epoch 5/10, Average Loss: 1.9224654319809704\n",
      "Epoch 6/10, Average Loss: 1.9223235787414923\n",
      "Epoch 7/10, Average Loss: 1.918185854830393\n",
      "Epoch 8/10, Average Loss: 1.9201224242768637\n",
      "Epoch 9/10, Average Loss: 1.9177876914419778\n",
      "Epoch 10/10, Average Loss: 1.9171956486818267\n",
      "Epoch 1/10, Average Loss: 2.052426089600819\n",
      "Epoch 2/10, Average Loss: 1.9778213297448508\n",
      "Epoch 3/10, Average Loss: 1.928737133014493\n",
      "Epoch 4/10, Average Loss: 1.9261396730818399\n",
      "Epoch 5/10, Average Loss: 1.923994830468806\n",
      "Epoch 6/10, Average Loss: 1.923201264404669\n",
      "Epoch 7/10, Average Loss: 1.923367911722602\n",
      "Epoch 8/10, Average Loss: 1.9208432552291126\n",
      "Epoch 9/10, Average Loss: 1.9219732604375699\n",
      "Epoch 10/10, Average Loss: 1.9226529816301858\n",
      "Epoch 1/10, Average Loss: 2.0476138199247966\n",
      "Epoch 2/10, Average Loss: 1.9630860453698693\n",
      "Epoch 3/10, Average Loss: 1.930786644540182\n",
      "Epoch 4/10, Average Loss: 1.925517003710677\n",
      "Epoch 5/10, Average Loss: 1.922151703660081\n",
      "Epoch 6/10, Average Loss: 1.9218501564933033\n",
      "Epoch 7/10, Average Loss: 1.9205121296208079\n",
      "Epoch 8/10, Average Loss: 1.920614531854304\n",
      "Epoch 9/10, Average Loss: 1.9155557475438931\n",
      "Epoch 10/10, Average Loss: 1.9160975552186734\n",
      "Epoch 1/10, Average Loss: 2.038856839261404\n",
      "Epoch 2/10, Average Loss: 1.9433235148104226\n",
      "Epoch 3/10, Average Loss: 1.9287341644124287\n",
      "Epoch 4/10, Average Loss: 1.9276557404820511\n",
      "Epoch 5/10, Average Loss: 1.9289158655375969\n",
      "Epoch 6/10, Average Loss: 1.9251489014160343\n",
      "Epoch 7/10, Average Loss: 1.923844237153123\n",
      "Epoch 8/10, Average Loss: 1.9279644750967257\n",
      "Epoch 9/10, Average Loss: 1.923928439617157\n",
      "Epoch 10/10, Average Loss: 1.9220260774217002\n",
      "Epoch 1/10, Average Loss: 2.0466986400325125\n",
      "Epoch 2/10, Average Loss: 1.955606271580952\n",
      "Epoch 3/10, Average Loss: 1.9332928875597513\n",
      "Epoch 4/10, Average Loss: 1.9300269542670832\n",
      "Epoch 5/10, Average Loss: 1.9298584781041959\n",
      "Epoch 6/10, Average Loss: 1.935436735792858\n",
      "Epoch 7/10, Average Loss: 1.928706227279291\n",
      "Epoch 8/10, Average Loss: 1.9257271725956986\n",
      "Epoch 9/10, Average Loss: 1.9272805248818747\n",
      "Epoch 10/10, Average Loss: 1.9244059120736472\n",
      "Epoch 1/10, Average Loss: 2.207819543233732\n",
      "Epoch 2/10, Average Loss: 2.0510465400974924\n",
      "Epoch 3/10, Average Loss: 2.0281162160198862\n",
      "Epoch 4/10, Average Loss: 2.024115844470699\n",
      "Epoch 5/10, Average Loss: 2.0114855606381488\n",
      "Epoch 6/10, Average Loss: 1.9867066421159885\n",
      "Epoch 7/10, Average Loss: 1.960362351522213\n",
      "Epoch 8/10, Average Loss: 1.9467474905455984\n",
      "Epoch 9/10, Average Loss: 1.9395015094338395\n",
      "Epoch 10/10, Average Loss: 1.934977816372383\n",
      "Epoch 1/10, Average Loss: 2.211662452395369\n",
      "Epoch 2/10, Average Loss: 2.0500673535393505\n",
      "Epoch 3/10, Average Loss: 2.0295196190112974\n",
      "Epoch 4/10, Average Loss: 2.0243631761248517\n",
      "Epoch 5/10, Average Loss: 2.015583029607447\n",
      "Epoch 6/10, Average Loss: 1.9916935664851492\n",
      "Epoch 7/10, Average Loss: 1.9649538121572354\n",
      "Epoch 8/10, Average Loss: 1.950013189781003\n",
      "Epoch 9/10, Average Loss: 1.9413478926914494\n",
      "Epoch 10/10, Average Loss: 1.9361357427224881\n",
      "Epoch 1/10, Average Loss: 2.210423670163969\n",
      "Epoch 2/10, Average Loss: 2.0455831565508027\n",
      "Epoch 3/10, Average Loss: 2.0216893800875035\n",
      "Epoch 4/10, Average Loss: 2.0187472192252556\n",
      "Epoch 5/10, Average Loss: 2.0125493101957366\n",
      "Epoch 6/10, Average Loss: 1.99311124551587\n",
      "Epoch 7/10, Average Loss: 1.9662465583987352\n",
      "Epoch 8/10, Average Loss: 1.9465989252416098\n",
      "Epoch 9/10, Average Loss: 1.9381779984730045\n",
      "Epoch 10/10, Average Loss: 1.9314861253994267\n",
      "Epoch 1/10, Average Loss: 2.2110790188719585\n",
      "Epoch 2/10, Average Loss: 2.044652703331738\n",
      "Epoch 3/10, Average Loss: 2.019951670635037\n",
      "Epoch 4/10, Average Loss: 2.0171566416577593\n",
      "Epoch 5/10, Average Loss: 2.015823346812551\n",
      "Epoch 6/10, Average Loss: 2.0019365709002424\n",
      "Epoch 7/10, Average Loss: 1.9753305257820502\n",
      "Epoch 8/10, Average Loss: 1.958071734847092\n",
      "Epoch 9/10, Average Loss: 1.945431773255511\n",
      "Epoch 10/10, Average Loss: 1.9388067838622303\n",
      "Epoch 1/10, Average Loss: 2.209358456658154\n",
      "Epoch 2/10, Average Loss: 2.0500604873750268\n",
      "Epoch 3/10, Average Loss: 2.025757889922072\n",
      "Epoch 4/10, Average Loss: 2.0223874217126427\n",
      "Epoch 5/10, Average Loss: 2.014207406741817\n",
      "Epoch 6/10, Average Loss: 1.9952224914620562\n",
      "Epoch 7/10, Average Loss: 1.9694941218306379\n",
      "Epoch 8/10, Average Loss: 1.9536107095276438\n",
      "Epoch 9/10, Average Loss: 1.947533552239581\n",
      "Epoch 10/10, Average Loss: 1.9416552971049053\n",
      "Epoch 1/10, Average Loss: 2.314295257010111\n",
      "Epoch 2/10, Average Loss: 2.292427874192959\n",
      "Epoch 3/10, Average Loss: 2.2665884058649945\n",
      "Epoch 4/10, Average Loss: 2.2368595658279045\n",
      "Epoch 5/10, Average Loss: 2.2069379207564563\n",
      "Epoch 6/10, Average Loss: 2.1783540452398906\n",
      "Epoch 7/10, Average Loss: 2.153524384265993\n",
      "Epoch 8/10, Average Loss: 2.132008773524587\n",
      "Epoch 9/10, Average Loss: 2.1132214301969947\n",
      "Epoch 10/10, Average Loss: 2.096033488831869\n",
      "Epoch 1/10, Average Loss: 2.31488789581671\n",
      "Epoch 2/10, Average Loss: 2.2931536494231803\n",
      "Epoch 3/10, Average Loss: 2.26641608156809\n",
      "Epoch 4/10, Average Loss: 2.237597625430037\n",
      "Epoch 5/10, Average Loss: 2.2073105573654175\n",
      "Epoch 6/10, Average Loss: 2.178947678426417\n",
      "Epoch 7/10, Average Loss: 2.153967773042074\n",
      "Epoch 8/10, Average Loss: 2.132055576254682\n",
      "Epoch 9/10, Average Loss: 2.113693347791346\n",
      "Epoch 10/10, Average Loss: 2.0945238601870653\n",
      "Epoch 1/10, Average Loss: 2.3147442311775395\n",
      "Epoch 2/10, Average Loss: 2.2932512992765846\n",
      "Epoch 3/10, Average Loss: 2.2677232317808196\n",
      "Epoch 4/10, Average Loss: 2.238965168231871\n",
      "Epoch 5/10, Average Loss: 2.208924750002419\n",
      "Epoch 6/10, Average Loss: 2.180935824789652\n",
      "Epoch 7/10, Average Loss: 2.155009048741038\n",
      "Epoch 8/10, Average Loss: 2.132226074614176\n",
      "Epoch 9/10, Average Loss: 2.1110971410100055\n",
      "Epoch 10/10, Average Loss: 2.090912022241732\n",
      "Epoch 1/10, Average Loss: 2.3153953494095223\n",
      "Epoch 2/10, Average Loss: 2.293872068567974\n",
      "Epoch 3/10, Average Loss: 2.268361367830416\n",
      "Epoch 4/10, Average Loss: 2.240001858734503\n",
      "Epoch 5/10, Average Loss: 2.210339522943264\n",
      "Epoch 6/10, Average Loss: 2.181892142063234\n",
      "Epoch 7/10, Average Loss: 2.1561742991935917\n",
      "Epoch 8/10, Average Loss: 2.134010248067902\n",
      "Epoch 9/10, Average Loss: 2.111917164267563\n",
      "Epoch 10/10, Average Loss: 2.090632540423696\n",
      "Epoch 1/10, Average Loss: 2.314732452718223\n",
      "Epoch 2/10, Average Loss: 2.2930802950044957\n",
      "Epoch 3/10, Average Loss: 2.2674290784975377\n",
      "Epoch 4/10, Average Loss: 2.2386645689243223\n",
      "Epoch 5/10, Average Loss: 2.209068257634233\n",
      "Epoch 6/10, Average Loss: 2.1813098977251753\n",
      "Epoch 7/10, Average Loss: 2.155149718610252\n",
      "Epoch 8/10, Average Loss: 2.133473466082317\n",
      "Epoch 9/10, Average Loss: 2.1139555646152033\n",
      "Epoch 10/10, Average Loss: 2.095377651656546\n"
     ]
    }
   ],
   "source": [
    "hidden_layer_sizes_list = [[5],[10],[25, 30], [20, 25, 30]]\n",
    "activation_functions = [F.tanh, F.relu, F.sigmoid]\n",
    "learning_rates = [0.01, 0.001, 0.0001]\n",
    "batch_sizes = [64]\n",
    "num_epochs_list = [10]\n",
    "\n",
    "dataset = wine_quality\n",
    "\n",
    "#smote_in = True\n",
    "#train_X, train_Y, test_X, test_Y = train_test_split(dataset, \"class\", return_torch=True, DoSmote=smote_in)\n",
    "\n",
    "#train_data = TensorDataset(train_X, train_Y)\n",
    "#train_loader = DataLoader(train_data, batch_size=32, shuffle=False)\n",
    "\n",
    "#test_data = TensorDataset(test_X, test_Y)\n",
    "#test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n",
    "\n",
    "X = dataset.drop([\"class\"], axis=1).values\n",
    "Y = dataset[\"class\"].values\n",
    "data = TensorDataset(torch.tensor(X), torch.tensor(Y))\n",
    "data_loader = DataLoader(data, batch_size=32, shuffle=False)\n",
    "\n",
    "input_size = X.shape[1]\n",
    "\n",
    "NumbOfClasses = 10\n",
    "\n",
    "grid_results_wine, best_f1, best_combination = grid_search_cv(\n",
    "    hidden_layer_sizes_list, activation_functions, learning_rates, batch_sizes, num_epochs_list, data_loader, NumbOfClasses,\n",
    "    k_folds=5, use_scaling=True)\n",
    "\n",
    "grid_results_wine['dataset'] = 'wine_quality'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hidden Layer Sizes</th>\n",
       "      <th>Activation Function</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Batch Size</th>\n",
       "      <th>Number of Epochs</th>\n",
       "      <th>Average Accuracy</th>\n",
       "      <th>Average F1</th>\n",
       "      <th>Average Training Time</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[5]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.533015</td>\n",
       "      <td>0.475026</td>\n",
       "      <td>1.834746</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[5]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.444663</td>\n",
       "      <td>0.371314</td>\n",
       "      <td>1.880026</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[5]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.253193</td>\n",
       "      <td>0.250863</td>\n",
       "      <td>1.958428</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[5]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.553334</td>\n",
       "      <td>0.520799</td>\n",
       "      <td>1.619479</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[5]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.473290</td>\n",
       "      <td>0.414571</td>\n",
       "      <td>1.618498</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[5]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.064952</td>\n",
       "      <td>0.034494</td>\n",
       "      <td>1.565606</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[5]</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.536865</td>\n",
       "      <td>0.465590</td>\n",
       "      <td>1.825684</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[5]</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.498074</td>\n",
       "      <td>0.431516</td>\n",
       "      <td>1.916184</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[5]</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.042635</td>\n",
       "      <td>0.016090</td>\n",
       "      <td>1.879657</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[10]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.558259</td>\n",
       "      <td>0.525075</td>\n",
       "      <td>1.944383</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[10]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.483146</td>\n",
       "      <td>0.438256</td>\n",
       "      <td>1.710016</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[10]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.227643</td>\n",
       "      <td>0.269501</td>\n",
       "      <td>1.560680</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[10]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.558569</td>\n",
       "      <td>0.523819</td>\n",
       "      <td>1.672438</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[10]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.507155</td>\n",
       "      <td>0.437458</td>\n",
       "      <td>1.676278</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[10]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.366476</td>\n",
       "      <td>0.353668</td>\n",
       "      <td>1.573558</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[10]</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.536864</td>\n",
       "      <td>0.465592</td>\n",
       "      <td>1.595092</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[10]</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.511003</td>\n",
       "      <td>0.441251</td>\n",
       "      <td>1.579533</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[10]</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.455284</td>\n",
       "      <td>0.386726</td>\n",
       "      <td>1.606400</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[25, 30]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.550103</td>\n",
       "      <td>0.494574</td>\n",
       "      <td>1.813134</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[25, 30]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.515008</td>\n",
       "      <td>0.473666</td>\n",
       "      <td>1.864979</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[25, 30]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.452362</td>\n",
       "      <td>0.420948</td>\n",
       "      <td>1.848730</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[25, 30]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.546562</td>\n",
       "      <td>0.474253</td>\n",
       "      <td>1.837029</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[25, 30]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.544714</td>\n",
       "      <td>0.472678</td>\n",
       "      <td>1.984330</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[25, 30]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.484225</td>\n",
       "      <td>0.417606</td>\n",
       "      <td>2.431855</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[25, 30]</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.537636</td>\n",
       "      <td>0.466331</td>\n",
       "      <td>1.780047</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[25, 30]</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.527320</td>\n",
       "      <td>0.457010</td>\n",
       "      <td>1.824922</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[25, 30]</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.445426</td>\n",
       "      <td>0.302370</td>\n",
       "      <td>1.784557</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[20, 25, 30]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.543945</td>\n",
       "      <td>0.472210</td>\n",
       "      <td>2.069877</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[20, 25, 30]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.518394</td>\n",
       "      <td>0.477677</td>\n",
       "      <td>1.977868</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[20, 25, 30]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.447434</td>\n",
       "      <td>0.378625</td>\n",
       "      <td>2.053940</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[20, 25, 30]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.538556</td>\n",
       "      <td>0.466700</td>\n",
       "      <td>2.011121</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[20, 25, 30]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.536401</td>\n",
       "      <td>0.464766</td>\n",
       "      <td>2.187464</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[20, 25, 30]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.447597</td>\n",
       "      <td>0.405085</td>\n",
       "      <td>2.958628</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[20, 25, 30]</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.534401</td>\n",
       "      <td>0.463327</td>\n",
       "      <td>3.215593</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[20, 25, 30]</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.525934</td>\n",
       "      <td>0.455669</td>\n",
       "      <td>2.045121</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[20, 25, 30]</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.350944</td>\n",
       "      <td>0.204666</td>\n",
       "      <td>2.438068</td>\n",
       "      <td>wine_quality</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Hidden Layer Sizes Activation Function  Learning Rate  Batch Size  \\\n",
       "0                 [5]                tanh         0.0100          64   \n",
       "1                 [5]                tanh         0.0010          64   \n",
       "2                 [5]                tanh         0.0001          64   \n",
       "3                 [5]                relu         0.0100          64   \n",
       "4                 [5]                relu         0.0010          64   \n",
       "5                 [5]                relu         0.0001          64   \n",
       "6                 [5]             sigmoid         0.0100          64   \n",
       "7                 [5]             sigmoid         0.0010          64   \n",
       "8                 [5]             sigmoid         0.0001          64   \n",
       "9                [10]                tanh         0.0100          64   \n",
       "10               [10]                tanh         0.0010          64   \n",
       "11               [10]                tanh         0.0001          64   \n",
       "12               [10]                relu         0.0100          64   \n",
       "13               [10]                relu         0.0010          64   \n",
       "14               [10]                relu         0.0001          64   \n",
       "15               [10]             sigmoid         0.0100          64   \n",
       "16               [10]             sigmoid         0.0010          64   \n",
       "17               [10]             sigmoid         0.0001          64   \n",
       "18           [25, 30]                tanh         0.0100          64   \n",
       "19           [25, 30]                tanh         0.0010          64   \n",
       "20           [25, 30]                tanh         0.0001          64   \n",
       "21           [25, 30]                relu         0.0100          64   \n",
       "22           [25, 30]                relu         0.0010          64   \n",
       "23           [25, 30]                relu         0.0001          64   \n",
       "24           [25, 30]             sigmoid         0.0100          64   \n",
       "25           [25, 30]             sigmoid         0.0010          64   \n",
       "26           [25, 30]             sigmoid         0.0001          64   \n",
       "27       [20, 25, 30]                tanh         0.0100          64   \n",
       "28       [20, 25, 30]                tanh         0.0010          64   \n",
       "29       [20, 25, 30]                tanh         0.0001          64   \n",
       "30       [20, 25, 30]                relu         0.0100          64   \n",
       "31       [20, 25, 30]                relu         0.0010          64   \n",
       "32       [20, 25, 30]                relu         0.0001          64   \n",
       "33       [20, 25, 30]             sigmoid         0.0100          64   \n",
       "34       [20, 25, 30]             sigmoid         0.0010          64   \n",
       "35       [20, 25, 30]             sigmoid         0.0001          64   \n",
       "\n",
       "    Number of Epochs  Average Accuracy  Average F1  Average Training Time  \\\n",
       "0                 10          0.533015    0.475026               1.834746   \n",
       "1                 10          0.444663    0.371314               1.880026   \n",
       "2                 10          0.253193    0.250863               1.958428   \n",
       "3                 10          0.553334    0.520799               1.619479   \n",
       "4                 10          0.473290    0.414571               1.618498   \n",
       "5                 10          0.064952    0.034494               1.565606   \n",
       "6                 10          0.536865    0.465590               1.825684   \n",
       "7                 10          0.498074    0.431516               1.916184   \n",
       "8                 10          0.042635    0.016090               1.879657   \n",
       "9                 10          0.558259    0.525075               1.944383   \n",
       "10                10          0.483146    0.438256               1.710016   \n",
       "11                10          0.227643    0.269501               1.560680   \n",
       "12                10          0.558569    0.523819               1.672438   \n",
       "13                10          0.507155    0.437458               1.676278   \n",
       "14                10          0.366476    0.353668               1.573558   \n",
       "15                10          0.536864    0.465592               1.595092   \n",
       "16                10          0.511003    0.441251               1.579533   \n",
       "17                10          0.455284    0.386726               1.606400   \n",
       "18                10          0.550103    0.494574               1.813134   \n",
       "19                10          0.515008    0.473666               1.864979   \n",
       "20                10          0.452362    0.420948               1.848730   \n",
       "21                10          0.546562    0.474253               1.837029   \n",
       "22                10          0.544714    0.472678               1.984330   \n",
       "23                10          0.484225    0.417606               2.431855   \n",
       "24                10          0.537636    0.466331               1.780047   \n",
       "25                10          0.527320    0.457010               1.824922   \n",
       "26                10          0.445426    0.302370               1.784557   \n",
       "27                10          0.543945    0.472210               2.069877   \n",
       "28                10          0.518394    0.477677               1.977868   \n",
       "29                10          0.447434    0.378625               2.053940   \n",
       "30                10          0.538556    0.466700               2.011121   \n",
       "31                10          0.536401    0.464766               2.187464   \n",
       "32                10          0.447597    0.405085               2.958628   \n",
       "33                10          0.534401    0.463327               3.215593   \n",
       "34                10          0.525934    0.455669               2.045121   \n",
       "35                10          0.350944    0.204666               2.438068   \n",
       "\n",
       "         dataset  \n",
       "0   wine_quality  \n",
       "1   wine_quality  \n",
       "2   wine_quality  \n",
       "3   wine_quality  \n",
       "4   wine_quality  \n",
       "5   wine_quality  \n",
       "6   wine_quality  \n",
       "7   wine_quality  \n",
       "8   wine_quality  \n",
       "9   wine_quality  \n",
       "10  wine_quality  \n",
       "11  wine_quality  \n",
       "12  wine_quality  \n",
       "13  wine_quality  \n",
       "14  wine_quality  \n",
       "15  wine_quality  \n",
       "16  wine_quality  \n",
       "17  wine_quality  \n",
       "18  wine_quality  \n",
       "19  wine_quality  \n",
       "20  wine_quality  \n",
       "21  wine_quality  \n",
       "22  wine_quality  \n",
       "23  wine_quality  \n",
       "24  wine_quality  \n",
       "25  wine_quality  \n",
       "26  wine_quality  \n",
       "27  wine_quality  \n",
       "28  wine_quality  \n",
       "29  wine_quality  \n",
       "30  wine_quality  \n",
       "31  wine_quality  \n",
       "32  wine_quality  \n",
       "33  wine_quality  \n",
       "34  wine_quality  \n",
       "35  wine_quality  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_results_wine\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Congressional Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Average Loss: 1.0931169390678406\n",
      "Epoch 2/10, Average Loss: 0.8803235093752543\n",
      "Epoch 3/10, Average Loss: 0.7031833132108053\n",
      "Epoch 4/10, Average Loss: 0.5734289089838663\n",
      "Epoch 5/10, Average Loss: 0.4860897362232208\n",
      "Epoch 6/10, Average Loss: 0.40965110063552856\n",
      "Epoch 7/10, Average Loss: 0.36114127437273663\n",
      "Epoch 8/10, Average Loss: 0.32630948225657147\n",
      "Epoch 9/10, Average Loss: 0.2915192147095998\n",
      "Epoch 10/10, Average Loss: 0.2733388940493266\n",
      "Epoch 1/10, Average Loss: 1.104884922504425\n",
      "Epoch 2/10, Average Loss: 0.8754033048947653\n",
      "Epoch 3/10, Average Loss: 0.7022010485331217\n",
      "Epoch 4/10, Average Loss: 0.5597648223241171\n",
      "Epoch 5/10, Average Loss: 0.46973538398742676\n",
      "Epoch 6/10, Average Loss: 0.3878113627433777\n",
      "Epoch 7/10, Average Loss: 0.32780036330223083\n",
      "Epoch 8/10, Average Loss: 0.2840626736481984\n",
      "Epoch 9/10, Average Loss: 0.26743921140829724\n",
      "Epoch 10/10, Average Loss: 0.24184114237626395\n",
      "Epoch 1/10, Average Loss: 1.102731962998708\n",
      "Epoch 2/10, Average Loss: 0.8889010945955912\n",
      "Epoch 3/10, Average Loss: 0.7252159913380941\n",
      "Epoch 4/10, Average Loss: 0.5913541913032532\n",
      "Epoch 5/10, Average Loss: 0.48930923144022626\n",
      "Epoch 6/10, Average Loss: 0.4196431338787079\n",
      "Epoch 7/10, Average Loss: 0.3711295525232951\n",
      "Epoch 8/10, Average Loss: 0.32753802339235943\n",
      "Epoch 9/10, Average Loss: 0.30915406346321106\n",
      "Epoch 10/10, Average Loss: 0.28856085737546283\n",
      "Epoch 1/10, Average Loss: 1.106957693894704\n",
      "Epoch 2/10, Average Loss: 0.8898626565933228\n",
      "Epoch 3/10, Average Loss: 0.7198844154675802\n",
      "Epoch 4/10, Average Loss: 0.5949467221895853\n",
      "Epoch 5/10, Average Loss: 0.49331212043762207\n",
      "Epoch 6/10, Average Loss: 0.42471054196357727\n",
      "Epoch 7/10, Average Loss: 0.37825578451156616\n",
      "Epoch 8/10, Average Loss: 0.3384880820910136\n",
      "Epoch 9/10, Average Loss: 0.31458242734273273\n",
      "Epoch 10/10, Average Loss: 0.28708280126253766\n",
      "Epoch 1/10, Average Loss: 1.0794202486673992\n",
      "Epoch 2/10, Average Loss: 0.8626826604207357\n",
      "Epoch 3/10, Average Loss: 0.6952765981356303\n",
      "Epoch 4/10, Average Loss: 0.5737174153327942\n",
      "Epoch 5/10, Average Loss: 0.47181076804796857\n",
      "Epoch 6/10, Average Loss: 0.4012583593527476\n",
      "Epoch 7/10, Average Loss: 0.3491394917170207\n",
      "Epoch 8/10, Average Loss: 0.32359512646993\n",
      "Epoch 9/10, Average Loss: 0.2942578097184499\n",
      "Epoch 10/10, Average Loss: 0.2649090488751729\n",
      "Epoch 1/10, Average Loss: 1.161855657895406\n",
      "Epoch 2/10, Average Loss: 1.1499100923538208\n",
      "Epoch 3/10, Average Loss: 1.1177000602086384\n",
      "Epoch 4/10, Average Loss: 1.1077334483464558\n",
      "Epoch 5/10, Average Loss: 1.0741946697235107\n",
      "Epoch 6/10, Average Loss: 1.0395254294077556\n",
      "Epoch 7/10, Average Loss: 1.0313474734624226\n",
      "Epoch 8/10, Average Loss: 1.0011760195096333\n",
      "Epoch 9/10, Average Loss: 0.9784696300824484\n",
      "Epoch 10/10, Average Loss: 0.9631786545117696\n",
      "Epoch 1/10, Average Loss: 1.178369164466858\n",
      "Epoch 2/10, Average Loss: 1.1636985143025715\n",
      "Epoch 3/10, Average Loss: 1.1219650904337566\n",
      "Epoch 4/10, Average Loss: 1.0993179480234783\n",
      "Epoch 5/10, Average Loss: 1.0841776529947917\n",
      "Epoch 6/10, Average Loss: 1.0593568483988445\n",
      "Epoch 7/10, Average Loss: 1.0281883279482524\n",
      "Epoch 8/10, Average Loss: 0.9968601862589518\n",
      "Epoch 9/10, Average Loss: 0.9772295753161112\n",
      "Epoch 10/10, Average Loss: 0.9639872709910074\n",
      "Epoch 1/10, Average Loss: 1.1782253980636597\n",
      "Epoch 2/10, Average Loss: 1.1644312143325806\n",
      "Epoch 3/10, Average Loss: 1.1316145658493042\n",
      "Epoch 4/10, Average Loss: 1.1096617778142293\n",
      "Epoch 5/10, Average Loss: 1.0789985259373982\n",
      "Epoch 6/10, Average Loss: 1.0581544240315754\n",
      "Epoch 7/10, Average Loss: 1.0458231568336487\n",
      "Epoch 8/10, Average Loss: 1.0198400616645813\n",
      "Epoch 9/10, Average Loss: 0.9912982980410258\n",
      "Epoch 10/10, Average Loss: 0.9765432278315226\n",
      "Epoch 1/10, Average Loss: 1.1812278827031453\n",
      "Epoch 2/10, Average Loss: 1.160137136777242\n",
      "Epoch 3/10, Average Loss: 1.1392126083374023\n",
      "Epoch 4/10, Average Loss: 1.1032408078511555\n",
      "Epoch 5/10, Average Loss: 1.0932724873224895\n",
      "Epoch 6/10, Average Loss: 1.0646506945292156\n",
      "Epoch 7/10, Average Loss: 1.0329644680023193\n",
      "Epoch 8/10, Average Loss: 1.0174850424130757\n",
      "Epoch 9/10, Average Loss: 1.004867136478424\n",
      "Epoch 10/10, Average Loss: 0.9713082313537598\n",
      "Epoch 1/10, Average Loss: 1.1601636012395222\n",
      "Epoch 2/10, Average Loss: 1.1338187058766682\n",
      "Epoch 3/10, Average Loss: 1.1067631642023723\n",
      "Epoch 4/10, Average Loss: 1.0931599934895833\n",
      "Epoch 5/10, Average Loss: 1.0684966643651326\n",
      "Epoch 6/10, Average Loss: 1.0263110001881917\n",
      "Epoch 7/10, Average Loss: 1.014970858891805\n",
      "Epoch 8/10, Average Loss: 0.9902340769767761\n",
      "Epoch 9/10, Average Loss: 0.9628112514813741\n",
      "Epoch 10/10, Average Loss: 0.9523979624112447\n",
      "Epoch 1/10, Average Loss: 1.1691670020421345\n",
      "Epoch 2/10, Average Loss: 1.1809285084406536\n",
      "Epoch 3/10, Average Loss: 1.1711461941401164\n",
      "Epoch 4/10, Average Loss: 1.1861859162648518\n",
      "Epoch 5/10, Average Loss: 1.1711978912353516\n",
      "Epoch 6/10, Average Loss: 1.156395395596822\n",
      "Epoch 7/10, Average Loss: 1.1703189214070637\n",
      "Epoch 8/10, Average Loss: 1.1593454678853352\n",
      "Epoch 9/10, Average Loss: 1.157830278078715\n",
      "Epoch 10/10, Average Loss: 1.1614975929260254\n",
      "Epoch 1/10, Average Loss: 1.1861473321914673\n",
      "Epoch 2/10, Average Loss: 1.196724494298299\n",
      "Epoch 3/10, Average Loss: 1.175900936126709\n",
      "Epoch 4/10, Average Loss: 1.1776984532674153\n",
      "Epoch 5/10, Average Loss: 1.1843615372975667\n",
      "Epoch 6/10, Average Loss: 1.1829901536305745\n",
      "Epoch 7/10, Average Loss: 1.1722696622212727\n",
      "Epoch 8/10, Average Loss: 1.1631959676742554\n",
      "Epoch 9/10, Average Loss: 1.1612881819407146\n",
      "Epoch 10/10, Average Loss: 1.1690703630447388\n",
      "Epoch 1/10, Average Loss: 1.1861884196599324\n",
      "Epoch 2/10, Average Loss: 1.1960536638895671\n",
      "Epoch 3/10, Average Loss: 1.1836401621500652\n",
      "Epoch 4/10, Average Loss: 1.1839646100997925\n",
      "Epoch 5/10, Average Loss: 1.1766599019368489\n",
      "Epoch 6/10, Average Loss: 1.1755940914154053\n",
      "Epoch 7/10, Average Loss: 1.1841353575388591\n",
      "Epoch 8/10, Average Loss: 1.1787137587865193\n",
      "Epoch 9/10, Average Loss: 1.1659516493479412\n",
      "Epoch 10/10, Average Loss: 1.1731571753819783\n",
      "Epoch 1/10, Average Loss: 1.1890665292739868\n",
      "Epoch 2/10, Average Loss: 1.1910914580027263\n",
      "Epoch 3/10, Average Loss: 1.1936359802881877\n",
      "Epoch 4/10, Average Loss: 1.1765367190043132\n",
      "Epoch 5/10, Average Loss: 1.1930731137593586\n",
      "Epoch 6/10, Average Loss: 1.1827486753463745\n",
      "Epoch 7/10, Average Loss: 1.1697988112767537\n",
      "Epoch 8/10, Average Loss: 1.176295280456543\n",
      "Epoch 9/10, Average Loss: 1.1863284905751545\n",
      "Epoch 10/10, Average Loss: 1.1687403122584026\n",
      "Epoch 1/10, Average Loss: 1.168684760729472\n",
      "Epoch 2/10, Average Loss: 1.1654109954833984\n",
      "Epoch 3/10, Average Loss: 1.1609952052434285\n",
      "Epoch 4/10, Average Loss: 1.1705832878748577\n",
      "Epoch 5/10, Average Loss: 1.1699055830637615\n",
      "Epoch 6/10, Average Loss: 1.145667831103007\n",
      "Epoch 7/10, Average Loss: 1.1592090924580891\n",
      "Epoch 8/10, Average Loss: 1.151147445042928\n",
      "Epoch 9/10, Average Loss: 1.14437735080719\n",
      "Epoch 10/10, Average Loss: 1.1572974920272827\n",
      "Epoch 1/10, Average Loss: 1.4168819586435955\n",
      "Epoch 2/10, Average Loss: 1.1347241401672363\n",
      "Epoch 3/10, Average Loss: 0.8782995343208313\n",
      "Epoch 4/10, Average Loss: 0.6866296927134196\n",
      "Epoch 5/10, Average Loss: 0.6070772608121237\n",
      "Epoch 6/10, Average Loss: 0.5528135498364767\n",
      "Epoch 7/10, Average Loss: 0.5252770880858103\n",
      "Epoch 8/10, Average Loss: 0.4881376624107361\n",
      "Epoch 9/10, Average Loss: 0.44497289260228473\n",
      "Epoch 10/10, Average Loss: 0.41801586747169495\n",
      "Epoch 1/10, Average Loss: 1.4568955898284912\n",
      "Epoch 2/10, Average Loss: 1.1518959601720173\n",
      "Epoch 3/10, Average Loss: 0.8963884711265564\n",
      "Epoch 4/10, Average Loss: 0.702186385790507\n",
      "Epoch 5/10, Average Loss: 0.5858662724494934\n",
      "Epoch 6/10, Average Loss: 0.5261831084887186\n",
      "Epoch 7/10, Average Loss: 0.4837846060593923\n",
      "Epoch 8/10, Average Loss: 0.4544950524965922\n",
      "Epoch 9/10, Average Loss: 0.42143447200457257\n",
      "Epoch 10/10, Average Loss: 0.39357640345891315\n",
      "Epoch 1/10, Average Loss: 1.4199013710021973\n",
      "Epoch 2/10, Average Loss: 1.1210778951644897\n",
      "Epoch 3/10, Average Loss: 0.88538924853007\n",
      "Epoch 4/10, Average Loss: 0.7101138035456339\n",
      "Epoch 5/10, Average Loss: 0.6030843257904053\n",
      "Epoch 6/10, Average Loss: 0.5655913750330607\n",
      "Epoch 7/10, Average Loss: 0.5223484536012014\n",
      "Epoch 8/10, Average Loss: 0.4778340657552083\n",
      "Epoch 9/10, Average Loss: 0.4600643416245778\n",
      "Epoch 10/10, Average Loss: 0.4227980673313141\n",
      "Epoch 1/10, Average Loss: 1.4241050879160564\n",
      "Epoch 2/10, Average Loss: 1.1393569707870483\n",
      "Epoch 3/10, Average Loss: 0.8987920085589091\n",
      "Epoch 4/10, Average Loss: 0.7238291700681051\n",
      "Epoch 5/10, Average Loss: 0.6055598855018616\n",
      "Epoch 6/10, Average Loss: 0.5683741172154745\n",
      "Epoch 7/10, Average Loss: 0.5308586756388346\n",
      "Epoch 8/10, Average Loss: 0.49138830105463666\n",
      "Epoch 9/10, Average Loss: 0.45060935616493225\n",
      "Epoch 10/10, Average Loss: 0.42169703046480816\n",
      "Epoch 1/10, Average Loss: 1.3750719626744587\n",
      "Epoch 2/10, Average Loss: 1.1027671694755554\n",
      "Epoch 3/10, Average Loss: 0.8695654074350992\n",
      "Epoch 4/10, Average Loss: 0.7018522421518961\n",
      "Epoch 5/10, Average Loss: 0.5839415291945139\n",
      "Epoch 6/10, Average Loss: 0.5486680070559183\n",
      "Epoch 7/10, Average Loss: 0.5072456995646158\n",
      "Epoch 8/10, Average Loss: 0.47963419556617737\n",
      "Epoch 9/10, Average Loss: 0.44356314341227215\n",
      "Epoch 10/10, Average Loss: 0.4076351225376129\n",
      "Epoch 1/10, Average Loss: 1.5102052688598633\n",
      "Epoch 2/10, Average Loss: 1.485722303390503\n",
      "Epoch 3/10, Average Loss: 1.4567091067632039\n",
      "Epoch 4/10, Average Loss: 1.4602032105127971\n",
      "Epoch 5/10, Average Loss: 1.3873880704243977\n",
      "Epoch 6/10, Average Loss: 1.3530229727427165\n",
      "Epoch 7/10, Average Loss: 1.3339705069859822\n",
      "Epoch 8/10, Average Loss: 1.3073764244715373\n",
      "Epoch 9/10, Average Loss: 1.277089277903239\n",
      "Epoch 10/10, Average Loss: 1.2413671414057414\n",
      "Epoch 1/10, Average Loss: 1.546865185101827\n",
      "Epoch 2/10, Average Loss: 1.5353983640670776\n",
      "Epoch 3/10, Average Loss: 1.493790825208028\n",
      "Epoch 4/10, Average Loss: 1.4418782790501912\n",
      "Epoch 5/10, Average Loss: 1.4296406110127766\n",
      "Epoch 6/10, Average Loss: 1.3950676520665486\n",
      "Epoch 7/10, Average Loss: 1.3733693361282349\n",
      "Epoch 8/10, Average Loss: 1.3119962215423584\n",
      "Epoch 9/10, Average Loss: 1.2907806237538655\n",
      "Epoch 10/10, Average Loss: 1.2853569984436035\n",
      "Epoch 1/10, Average Loss: 1.516136606534322\n",
      "Epoch 2/10, Average Loss: 1.47974693775177\n",
      "Epoch 3/10, Average Loss: 1.4457180102666218\n",
      "Epoch 4/10, Average Loss: 1.421811620394389\n",
      "Epoch 5/10, Average Loss: 1.3852445284525554\n",
      "Epoch 6/10, Average Loss: 1.3511441548665364\n",
      "Epoch 7/10, Average Loss: 1.330472707748413\n",
      "Epoch 8/10, Average Loss: 1.3155823548634846\n",
      "Epoch 9/10, Average Loss: 1.251775582631429\n",
      "Epoch 10/10, Average Loss: 1.261792818705241\n",
      "Epoch 1/10, Average Loss: 1.512620170911153\n",
      "Epoch 2/10, Average Loss: 1.5010789632797241\n",
      "Epoch 3/10, Average Loss: 1.490902304649353\n",
      "Epoch 4/10, Average Loss: 1.4371650218963623\n",
      "Epoch 5/10, Average Loss: 1.4141019582748413\n",
      "Epoch 6/10, Average Loss: 1.3732575972874959\n",
      "Epoch 7/10, Average Loss: 1.319823185602824\n",
      "Epoch 8/10, Average Loss: 1.3189301093419392\n",
      "Epoch 9/10, Average Loss: 1.297156572341919\n",
      "Epoch 10/10, Average Loss: 1.2426997025807698\n",
      "Epoch 1/10, Average Loss: 1.4654606183369954\n",
      "Epoch 2/10, Average Loss: 1.4551304976145427\n",
      "Epoch 3/10, Average Loss: 1.4106518030166626\n",
      "Epoch 4/10, Average Loss: 1.3901095787684123\n",
      "Epoch 5/10, Average Loss: 1.356492241223653\n",
      "Epoch 6/10, Average Loss: 1.3027954697608948\n",
      "Epoch 7/10, Average Loss: 1.3065963586171467\n",
      "Epoch 8/10, Average Loss: 1.2708578904469807\n",
      "Epoch 9/10, Average Loss: 1.235456943511963\n",
      "Epoch 10/10, Average Loss: 1.2367819547653198\n",
      "Epoch 1/10, Average Loss: 1.5200498501459758\n",
      "Epoch 2/10, Average Loss: 1.5258012215296428\n",
      "Epoch 3/10, Average Loss: 1.526847243309021\n",
      "Epoch 4/10, Average Loss: 1.5650864044825237\n",
      "Epoch 5/10, Average Loss: 1.5124839146931965\n",
      "Epoch 6/10, Average Loss: 1.5071860154469807\n",
      "Epoch 7/10, Average Loss: 1.5110222895940144\n",
      "Epoch 8/10, Average Loss: 1.5151077508926392\n",
      "Epoch 9/10, Average Loss: 1.5134611527125041\n",
      "Epoch 10/10, Average Loss: 1.502493977546692\n",
      "Epoch 1/10, Average Loss: 1.5562451283137004\n",
      "Epoch 2/10, Average Loss: 1.5777428150177002\n",
      "Epoch 3/10, Average Loss: 1.5644797881444295\n",
      "Epoch 4/10, Average Loss: 1.5400002002716064\n",
      "Epoch 5/10, Average Loss: 1.5585428476333618\n",
      "Epoch 6/10, Average Loss: 1.5507516860961914\n",
      "Epoch 7/10, Average Loss: 1.563042163848877\n",
      "Epoch 8/10, Average Loss: 1.5211131572723389\n",
      "Epoch 9/10, Average Loss: 1.5293956995010376\n",
      "Epoch 10/10, Average Loss: 1.5539389848709106\n",
      "Epoch 1/10, Average Loss: 1.5262171030044556\n",
      "Epoch 2/10, Average Loss: 1.5199108521143596\n",
      "Epoch 3/10, Average Loss: 1.513722538948059\n",
      "Epoch 4/10, Average Loss: 1.519846002260844\n",
      "Epoch 5/10, Average Loss: 1.5116552511850994\n",
      "Epoch 6/10, Average Loss: 1.5034786065419514\n",
      "Epoch 7/10, Average Loss: 1.5126171509424846\n",
      "Epoch 8/10, Average Loss: 1.5303370157877605\n",
      "Epoch 9/10, Average Loss: 1.4794669151306152\n",
      "Epoch 10/10, Average Loss: 1.5282095670700073\n",
      "Epoch 1/10, Average Loss: 1.5220956405003865\n",
      "Epoch 2/10, Average Loss: 1.5408798058827717\n",
      "Epoch 3/10, Average Loss: 1.5611093441645305\n",
      "Epoch 4/10, Average Loss: 1.5322006940841675\n",
      "Epoch 5/10, Average Loss: 1.541604995727539\n",
      "Epoch 6/10, Average Loss: 1.5256389776865642\n",
      "Epoch 7/10, Average Loss: 1.4957008759180705\n",
      "Epoch 8/10, Average Loss: 1.527552843093872\n",
      "Epoch 9/10, Average Loss: 1.536711613337199\n",
      "Epoch 10/10, Average Loss: 1.4963452418645222\n",
      "Epoch 1/10, Average Loss: 1.4749339024225872\n",
      "Epoch 2/10, Average Loss: 1.4942310253779094\n",
      "Epoch 3/10, Average Loss: 1.4762653907140095\n",
      "Epoch 4/10, Average Loss: 1.4838413000106812\n",
      "Epoch 5/10, Average Loss: 1.4794085423151653\n",
      "Epoch 6/10, Average Loss: 1.4473964770634968\n",
      "Epoch 7/10, Average Loss: 1.4845839341481526\n",
      "Epoch 8/10, Average Loss: 1.4718900918960571\n",
      "Epoch 9/10, Average Loss: 1.462857683499654\n",
      "Epoch 10/10, Average Loss: 1.4999613364537556\n",
      "Epoch 1/10, Average Loss: 0.7642374436060587\n",
      "Epoch 2/10, Average Loss: 0.7110618352890015\n",
      "Epoch 3/10, Average Loss: 0.6694051027297974\n",
      "Epoch 4/10, Average Loss: 0.6347196102142334\n",
      "Epoch 5/10, Average Loss: 0.5948000550270081\n",
      "Epoch 6/10, Average Loss: 0.5588457584381104\n",
      "Epoch 7/10, Average Loss: 0.5191956162452698\n",
      "Epoch 8/10, Average Loss: 0.4870142837365468\n",
      "Epoch 9/10, Average Loss: 0.4551298717657725\n",
      "Epoch 10/10, Average Loss: 0.42467256387074787\n",
      "Epoch 1/10, Average Loss: 0.7667656143506368\n",
      "Epoch 2/10, Average Loss: 0.7161857684453329\n",
      "Epoch 3/10, Average Loss: 0.6761613289515177\n",
      "Epoch 4/10, Average Loss: 0.6367937922477722\n",
      "Epoch 5/10, Average Loss: 0.6061655879020691\n",
      "Epoch 6/10, Average Loss: 0.5690450668334961\n",
      "Epoch 7/10, Average Loss: 0.5328758955001831\n",
      "Epoch 8/10, Average Loss: 0.49600494901339215\n",
      "Epoch 9/10, Average Loss: 0.4661247630914052\n",
      "Epoch 10/10, Average Loss: 0.42976290980974835\n",
      "Epoch 1/10, Average Loss: 0.7642251253128052\n",
      "Epoch 2/10, Average Loss: 0.7134290933609009\n",
      "Epoch 3/10, Average Loss: 0.6735356251398722\n",
      "Epoch 4/10, Average Loss: 0.6362586816151937\n",
      "Epoch 5/10, Average Loss: 0.5963293313980103\n",
      "Epoch 6/10, Average Loss: 0.5594048500061035\n",
      "Epoch 7/10, Average Loss: 0.5238627791404724\n",
      "Epoch 8/10, Average Loss: 0.4869296948115031\n",
      "Epoch 9/10, Average Loss: 0.45560222864151\n",
      "Epoch 10/10, Average Loss: 0.4258149762948354\n",
      "Epoch 1/10, Average Loss: 0.7634536425272623\n",
      "Epoch 2/10, Average Loss: 0.7156525055567423\n",
      "Epoch 3/10, Average Loss: 0.6762033303578695\n",
      "Epoch 4/10, Average Loss: 0.6408173243204752\n",
      "Epoch 5/10, Average Loss: 0.6031098365783691\n",
      "Epoch 6/10, Average Loss: 0.5669005314509074\n",
      "Epoch 7/10, Average Loss: 0.5324031710624695\n",
      "Epoch 8/10, Average Loss: 0.49667858084042865\n",
      "Epoch 9/10, Average Loss: 0.46572981278101605\n",
      "Epoch 10/10, Average Loss: 0.4354826013247172\n",
      "Epoch 1/10, Average Loss: 0.7626664837201437\n",
      "Epoch 2/10, Average Loss: 0.7116292715072632\n",
      "Epoch 3/10, Average Loss: 0.6664602955182394\n",
      "Epoch 4/10, Average Loss: 0.628609816233317\n",
      "Epoch 5/10, Average Loss: 0.5892266631126404\n",
      "Epoch 6/10, Average Loss: 0.551402231057485\n",
      "Epoch 7/10, Average Loss: 0.5167340238889059\n",
      "Epoch 8/10, Average Loss: 0.486381471157074\n",
      "Epoch 9/10, Average Loss: 0.45236586531003314\n",
      "Epoch 10/10, Average Loss: 0.42027262846628827\n",
      "Epoch 1/10, Average Loss: 0.780491848786672\n",
      "Epoch 2/10, Average Loss: 0.7767666180928549\n",
      "Epoch 3/10, Average Loss: 0.7696420351664225\n",
      "Epoch 4/10, Average Loss: 0.766593873500824\n",
      "Epoch 5/10, Average Loss: 0.7586831251780192\n",
      "Epoch 6/10, Average Loss: 0.7517899672190348\n",
      "Epoch 7/10, Average Loss: 0.7484074831008911\n",
      "Epoch 8/10, Average Loss: 0.7429991364479065\n",
      "Epoch 9/10, Average Loss: 0.7369509140650431\n",
      "Epoch 10/10, Average Loss: 0.733115017414093\n",
      "Epoch 1/10, Average Loss: 0.7834653457005819\n",
      "Epoch 2/10, Average Loss: 0.7798004349072775\n",
      "Epoch 3/10, Average Loss: 0.7707169651985168\n",
      "Epoch 4/10, Average Loss: 0.7654104034105936\n",
      "Epoch 5/10, Average Loss: 0.7610997358957926\n",
      "Epoch 6/10, Average Loss: 0.7557340264320374\n",
      "Epoch 7/10, Average Loss: 0.7498959501584371\n",
      "Epoch 8/10, Average Loss: 0.742806633313497\n",
      "Epoch 9/10, Average Loss: 0.7376019358634949\n",
      "Epoch 10/10, Average Loss: 0.7333714365959167\n",
      "Epoch 1/10, Average Loss: 0.7840118209520975\n",
      "Epoch 2/10, Average Loss: 0.7789993683497111\n",
      "Epoch 3/10, Average Loss: 0.7716101010640463\n",
      "Epoch 4/10, Average Loss: 0.7655450105667114\n",
      "Epoch 5/10, Average Loss: 0.7599320610364279\n",
      "Epoch 6/10, Average Loss: 0.7540717919667562\n",
      "Epoch 7/10, Average Loss: 0.7516074180603027\n",
      "Epoch 8/10, Average Loss: 0.7462676564852396\n",
      "Epoch 9/10, Average Loss: 0.7391988436381022\n",
      "Epoch 10/10, Average Loss: 0.7361703316370646\n",
      "Epoch 1/10, Average Loss: 0.7812094291051229\n",
      "Epoch 2/10, Average Loss: 0.7757846713066101\n",
      "Epoch 3/10, Average Loss: 0.7714318434397379\n",
      "Epoch 4/10, Average Loss: 0.7630985975265503\n",
      "Epoch 5/10, Average Loss: 0.760785977045695\n",
      "Epoch 6/10, Average Loss: 0.754256546497345\n",
      "Epoch 7/10, Average Loss: 0.7473624547322592\n",
      "Epoch 8/10, Average Loss: 0.744437019030253\n",
      "Epoch 9/10, Average Loss: 0.7416394154230753\n",
      "Epoch 10/10, Average Loss: 0.7334394454956055\n",
      "Epoch 1/10, Average Loss: 0.7813827991485596\n",
      "Epoch 2/10, Average Loss: 0.7744311491648356\n",
      "Epoch 3/10, Average Loss: 0.7686420679092407\n",
      "Epoch 4/10, Average Loss: 0.7642185091972351\n",
      "Epoch 5/10, Average Loss: 0.7586349248886108\n",
      "Epoch 6/10, Average Loss: 0.7500093181927999\n",
      "Epoch 7/10, Average Loss: 0.7466224829355875\n",
      "Epoch 8/10, Average Loss: 0.740970234076182\n",
      "Epoch 9/10, Average Loss: 0.7353924512863159\n",
      "Epoch 10/10, Average Loss: 0.7321309447288513\n",
      "Epoch 1/10, Average Loss: 0.7822263836860657\n",
      "Epoch 2/10, Average Loss: 0.7843642036120096\n",
      "Epoch 3/10, Average Loss: 0.782098650932312\n",
      "Epoch 4/10, Average Loss: 0.7838393052419027\n",
      "Epoch 5/10, Average Loss: 0.7814401586850485\n",
      "Epoch 6/10, Average Loss: 0.7788087725639343\n",
      "Epoch 7/10, Average Loss: 0.7817604740460714\n",
      "Epoch 8/10, Average Loss: 0.7797892689704895\n",
      "Epoch 9/10, Average Loss: 0.7779515186945597\n",
      "Epoch 10/10, Average Loss: 0.7791707714398702\n",
      "Epoch 1/10, Average Loss: 0.7852227687835693\n",
      "Epoch 2/10, Average Loss: 0.787221093972524\n",
      "Epoch 3/10, Average Loss: 0.7829020023345947\n",
      "Epoch 4/10, Average Loss: 0.7835725545883179\n",
      "Epoch 5/10, Average Loss: 0.7837686538696289\n",
      "Epoch 6/10, Average Loss: 0.7842190265655518\n",
      "Epoch 7/10, Average Loss: 0.7822980284690857\n",
      "Epoch 8/10, Average Loss: 0.7810563445091248\n",
      "Epoch 9/10, Average Loss: 0.7789161006609598\n",
      "Epoch 10/10, Average Loss: 0.7802407542864481\n",
      "Epoch 1/10, Average Loss: 0.7861316800117493\n",
      "Epoch 2/10, Average Loss: 0.7866981029510498\n",
      "Epoch 3/10, Average Loss: 0.7841013669967651\n",
      "Epoch 4/10, Average Loss: 0.7828983068466187\n",
      "Epoch 5/10, Average Loss: 0.7827054460843405\n",
      "Epoch 6/10, Average Loss: 0.7818158268928528\n",
      "Epoch 7/10, Average Loss: 0.7838907440503439\n",
      "Epoch 8/10, Average Loss: 0.7821825941403707\n",
      "Epoch 9/10, Average Loss: 0.7809017896652222\n",
      "Epoch 10/10, Average Loss: 0.7812278668085734\n",
      "Epoch 1/10, Average Loss: 0.7830472389856974\n",
      "Epoch 2/10, Average Loss: 0.782620926698049\n",
      "Epoch 3/10, Average Loss: 0.7833737134933472\n",
      "Epoch 4/10, Average Loss: 0.7795064250628153\n",
      "Epoch 5/10, Average Loss: 0.7826685110727946\n",
      "Epoch 6/10, Average Loss: 0.7809859315554301\n",
      "Epoch 7/10, Average Loss: 0.7786198258399963\n",
      "Epoch 8/10, Average Loss: 0.7796809474627177\n",
      "Epoch 9/10, Average Loss: 0.7807823816935221\n",
      "Epoch 10/10, Average Loss: 0.7772144675254822\n",
      "Epoch 1/10, Average Loss: 0.7833911180496216\n",
      "Epoch 2/10, Average Loss: 0.7817625403404236\n",
      "Epoch 3/10, Average Loss: 0.7816879351933798\n",
      "Epoch 4/10, Average Loss: 0.78264319896698\n",
      "Epoch 5/10, Average Loss: 0.7824576497077942\n",
      "Epoch 6/10, Average Loss: 0.7788434624671936\n",
      "Epoch 7/10, Average Loss: 0.7798553903897604\n",
      "Epoch 8/10, Average Loss: 0.7786609927813212\n",
      "Epoch 9/10, Average Loss: 0.777945359547933\n",
      "Epoch 10/10, Average Loss: 0.7790613571802775\n",
      "Epoch 1/10, Average Loss: 0.9526531298955282\n",
      "Epoch 2/10, Average Loss: 0.597745935122172\n",
      "Epoch 3/10, Average Loss: 0.42039037744204205\n",
      "Epoch 4/10, Average Loss: 0.32337483763694763\n",
      "Epoch 5/10, Average Loss: 0.2871093948682149\n",
      "Epoch 6/10, Average Loss: 0.25568652153015137\n",
      "Epoch 7/10, Average Loss: 0.22599262992540994\n",
      "Epoch 8/10, Average Loss: 0.19660218308369318\n",
      "Epoch 9/10, Average Loss: 0.19355249404907227\n",
      "Epoch 10/10, Average Loss: 0.16639250765244165\n",
      "Epoch 1/10, Average Loss: 0.9568756818771362\n",
      "Epoch 2/10, Average Loss: 0.5839642186959585\n",
      "Epoch 3/10, Average Loss: 0.38971277077992755\n",
      "Epoch 4/10, Average Loss: 0.2939084420601527\n",
      "Epoch 5/10, Average Loss: 0.24153678119182587\n",
      "Epoch 6/10, Average Loss: 0.208407461643219\n",
      "Epoch 7/10, Average Loss: 0.1776288946469625\n",
      "Epoch 8/10, Average Loss: 0.15619786083698273\n",
      "Epoch 9/10, Average Loss: 0.15804927547772726\n",
      "Epoch 10/10, Average Loss: 0.13005350033442178\n",
      "Epoch 1/10, Average Loss: 1.0040133396784465\n",
      "Epoch 2/10, Average Loss: 0.6154366036256155\n",
      "Epoch 3/10, Average Loss: 0.4330635766188304\n",
      "Epoch 4/10, Average Loss: 0.3341931700706482\n",
      "Epoch 5/10, Average Loss: 0.28695209821065265\n",
      "Epoch 6/10, Average Loss: 0.2474452704191208\n",
      "Epoch 7/10, Average Loss: 0.22497008740901947\n",
      "Epoch 8/10, Average Loss: 0.20620508243640265\n",
      "Epoch 9/10, Average Loss: 0.18596105525890985\n",
      "Epoch 10/10, Average Loss: 0.1743290275335312\n",
      "Epoch 1/10, Average Loss: 0.9478411873181661\n",
      "Epoch 2/10, Average Loss: 0.5931483507156372\n",
      "Epoch 3/10, Average Loss: 0.4134134252866109\n",
      "Epoch 4/10, Average Loss: 0.31977935632069904\n",
      "Epoch 5/10, Average Loss: 0.28571900228659314\n",
      "Epoch 6/10, Average Loss: 0.24736430247624716\n",
      "Epoch 7/10, Average Loss: 0.21049530307451883\n",
      "Epoch 8/10, Average Loss: 0.19752764701843262\n",
      "Epoch 9/10, Average Loss: 0.17799497892459235\n",
      "Epoch 10/10, Average Loss: 0.15622766315937042\n",
      "Epoch 1/10, Average Loss: 0.9413673281669617\n",
      "Epoch 2/10, Average Loss: 0.6227815349896749\n",
      "Epoch 3/10, Average Loss: 0.4227958122889201\n",
      "Epoch 4/10, Average Loss: 0.3371298561493556\n",
      "Epoch 5/10, Average Loss: 0.2888547231753667\n",
      "Epoch 6/10, Average Loss: 0.25860289732615155\n",
      "Epoch 7/10, Average Loss: 0.23005873461564383\n",
      "Epoch 8/10, Average Loss: 0.2200943926970164\n",
      "Epoch 9/10, Average Loss: 0.19092818101247153\n",
      "Epoch 10/10, Average Loss: 0.1788944328824679\n",
      "Epoch 1/10, Average Loss: 1.088836908340454\n",
      "Epoch 2/10, Average Loss: 1.0436142086982727\n",
      "Epoch 3/10, Average Loss: 0.9802949825922648\n",
      "Epoch 4/10, Average Loss: 0.9390166997909546\n",
      "Epoch 5/10, Average Loss: 0.903939962387085\n",
      "Epoch 6/10, Average Loss: 0.8566791216532389\n",
      "Epoch 7/10, Average Loss: 0.8256158034006754\n",
      "Epoch 8/10, Average Loss: 0.7833625674247742\n",
      "Epoch 9/10, Average Loss: 0.7476401925086975\n",
      "Epoch 10/10, Average Loss: 0.7156785726547241\n",
      "Epoch 1/10, Average Loss: 1.0891355673472087\n",
      "Epoch 2/10, Average Loss: 1.040841778119405\n",
      "Epoch 3/10, Average Loss: 0.9812530477841696\n",
      "Epoch 4/10, Average Loss: 0.9376272559165955\n",
      "Epoch 5/10, Average Loss: 0.9074693322181702\n",
      "Epoch 6/10, Average Loss: 0.8728571136792501\n",
      "Epoch 7/10, Average Loss: 0.8260100483894348\n",
      "Epoch 8/10, Average Loss: 0.7826712528864542\n",
      "Epoch 9/10, Average Loss: 0.7532936731974283\n",
      "Epoch 10/10, Average Loss: 0.7115223209063212\n",
      "Epoch 1/10, Average Loss: 1.140596826871236\n",
      "Epoch 2/10, Average Loss: 1.0522991220156352\n",
      "Epoch 3/10, Average Loss: 1.0312914649645488\n",
      "Epoch 4/10, Average Loss: 0.9739705125490824\n",
      "Epoch 5/10, Average Loss: 0.9263561964035034\n",
      "Epoch 6/10, Average Loss: 0.8862135807673136\n",
      "Epoch 7/10, Average Loss: 0.8503923614819845\n",
      "Epoch 8/10, Average Loss: 0.816933810710907\n",
      "Epoch 9/10, Average Loss: 0.7750977277755737\n",
      "Epoch 10/10, Average Loss: 0.7568958600362142\n",
      "Epoch 1/10, Average Loss: 1.0753647089004517\n",
      "Epoch 2/10, Average Loss: 1.0196937322616577\n",
      "Epoch 3/10, Average Loss: 0.9728356003761292\n",
      "Epoch 4/10, Average Loss: 0.9353399078051249\n",
      "Epoch 5/10, Average Loss: 0.9026299715042114\n",
      "Epoch 6/10, Average Loss: 0.8612086375554403\n",
      "Epoch 7/10, Average Loss: 0.8115511933962504\n",
      "Epoch 8/10, Average Loss: 0.7775972882906595\n",
      "Epoch 9/10, Average Loss: 0.7326899568239847\n",
      "Epoch 10/10, Average Loss: 0.7124757766723633\n",
      "Epoch 1/10, Average Loss: 1.0711002945899963\n",
      "Epoch 2/10, Average Loss: 1.044979453086853\n",
      "Epoch 3/10, Average Loss: 0.9805513223012289\n",
      "Epoch 4/10, Average Loss: 0.9407550493876139\n",
      "Epoch 5/10, Average Loss: 0.9056115547815958\n",
      "Epoch 6/10, Average Loss: 0.8544087409973145\n",
      "Epoch 7/10, Average Loss: 0.8262719909350077\n",
      "Epoch 8/10, Average Loss: 0.8020724852879842\n",
      "Epoch 9/10, Average Loss: 0.7477416396141052\n",
      "Epoch 10/10, Average Loss: 0.727184534072876\n",
      "Epoch 1/10, Average Loss: 1.1039588848749797\n",
      "Epoch 2/10, Average Loss: 1.104915201663971\n",
      "Epoch 3/10, Average Loss: 1.081530491511027\n",
      "Epoch 4/10, Average Loss: 1.081904927889506\n",
      "Epoch 5/10, Average Loss: 1.0835410157839458\n",
      "Epoch 6/10, Average Loss: 1.0713610450426738\n",
      "Epoch 7/10, Average Loss: 1.0774227380752563\n",
      "Epoch 8/10, Average Loss: 1.0674368540445964\n",
      "Epoch 9/10, Average Loss: 1.0537234942118328\n",
      "Epoch 10/10, Average Loss: 1.0499399900436401\n",
      "Epoch 1/10, Average Loss: 1.1039940118789673\n",
      "Epoch 2/10, Average Loss: 1.1028666098912556\n",
      "Epoch 3/10, Average Loss: 1.0857061743736267\n",
      "Epoch 4/10, Average Loss: 1.082420249780019\n",
      "Epoch 5/10, Average Loss: 1.092678705851237\n",
      "Epoch 6/10, Average Loss: 1.0975202719370525\n",
      "Epoch 7/10, Average Loss: 1.0804921785990398\n",
      "Epoch 8/10, Average Loss: 1.0695961117744446\n",
      "Epoch 9/10, Average Loss: 1.0714863936106365\n",
      "Epoch 10/10, Average Loss: 1.057874083518982\n",
      "Epoch 1/10, Average Loss: 1.1556628147761028\n",
      "Epoch 2/10, Average Loss: 1.112685223420461\n",
      "Epoch 3/10, Average Loss: 1.1366950869560242\n",
      "Epoch 4/10, Average Loss: 1.1196451981862385\n",
      "Epoch 5/10, Average Loss: 1.109570026397705\n",
      "Epoch 6/10, Average Loss: 1.1046313047409058\n",
      "Epoch 7/10, Average Loss: 1.1040666103363037\n",
      "Epoch 8/10, Average Loss: 1.1027739842732747\n",
      "Epoch 9/10, Average Loss: 1.0895111560821533\n",
      "Epoch 10/10, Average Loss: 1.1030276616414387\n",
      "Epoch 1/10, Average Loss: 1.0897270838419597\n",
      "Epoch 2/10, Average Loss: 1.0777988036473591\n",
      "Epoch 3/10, Average Loss: 1.0725682973861694\n",
      "Epoch 4/10, Average Loss: 1.0780129035313923\n",
      "Epoch 5/10, Average Loss: 1.0843030214309692\n",
      "Epoch 6/10, Average Loss: 1.0754974484443665\n",
      "Epoch 7/10, Average Loss: 1.0620113611221313\n",
      "Epoch 8/10, Average Loss: 1.0567614634831746\n",
      "Epoch 9/10, Average Loss: 1.036859432856242\n",
      "Epoch 10/10, Average Loss: 1.057074209054311\n",
      "Epoch 1/10, Average Loss: 1.0855640570322673\n",
      "Epoch 2/10, Average Loss: 1.1024854977925618\n",
      "Epoch 3/10, Average Loss: 1.0792083342870076\n",
      "Epoch 4/10, Average Loss: 1.0766413013140361\n",
      "Epoch 5/10, Average Loss: 1.079034686088562\n",
      "Epoch 6/10, Average Loss: 1.0612664024035137\n",
      "Epoch 7/10, Average Loss: 1.069659431775411\n",
      "Epoch 8/10, Average Loss: 1.0732604265213013\n",
      "Epoch 9/10, Average Loss: 1.042056381702423\n",
      "Epoch 10/10, Average Loss: 1.0493916074434917\n",
      "Epoch 1/10, Average Loss: 1.0579779545466106\n",
      "Epoch 2/10, Average Loss: 0.6857357819875082\n",
      "Epoch 3/10, Average Loss: 0.4805119534333547\n",
      "Epoch 4/10, Average Loss: 0.38278792301813763\n",
      "Epoch 5/10, Average Loss: 0.3259077270825704\n",
      "Epoch 6/10, Average Loss: 0.27111541231473285\n",
      "Epoch 7/10, Average Loss: 0.2414932201306025\n",
      "Epoch 8/10, Average Loss: 0.2050887644290924\n",
      "Epoch 9/10, Average Loss: 0.19648023943106332\n",
      "Epoch 10/10, Average Loss: 0.17275846501191458\n",
      "Epoch 1/10, Average Loss: 1.075968345006307\n",
      "Epoch 2/10, Average Loss: 0.6958608229955038\n",
      "Epoch 3/10, Average Loss: 0.4986795485019684\n",
      "Epoch 4/10, Average Loss: 0.38114969929059345\n",
      "Epoch 5/10, Average Loss: 0.3264642159144084\n",
      "Epoch 6/10, Average Loss: 0.27346037824948627\n",
      "Epoch 7/10, Average Loss: 0.23252934714158377\n",
      "Epoch 8/10, Average Loss: 0.2017904371023178\n",
      "Epoch 9/10, Average Loss: 0.1963799943526586\n",
      "Epoch 10/10, Average Loss: 0.16437684247891107\n",
      "Epoch 1/10, Average Loss: 1.1319477955500286\n",
      "Epoch 2/10, Average Loss: 0.7145096659660339\n",
      "Epoch 3/10, Average Loss: 0.5139415661493937\n",
      "Epoch 4/10, Average Loss: 0.40414755543073017\n",
      "Epoch 5/10, Average Loss: 0.3358240524927775\n",
      "Epoch 6/10, Average Loss: 0.2875539908806483\n",
      "Epoch 7/10, Average Loss: 0.2561233937740326\n",
      "Epoch 8/10, Average Loss: 0.23720106482505798\n",
      "Epoch 9/10, Average Loss: 0.2109170456727346\n",
      "Epoch 10/10, Average Loss: 0.1927200655142466\n",
      "Epoch 1/10, Average Loss: 1.1146246592203777\n",
      "Epoch 2/10, Average Loss: 0.7323249777158102\n",
      "Epoch 3/10, Average Loss: 0.5267069439093272\n",
      "Epoch 4/10, Average Loss: 0.4180416365464528\n",
      "Epoch 5/10, Average Loss: 0.3586955666542053\n",
      "Epoch 6/10, Average Loss: 0.3081243932247162\n",
      "Epoch 7/10, Average Loss: 0.26250627140204114\n",
      "Epoch 8/10, Average Loss: 0.23890235523382822\n",
      "Epoch 9/10, Average Loss: 0.21123321851094565\n",
      "Epoch 10/10, Average Loss: 0.18957138061523438\n",
      "Epoch 1/10, Average Loss: 1.0947706302007039\n",
      "Epoch 2/10, Average Loss: 0.7164071798324585\n",
      "Epoch 3/10, Average Loss: 0.5005430380503336\n",
      "Epoch 4/10, Average Loss: 0.4075656433900197\n",
      "Epoch 5/10, Average Loss: 0.3511979877948761\n",
      "Epoch 6/10, Average Loss: 0.30248509844144184\n",
      "Epoch 7/10, Average Loss: 0.2669978241125743\n",
      "Epoch 8/10, Average Loss: 0.2475897173086802\n",
      "Epoch 9/10, Average Loss: 0.21907385687033334\n",
      "Epoch 10/10, Average Loss: 0.20691039164861044\n",
      "Epoch 1/10, Average Loss: 1.1974233388900757\n",
      "Epoch 2/10, Average Loss: 1.1641286214192708\n",
      "Epoch 3/10, Average Loss: 1.0986611644426982\n",
      "Epoch 4/10, Average Loss: 1.0622400442759197\n",
      "Epoch 5/10, Average Loss: 0.9939977725346884\n",
      "Epoch 6/10, Average Loss: 0.956204374631246\n",
      "Epoch 7/10, Average Loss: 0.9043425718943278\n",
      "Epoch 8/10, Average Loss: 0.8628995219866434\n",
      "Epoch 9/10, Average Loss: 0.8238244851430258\n",
      "Epoch 10/10, Average Loss: 0.7967752814292908\n",
      "Epoch 1/10, Average Loss: 1.2195005019505818\n",
      "Epoch 2/10, Average Loss: 1.1620643138885498\n",
      "Epoch 3/10, Average Loss: 1.0993881225585938\n",
      "Epoch 4/10, Average Loss: 1.0613322655359905\n",
      "Epoch 5/10, Average Loss: 1.0149734020233154\n",
      "Epoch 6/10, Average Loss: 0.9850973089536031\n",
      "Epoch 7/10, Average Loss: 0.9402206142743429\n",
      "Epoch 8/10, Average Loss: 0.8984238306681315\n",
      "Epoch 9/10, Average Loss: 0.8425755699475607\n",
      "Epoch 10/10, Average Loss: 0.819220761458079\n",
      "Epoch 1/10, Average Loss: 1.2560189167658489\n",
      "Epoch 2/10, Average Loss: 1.2095286846160889\n",
      "Epoch 3/10, Average Loss: 1.1623683373133342\n",
      "Epoch 4/10, Average Loss: 1.1049773295720418\n",
      "Epoch 5/10, Average Loss: 1.0454596877098083\n",
      "Epoch 6/10, Average Loss: 0.9980652729670206\n",
      "Epoch 7/10, Average Loss: 0.9766995509465536\n",
      "Epoch 8/10, Average Loss: 0.9205017487208048\n",
      "Epoch 9/10, Average Loss: 0.875204841295878\n",
      "Epoch 10/10, Average Loss: 0.8445291121800741\n",
      "Epoch 1/10, Average Loss: 1.255225380261739\n",
      "Epoch 2/10, Average Loss: 1.2021981080373128\n",
      "Epoch 3/10, Average Loss: 1.1437203486760457\n",
      "Epoch 4/10, Average Loss: 1.1111471056938171\n",
      "Epoch 5/10, Average Loss: 1.0711236993471782\n",
      "Epoch 6/10, Average Loss: 1.0071535110473633\n",
      "Epoch 7/10, Average Loss: 0.9594708283742269\n",
      "Epoch 8/10, Average Loss: 0.9248749812444051\n",
      "Epoch 9/10, Average Loss: 0.8780330816904703\n",
      "Epoch 10/10, Average Loss: 0.8543188770612081\n",
      "Epoch 1/10, Average Loss: 1.2534880638122559\n",
      "Epoch 2/10, Average Loss: 1.2062207857767742\n",
      "Epoch 3/10, Average Loss: 1.1247910857200623\n",
      "Epoch 4/10, Average Loss: 1.077172080675761\n",
      "Epoch 5/10, Average Loss: 1.0291171272595723\n",
      "Epoch 6/10, Average Loss: 0.9725239872932434\n",
      "Epoch 7/10, Average Loss: 0.9362545013427734\n",
      "Epoch 8/10, Average Loss: 0.9112569093704224\n",
      "Epoch 9/10, Average Loss: 0.8587652444839478\n",
      "Epoch 10/10, Average Loss: 0.8410860300064087\n",
      "Epoch 1/10, Average Loss: 1.2135591109593709\n",
      "Epoch 2/10, Average Loss: 1.2337944507598877\n",
      "Epoch 3/10, Average Loss: 1.2188504139582317\n",
      "Epoch 4/10, Average Loss: 1.2293245395024617\n",
      "Epoch 5/10, Average Loss: 1.1960115035374959\n",
      "Epoch 6/10, Average Loss: 1.2036443154017131\n",
      "Epoch 7/10, Average Loss: 1.1817543109258015\n",
      "Epoch 8/10, Average Loss: 1.1794100602467854\n",
      "Epoch 9/10, Average Loss: 1.1612473328908284\n",
      "Epoch 10/10, Average Loss: 1.168673038482666\n",
      "Epoch 1/10, Average Loss: 1.236566424369812\n",
      "Epoch 2/10, Average Loss: 1.2310067017873128\n",
      "Epoch 3/10, Average Loss: 1.2189104557037354\n",
      "Epoch 4/10, Average Loss: 1.2283192078272502\n",
      "Epoch 5/10, Average Loss: 1.2238948742548625\n",
      "Epoch 6/10, Average Loss: 1.233350694179535\n",
      "Epoch 7/10, Average Loss: 1.2254081964492798\n",
      "Epoch 8/10, Average Loss: 1.2198799848556519\n",
      "Epoch 9/10, Average Loss: 1.1898683706919353\n",
      "Epoch 10/10, Average Loss: 1.1965255737304688\n",
      "Epoch 1/10, Average Loss: 1.270355502764384\n",
      "Epoch 2/10, Average Loss: 1.282998005549113\n",
      "Epoch 3/10, Average Loss: 1.285650650660197\n",
      "Epoch 4/10, Average Loss: 1.2741336425145466\n",
      "Epoch 5/10, Average Loss: 1.2553929487864177\n",
      "Epoch 6/10, Average Loss: 1.2527902523676555\n",
      "Epoch 7/10, Average Loss: 1.2732085386912029\n",
      "Epoch 8/10, Average Loss: 1.24332594871521\n",
      "Epoch 9/10, Average Loss: 1.2342698971430461\n",
      "Epoch 10/10, Average Loss: 1.2312859694163005\n",
      "Epoch 1/10, Average Loss: 1.2714299360911052\n",
      "Epoch 2/10, Average Loss: 1.2697511911392212\n",
      "Epoch 3/10, Average Loss: 1.2610992590586345\n",
      "Epoch 4/10, Average Loss: 1.2817797660827637\n",
      "Epoch 5/10, Average Loss: 1.2805364926656086\n",
      "Epoch 6/10, Average Loss: 1.2515734036763508\n",
      "Epoch 7/10, Average Loss: 1.2407089074452717\n",
      "Epoch 8/10, Average Loss: 1.247321605682373\n",
      "Epoch 9/10, Average Loss: 1.2350298166275024\n",
      "Epoch 10/10, Average Loss: 1.239428202311198\n",
      "Epoch 1/10, Average Loss: 1.2717150847117107\n",
      "Epoch 2/10, Average Loss: 1.2787080605824788\n",
      "Epoch 3/10, Average Loss: 1.2454125881195068\n",
      "Epoch 4/10, Average Loss: 1.2432485421498616\n",
      "Epoch 5/10, Average Loss: 1.2392316261927288\n",
      "Epoch 6/10, Average Loss: 1.2239702145258586\n",
      "Epoch 7/10, Average Loss: 1.224101146062215\n",
      "Epoch 8/10, Average Loss: 1.2332199414571126\n",
      "Epoch 9/10, Average Loss: 1.2089755535125732\n",
      "Epoch 10/10, Average Loss: 1.2223186890284221\n",
      "Epoch 1/10, Average Loss: 0.8461300333340963\n",
      "Epoch 2/10, Average Loss: 0.6597559253374735\n",
      "Epoch 3/10, Average Loss: 0.53117968638738\n",
      "Epoch 4/10, Average Loss: 0.4550279875596364\n",
      "Epoch 5/10, Average Loss: 0.4169487754503886\n",
      "Epoch 6/10, Average Loss: 0.3751689891020457\n",
      "Epoch 7/10, Average Loss: 0.3535468677679698\n",
      "Epoch 8/10, Average Loss: 0.32315022746721905\n",
      "Epoch 9/10, Average Loss: 0.3101242184638977\n",
      "Epoch 10/10, Average Loss: 0.2847977976004283\n",
      "Epoch 1/10, Average Loss: 0.8448986212412516\n",
      "Epoch 2/10, Average Loss: 0.6573531627655029\n",
      "Epoch 3/10, Average Loss: 0.5279684166113535\n",
      "Epoch 4/10, Average Loss: 0.4498816827932994\n",
      "Epoch 5/10, Average Loss: 0.4098506172498067\n",
      "Epoch 6/10, Average Loss: 0.37212618192036945\n",
      "Epoch 7/10, Average Loss: 0.34018561244010925\n",
      "Epoch 8/10, Average Loss: 0.3167482018470764\n",
      "Epoch 9/10, Average Loss: 0.30196236570676166\n",
      "Epoch 10/10, Average Loss: 0.2739480833212535\n",
      "Epoch 1/10, Average Loss: 0.8552273313204447\n",
      "Epoch 2/10, Average Loss: 0.6642333269119263\n",
      "Epoch 3/10, Average Loss: 0.5453199942906698\n",
      "Epoch 4/10, Average Loss: 0.46932007869084674\n",
      "Epoch 5/10, Average Loss: 0.420840044816335\n",
      "Epoch 6/10, Average Loss: 0.3876095612843831\n",
      "Epoch 7/10, Average Loss: 0.3621134360631307\n",
      "Epoch 8/10, Average Loss: 0.3511234869559606\n",
      "Epoch 9/10, Average Loss: 0.3216090500354767\n",
      "Epoch 10/10, Average Loss: 0.30492157737414044\n",
      "Epoch 1/10, Average Loss: 0.8414719700813293\n",
      "Epoch 2/10, Average Loss: 0.6614014705022176\n",
      "Epoch 3/10, Average Loss: 0.5418321291605631\n",
      "Epoch 4/10, Average Loss: 0.4656418561935425\n",
      "Epoch 5/10, Average Loss: 0.4269406795501709\n",
      "Epoch 6/10, Average Loss: 0.39735568563143414\n",
      "Epoch 7/10, Average Loss: 0.3705134987831116\n",
      "Epoch 8/10, Average Loss: 0.345913290977478\n",
      "Epoch 9/10, Average Loss: 0.3177712659041087\n",
      "Epoch 10/10, Average Loss: 0.298299103975296\n",
      "Epoch 1/10, Average Loss: 0.853930135567983\n",
      "Epoch 2/10, Average Loss: 0.6628874937693278\n",
      "Epoch 3/10, Average Loss: 0.5351566771666209\n",
      "Epoch 4/10, Average Loss: 0.45957175890604657\n",
      "Epoch 5/10, Average Loss: 0.4155540466308594\n",
      "Epoch 6/10, Average Loss: 0.38314589858055115\n",
      "Epoch 7/10, Average Loss: 0.3628747860590617\n",
      "Epoch 8/10, Average Loss: 0.345094233751297\n",
      "Epoch 9/10, Average Loss: 0.31469691793123883\n",
      "Epoch 10/10, Average Loss: 0.3051268458366394\n",
      "Epoch 1/10, Average Loss: 0.9094696442286173\n",
      "Epoch 2/10, Average Loss: 0.8915650049845377\n",
      "Epoch 3/10, Average Loss: 0.8721445202827454\n",
      "Epoch 4/10, Average Loss: 0.8465875784556071\n",
      "Epoch 5/10, Average Loss: 0.8171836932500204\n",
      "Epoch 6/10, Average Loss: 0.8061380386352539\n",
      "Epoch 7/10, Average Loss: 0.7796748081843058\n",
      "Epoch 8/10, Average Loss: 0.7635701696077982\n",
      "Epoch 9/10, Average Loss: 0.7419365247090658\n",
      "Epoch 10/10, Average Loss: 0.726576050122579\n",
      "Epoch 1/10, Average Loss: 0.9102556308110555\n",
      "Epoch 2/10, Average Loss: 0.8818226854006449\n",
      "Epoch 3/10, Average Loss: 0.8599892656008402\n",
      "Epoch 4/10, Average Loss: 0.8409080108006796\n",
      "Epoch 5/10, Average Loss: 0.8177209893862406\n",
      "Epoch 6/10, Average Loss: 0.8012171387672424\n",
      "Epoch 7/10, Average Loss: 0.7838233908017477\n",
      "Epoch 8/10, Average Loss: 0.7599593798319498\n",
      "Epoch 9/10, Average Loss: 0.7402922113736471\n",
      "Epoch 10/10, Average Loss: 0.7223105033238729\n",
      "Epoch 1/10, Average Loss: 0.9069838722546896\n",
      "Epoch 2/10, Average Loss: 0.894991417725881\n",
      "Epoch 3/10, Average Loss: 0.8705669045448303\n",
      "Epoch 4/10, Average Loss: 0.8471422592798868\n",
      "Epoch 5/10, Average Loss: 0.8243709802627563\n",
      "Epoch 6/10, Average Loss: 0.8077848156293234\n",
      "Epoch 7/10, Average Loss: 0.7924834887186686\n",
      "Epoch 8/10, Average Loss: 0.7648897965749105\n",
      "Epoch 9/10, Average Loss: 0.7493424614270529\n",
      "Epoch 10/10, Average Loss: 0.7319629987080892\n",
      "Epoch 1/10, Average Loss: 0.898838738600413\n",
      "Epoch 2/10, Average Loss: 0.87767094373703\n",
      "Epoch 3/10, Average Loss: 0.8515047033627828\n",
      "Epoch 4/10, Average Loss: 0.8410747051239014\n",
      "Epoch 5/10, Average Loss: 0.8200451135635376\n",
      "Epoch 6/10, Average Loss: 0.7914568583170573\n",
      "Epoch 7/10, Average Loss: 0.7690138419469198\n",
      "Epoch 8/10, Average Loss: 0.7593991557757059\n",
      "Epoch 9/10, Average Loss: 0.7423709829648336\n",
      "Epoch 10/10, Average Loss: 0.7238903840382894\n",
      "Epoch 1/10, Average Loss: 0.9259664614995321\n",
      "Epoch 2/10, Average Loss: 0.8946699897448221\n",
      "Epoch 3/10, Average Loss: 0.8672840595245361\n",
      "Epoch 4/10, Average Loss: 0.8456170757611593\n",
      "Epoch 5/10, Average Loss: 0.82576056321462\n",
      "Epoch 6/10, Average Loss: 0.8057183821996053\n",
      "Epoch 7/10, Average Loss: 0.7831516663233439\n",
      "Epoch 8/10, Average Loss: 0.7698877652486166\n",
      "Epoch 9/10, Average Loss: 0.7472628752390543\n",
      "Epoch 10/10, Average Loss: 0.7330140074094137\n",
      "Epoch 1/10, Average Loss: 0.9162908792495728\n",
      "Epoch 2/10, Average Loss: 0.9200472434361776\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 27\u001b[0m\n\u001b[1;32m     23\u001b[0m input_size \u001b[39m=\u001b[39m train_X\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n\u001b[1;32m     25\u001b[0m NumbOfClasses \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m\n\u001b[0;32m---> 27\u001b[0m grid_results_voting, best_accuracy, best_combination \u001b[39m=\u001b[39m grid_search_cv(\n\u001b[1;32m     28\u001b[0m     hidden_layer_sizes_list, activation_functions, learning_rates, batch_sizes, num_epochs_list, data_loader, NumbOfClasses,\n\u001b[1;32m     29\u001b[0m     k_folds\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m, use_scaling\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     31\u001b[0m grid_results_voting[\u001b[39m'\u001b[39m\u001b[39mdataset\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mcong_voting\u001b[39m\u001b[39m'\u001b[39m\n",
      "Cell \u001b[0;32mIn[7], line 40\u001b[0m, in \u001b[0;36mgrid_search_cv\u001b[0;34m(hidden_layer_sizes_list, activation_functions, learning_rates, batch_sizes, num_epochs_list, train_loader, NumbOfClasses, k_folds, use_scaling)\u001b[0m\n\u001b[1;32m     37\u001b[0m     X_train_scaled, X_test_scaled \u001b[39m=\u001b[39m X_train, X_test\n\u001b[1;32m     39\u001b[0m train_start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m---> 40\u001b[0m train_model(model, DataLoader(TensorDataset(X_train_scaled, y_train), batch_size\u001b[39m=\u001b[39;49mbatch_size, shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m), optimizer, criterion, num_epochs)\n\u001b[1;32m     41\u001b[0m train_end_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m     42\u001b[0m fold_training_times\u001b[39m.\u001b[39mappend(train_end_time \u001b[39m-\u001b[39m train_start_time)\n",
      "Cell \u001b[0;32mIn[4], line 14\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, optimizer, criterion, num_epochs)\u001b[0m\n\u001b[1;32m     12\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     13\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m---> 14\u001b[0m     optimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m     16\u001b[0m     total_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()  \u001b[39m# Accumulate the batch loss\u001b[39;00m\n\u001b[1;32m     18\u001b[0m average_loss \u001b[39m=\u001b[39m total_loss \u001b[39m/\u001b[39m num_batches\n",
      "File \u001b[0;32m~/MachineLearning23ws/.venv/lib/python3.11/site-packages/torch/optim/optimizer.py:373\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    369\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    370\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m}\u001b[39;00m\u001b[39m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[39m{\u001b[39;00mresult\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    371\u001b[0m             )\n\u001b[0;32m--> 373\u001b[0m out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    374\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    376\u001b[0m \u001b[39m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/MachineLearning23ws/.venv/lib/python3.11/site-packages/torch/optim/optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefaults[\u001b[39m'\u001b[39m\u001b[39mdifferentiable\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     75\u001b[0m     torch\u001b[39m.\u001b[39m_dynamo\u001b[39m.\u001b[39mgraph_break()\n\u001b[0;32m---> 76\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     77\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     torch\u001b[39m.\u001b[39m_dynamo\u001b[39m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/MachineLearning23ws/.venv/lib/python3.11/site-packages/torch/optim/adam.py:163\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    152\u001b[0m     beta1, beta2 \u001b[39m=\u001b[39m group[\u001b[39m'\u001b[39m\u001b[39mbetas\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m    154\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_group(\n\u001b[1;32m    155\u001b[0m         group,\n\u001b[1;32m    156\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    160\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    161\u001b[0m         state_steps)\n\u001b[0;32m--> 163\u001b[0m     adam(\n\u001b[1;32m    164\u001b[0m         params_with_grad,\n\u001b[1;32m    165\u001b[0m         grads,\n\u001b[1;32m    166\u001b[0m         exp_avgs,\n\u001b[1;32m    167\u001b[0m         exp_avg_sqs,\n\u001b[1;32m    168\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    169\u001b[0m         state_steps,\n\u001b[1;32m    170\u001b[0m         amsgrad\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mamsgrad\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    171\u001b[0m         beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    172\u001b[0m         beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    173\u001b[0m         lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    174\u001b[0m         weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    175\u001b[0m         eps\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    176\u001b[0m         maximize\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    177\u001b[0m         foreach\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mforeach\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    178\u001b[0m         capturable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mcapturable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    179\u001b[0m         differentiable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mdifferentiable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    180\u001b[0m         fused\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mfused\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    181\u001b[0m         grad_scale\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mgrad_scale\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    182\u001b[0m         found_inf\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mfound_inf\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    183\u001b[0m     )\n\u001b[1;32m    185\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/MachineLearning23ws/.venv/lib/python3.11/site-packages/torch/optim/adam.py:311\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    309\u001b[0m     func \u001b[39m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 311\u001b[0m func(params,\n\u001b[1;32m    312\u001b[0m      grads,\n\u001b[1;32m    313\u001b[0m      exp_avgs,\n\u001b[1;32m    314\u001b[0m      exp_avg_sqs,\n\u001b[1;32m    315\u001b[0m      max_exp_avg_sqs,\n\u001b[1;32m    316\u001b[0m      state_steps,\n\u001b[1;32m    317\u001b[0m      amsgrad\u001b[39m=\u001b[39;49mamsgrad,\n\u001b[1;32m    318\u001b[0m      beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    319\u001b[0m      beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    320\u001b[0m      lr\u001b[39m=\u001b[39;49mlr,\n\u001b[1;32m    321\u001b[0m      weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[1;32m    322\u001b[0m      eps\u001b[39m=\u001b[39;49meps,\n\u001b[1;32m    323\u001b[0m      maximize\u001b[39m=\u001b[39;49mmaximize,\n\u001b[1;32m    324\u001b[0m      capturable\u001b[39m=\u001b[39;49mcapturable,\n\u001b[1;32m    325\u001b[0m      differentiable\u001b[39m=\u001b[39;49mdifferentiable,\n\u001b[1;32m    326\u001b[0m      grad_scale\u001b[39m=\u001b[39;49mgrad_scale,\n\u001b[1;32m    327\u001b[0m      found_inf\u001b[39m=\u001b[39;49mfound_inf)\n",
      "File \u001b[0;32m~/MachineLearning23ws/.venv/lib/python3.11/site-packages/torch/optim/adam.py:384\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    381\u001b[0m     param \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mview_as_real(param)\n\u001b[1;32m    383\u001b[0m \u001b[39m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[0;32m--> 384\u001b[0m exp_avg\u001b[39m.\u001b[39;49mlerp_(grad, \u001b[39m1\u001b[39;49m \u001b[39m-\u001b[39;49m beta1)\n\u001b[1;32m    385\u001b[0m exp_avg_sq\u001b[39m.\u001b[39mmul_(beta2)\u001b[39m.\u001b[39maddcmul_(grad, grad\u001b[39m.\u001b[39mconj(), value\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m beta2)\n\u001b[1;32m    387\u001b[0m \u001b[39mif\u001b[39;00m capturable \u001b[39mor\u001b[39;00m differentiable:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hidden_layer_sizes_list = [[5],[10],[25, 30], [20, 25, 30]]\n",
    "activation_functions = [F.tanh, F.relu, F.sigmoid]\n",
    "learning_rates = [0.01, 0.001, 0.0001]\n",
    "batch_sizes = [64]\n",
    "num_epochs_list = [10]\n",
    "\n",
    "dataset = cong_voting\n",
    "\n",
    "#smote_in = True\n",
    "#train_X, train_Y, test_X, test_Y = train_test_split(dataset, \"class\", return_torch=True, DoSmote=smote_in)\n",
    "\n",
    "#train_data = TensorDataset(train_X, train_Y)\n",
    "#train_loader = DataLoader(train_data, batch_size=32, shuffle=False)\n",
    "\n",
    "#test_data = TensorDataset(test_X, test_Y)\n",
    "#test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n",
    "\n",
    "X = dataset.drop([\"class\"], axis=1).values\n",
    "Y = dataset[\"class\"].values\n",
    "data = TensorDataset(torch.tensor(X), torch.tensor(Y))\n",
    "data_loader = DataLoader(data, batch_size=32, shuffle=False)\n",
    "\n",
    "input_size = X.shape[1]\n",
    "\n",
    "NumbOfClasses = 2\n",
    "\n",
    "grid_results_voting, best_accuracy, best_combination = grid_search_cv(\n",
    "    hidden_layer_sizes_list, activation_functions, learning_rates, batch_sizes, num_epochs_list, data_loader, NumbOfClasses,\n",
    "    k_folds=5, use_scaling=True)\n",
    "\n",
    "grid_results_voting['dataset'] = 'cong_voting'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hidden Layer Sizes</th>\n",
       "      <th>Activation Function</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Batch Size</th>\n",
       "      <th>Number of Epochs</th>\n",
       "      <th>Average Accuracy</th>\n",
       "      <th>Average Training Time</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[5]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.896471</td>\n",
       "      <td>0.141268</td>\n",
       "      <td>cong_voting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[5]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.287731</td>\n",
       "      <td>0.122248</td>\n",
       "      <td>cong_voting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[5]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.212773</td>\n",
       "      <td>0.124714</td>\n",
       "      <td>cong_voting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[5]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.890756</td>\n",
       "      <td>0.126250</td>\n",
       "      <td>cong_voting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[5]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.304706</td>\n",
       "      <td>0.119831</td>\n",
       "      <td>cong_voting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[5]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.235798</td>\n",
       "      <td>0.114162</td>\n",
       "      <td>cong_voting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[5]</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.913782</td>\n",
       "      <td>0.058026</td>\n",
       "      <td>cong_voting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[5]</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>0.057321</td>\n",
       "      <td>cong_voting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[5]</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.166891</td>\n",
       "      <td>0.054440</td>\n",
       "      <td>cong_voting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[10]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.936639</td>\n",
       "      <td>0.057579</td>\n",
       "      <td>cong_voting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[10]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.528571</td>\n",
       "      <td>0.058448</td>\n",
       "      <td>cong_voting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[10]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.373782</td>\n",
       "      <td>0.058223</td>\n",
       "      <td>cong_voting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[10]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.896639</td>\n",
       "      <td>0.059396</td>\n",
       "      <td>cong_voting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[10]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.581008</td>\n",
       "      <td>0.065138</td>\n",
       "      <td>cong_voting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[10]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.449244</td>\n",
       "      <td>0.055740</td>\n",
       "      <td>cong_voting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[10]</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.919328</td>\n",
       "      <td>0.057038</td>\n",
       "      <td>cong_voting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[10]</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.385714</td>\n",
       "      <td>0.056266</td>\n",
       "      <td>cong_voting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[10]</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.368235</td>\n",
       "      <td>0.059511</td>\n",
       "      <td>cong_voting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[25, 30]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.965546</td>\n",
       "      <td>0.066926</td>\n",
       "      <td>cong_voting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[25, 30]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.936639</td>\n",
       "      <td>0.071426</td>\n",
       "      <td>cong_voting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[25, 30]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.890756</td>\n",
       "      <td>0.067815</td>\n",
       "      <td>cong_voting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[25, 30]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.965378</td>\n",
       "      <td>0.069432</td>\n",
       "      <td>cong_voting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[25, 30]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.948067</td>\n",
       "      <td>0.071041</td>\n",
       "      <td>cong_voting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[25, 30]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.873445</td>\n",
       "      <td>0.065911</td>\n",
       "      <td>cong_voting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[25, 30]</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.948235</td>\n",
       "      <td>0.067652</td>\n",
       "      <td>cong_voting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[25, 30]</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.631765</td>\n",
       "      <td>0.068159</td>\n",
       "      <td>cong_voting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[25, 30]</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.919328</td>\n",
       "      <td>0.072122</td>\n",
       "      <td>cong_voting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[20, 25, 30]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.948067</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>cong_voting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[20, 25, 30]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.873445</td>\n",
       "      <td>0.075941</td>\n",
       "      <td>cong_voting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[20, 25, 30]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.494286</td>\n",
       "      <td>0.080217</td>\n",
       "      <td>cong_voting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[20, 25, 30]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.925210</td>\n",
       "      <td>0.078178</td>\n",
       "      <td>cong_voting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[20, 25, 30]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.890420</td>\n",
       "      <td>0.081912</td>\n",
       "      <td>cong_voting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[20, 25, 30]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.631597</td>\n",
       "      <td>0.077753</td>\n",
       "      <td>cong_voting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[20, 25, 30]</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.919496</td>\n",
       "      <td>0.081349</td>\n",
       "      <td>cong_voting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[20, 25, 30]</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.631765</td>\n",
       "      <td>0.078873</td>\n",
       "      <td>cong_voting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[20, 25, 30]</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.631765</td>\n",
       "      <td>0.078178</td>\n",
       "      <td>cong_voting</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Hidden Layer Sizes Activation Function  Learning Rate  Batch Size  \\\n",
       "0                 [5]                tanh         0.0100          64   \n",
       "1                 [5]                tanh         0.0010          64   \n",
       "2                 [5]                tanh         0.0001          64   \n",
       "3                 [5]                relu         0.0100          64   \n",
       "4                 [5]                relu         0.0010          64   \n",
       "5                 [5]                relu         0.0001          64   \n",
       "6                 [5]             sigmoid         0.0100          64   \n",
       "7                 [5]             sigmoid         0.0010          64   \n",
       "8                 [5]             sigmoid         0.0001          64   \n",
       "9                [10]                tanh         0.0100          64   \n",
       "10               [10]                tanh         0.0010          64   \n",
       "11               [10]                tanh         0.0001          64   \n",
       "12               [10]                relu         0.0100          64   \n",
       "13               [10]                relu         0.0010          64   \n",
       "14               [10]                relu         0.0001          64   \n",
       "15               [10]             sigmoid         0.0100          64   \n",
       "16               [10]             sigmoid         0.0010          64   \n",
       "17               [10]             sigmoid         0.0001          64   \n",
       "18           [25, 30]                tanh         0.0100          64   \n",
       "19           [25, 30]                tanh         0.0010          64   \n",
       "20           [25, 30]                tanh         0.0001          64   \n",
       "21           [25, 30]                relu         0.0100          64   \n",
       "22           [25, 30]                relu         0.0010          64   \n",
       "23           [25, 30]                relu         0.0001          64   \n",
       "24           [25, 30]             sigmoid         0.0100          64   \n",
       "25           [25, 30]             sigmoid         0.0010          64   \n",
       "26           [25, 30]             sigmoid         0.0001          64   \n",
       "27       [20, 25, 30]                tanh         0.0100          64   \n",
       "28       [20, 25, 30]                tanh         0.0010          64   \n",
       "29       [20, 25, 30]                tanh         0.0001          64   \n",
       "30       [20, 25, 30]                relu         0.0100          64   \n",
       "31       [20, 25, 30]                relu         0.0010          64   \n",
       "32       [20, 25, 30]                relu         0.0001          64   \n",
       "33       [20, 25, 30]             sigmoid         0.0100          64   \n",
       "34       [20, 25, 30]             sigmoid         0.0010          64   \n",
       "35       [20, 25, 30]             sigmoid         0.0001          64   \n",
       "\n",
       "    Number of Epochs  Average Accuracy  Average Training Time      dataset  \n",
       "0                 10          0.896471               0.141268  cong_voting  \n",
       "1                 10          0.287731               0.122248  cong_voting  \n",
       "2                 10          0.212773               0.124714  cong_voting  \n",
       "3                 10          0.890756               0.126250  cong_voting  \n",
       "4                 10          0.304706               0.119831  cong_voting  \n",
       "5                 10          0.235798               0.114162  cong_voting  \n",
       "6                 10          0.913782               0.058026  cong_voting  \n",
       "7                 10          0.264706               0.057321  cong_voting  \n",
       "8                 10          0.166891               0.054440  cong_voting  \n",
       "9                 10          0.936639               0.057579  cong_voting  \n",
       "10                10          0.528571               0.058448  cong_voting  \n",
       "11                10          0.373782               0.058223  cong_voting  \n",
       "12                10          0.896639               0.059396  cong_voting  \n",
       "13                10          0.581008               0.065138  cong_voting  \n",
       "14                10          0.449244               0.055740  cong_voting  \n",
       "15                10          0.919328               0.057038  cong_voting  \n",
       "16                10          0.385714               0.056266  cong_voting  \n",
       "17                10          0.368235               0.059511  cong_voting  \n",
       "18                10          0.965546               0.066926  cong_voting  \n",
       "19                10          0.936639               0.071426  cong_voting  \n",
       "20                10          0.890756               0.067815  cong_voting  \n",
       "21                10          0.965378               0.069432  cong_voting  \n",
       "22                10          0.948067               0.071041  cong_voting  \n",
       "23                10          0.873445               0.065911  cong_voting  \n",
       "24                10          0.948235               0.067652  cong_voting  \n",
       "25                10          0.631765               0.068159  cong_voting  \n",
       "26                10          0.919328               0.072122  cong_voting  \n",
       "27                10          0.948067               0.074412  cong_voting  \n",
       "28                10          0.873445               0.075941  cong_voting  \n",
       "29                10          0.494286               0.080217  cong_voting  \n",
       "30                10          0.925210               0.078178  cong_voting  \n",
       "31                10          0.890420               0.081912  cong_voting  \n",
       "32                10          0.631597               0.077753  cong_voting  \n",
       "33                10          0.919496               0.081349  cong_voting  \n",
       "34                10          0.631765               0.078873  cong_voting  \n",
       "35                10          0.631765               0.078178  cong_voting  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_results_voting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grid_results_voting' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m full_results_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([grid_results_voting,grid_results_wine,grid_results_bank], ignore_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      2\u001b[0m full_results_df\n",
      "\u001b[0;31mNameError\u001b[0m: name 'grid_results_voting' is not defined"
     ]
    }
   ],
   "source": [
    "full_results_df = pd.concat([grid_results_voting,grid_results_wine,grid_results_bank], ignore_index=True)\n",
    "full_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'full_results_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m full_results_df\u001b[39m.\u001b[39mto_csv(\u001b[39m'\u001b[39m\u001b[39m./results/cv_grid_search_results.csv\u001b[39m\u001b[39m'\u001b[39m, index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'full_results_df' is not defined"
     ]
    }
   ],
   "source": [
    "full_results_df.to_csv('./results/cv_grid_search_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top Perfroming Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'full_results_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m top_models_rows \u001b[39m=\u001b[39m []\n\u001b[0;32m----> 3\u001b[0m \u001b[39mfor\u001b[39;00m dataset \u001b[39min\u001b[39;00m full_results_df[\u001b[39m'\u001b[39m\u001b[39mdataset\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39munique():\n\u001b[1;32m      4\u001b[0m     top_models_rows\u001b[39m.\u001b[39mextend(full_results_df[full_results_df[\u001b[39m'\u001b[39m\u001b[39mdataset\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m dataset]\u001b[39m.\u001b[39mnlargest(\u001b[39m2\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAverage Accuracy\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39miterrows())\n\u001b[1;32m      6\u001b[0m top_models_rows_data \u001b[39m=\u001b[39m [row[\u001b[39m1\u001b[39m] \u001b[39mfor\u001b[39;00m row \u001b[39min\u001b[39;00m top_models_rows]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'full_results_df' is not defined"
     ]
    }
   ],
   "source": [
    "top_models_rows = []\n",
    "\n",
    "for dataset in full_results_df['dataset'].unique():\n",
    "    top_models_rows.extend(full_results_df[full_results_df['dataset'] == dataset].nlargest(2, 'Average Accuracy').iterrows())\n",
    "\n",
    "top_models_rows_data = [row[1] for row in top_models_rows]\n",
    "\n",
    "top_models_df = pd.DataFrame(top_models_rows_data).reset_index(drop=True)\n",
    "\n",
    "top_models_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
