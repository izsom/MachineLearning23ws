{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import cv2\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import albumentations\n",
    "import argparse\n",
    "#import models\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import transforms\n",
    "from torchvision.utils import save_image\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 128, kernel_size=5, padding=1)\n",
    "        self.conv2 = nn.Conv2d(128, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 3, kernel_size=1, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "\n",
    "        return x\n",
    "\n",
    "class SimpleAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleAE, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=5),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(32, 64, kernel_size=5),\n",
    "            nn.ReLU(True))\n",
    "        self.decoder = nn.Sequential(             \n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=5),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(32, 3, kernel_size=5),\n",
    "            nn.ReLU(True))\n",
    "    def forward(self,x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constructing the argument parser\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('-e', '--epochs', type=int, default=50, \n",
    "            help='number of epochs to train the model for')\n",
    "args = vars(parser.parse_args())\n",
    "\n",
    "# helper functions\n",
    "image_dir = 'drive/My Drive/Image-Deblurring/outputs/saved_images'\n",
    "os.makedirs(image_dir, exist_ok=True)\n",
    "    \n",
    "def save_decoded_image(img, name):\n",
    "    img = img.view(img.size(0), 3, 224, 224)\n",
    "    save_image(img, name)\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print(device)\n",
    "\n",
    "batch_size = 2\n",
    "\n",
    "gauss_blur = os.listdir('drive/My Drive/Image-Deblurring/input/gaussian_blurred/')\n",
    "gauss_blur.sort()\n",
    "sharp = os.listdir('drive/My Drive/Image-Deblurring/input/sharp/')\n",
    "sharp.sort()\n",
    "\n",
    "x_blur = []\n",
    "for i in range(len(gauss_blur)):\n",
    "    x_blur.append(gauss_blur[i])\n",
    "\n",
    "y_sharp = []\n",
    "for i in range(len(sharp)):\n",
    "    y_sharp.append(sharp[i])\n",
    "    \n",
    "print(x_blur[10])\n",
    "print(y_sharp[10])\n",
    "\n",
    "(x_train, x_val, y_train, y_val) = train_test_split(x_blur, y_sharp, test_size=0.25)\n",
    "\n",
    "print(len(x_train))\n",
    "print(len(x_val))\n",
    "\n",
    "# define transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "class DeblurDataset(Dataset):\n",
    "    def __init__(self, blur_paths, sharp_paths=None, transforms=None):\n",
    "        self.X = blur_paths\n",
    "        self.y = sharp_paths\n",
    "        self.transforms = transforms\n",
    "         \n",
    "    def __len__(self):\n",
    "        return (len(self.X))\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        blur_image = cv2.imread(f\"drive/My Drive/Image-Deblurring/input/gaussian_blurred/{self.X[i]}\")\n",
    "        \n",
    "        if self.transforms:\n",
    "            blur_image = self.transforms(blur_image)\n",
    "            \n",
    "        if self.y is not None:\n",
    "            sharp_image = cv2.imread(f\"drive/My Drive/Image-Deblurring/input/sharp/{self.y[i]}\")\n",
    "            sharp_image = self.transforms(sharp_image)\n",
    "            return (blur_image, sharp_image)\n",
    "        else:\n",
    "            return blur_image\n",
    "\n",
    "train_data = DeblurDataset(x_train, y_train, transform)\n",
    "val_data = DeblurDataset(x_val, y_val, transform)\n",
    " \n",
    "trainloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "valloader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "model = models.CNN().to(device)\n",
    "print(model)\n",
    "\n",
    "# the loss function\n",
    "criterion = nn.MSELoss()\n",
    "# the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau( \n",
    "        optimizer,\n",
    "        mode='min',\n",
    "        patience=5,\n",
    "        factor=0.1,\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "def fit(model, dataloader, epoch):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in tqdm(enumerate(dataloader), total=int(len(train_data)/dataloader.batch_size)):\n",
    "        blur_image = data[0]\n",
    "        sharp_image = data[1]\n",
    "        blur_image = blur_image.to(device)\n",
    "        sharp_image = sharp_image.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(blur_image)\n",
    "        loss = criterion(outputs, sharp_image)\n",
    "        # backpropagation\n",
    "        loss.backward()\n",
    "        # update the parameters\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    train_loss = running_loss/len(dataloader.dataset)\n",
    "    print(f\"Train Loss: {train_loss:.5f}\")\n",
    "    \n",
    "    return train_loss\n",
    "\n",
    "# the training function\n",
    "def validate(model, dataloader, epoch):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for i, data in tqdm(enumerate(dataloader), total=int(len(val_data)/dataloader.batch_size)):\n",
    "            blur_image = data[0]\n",
    "            sharp_image = data[1]\n",
    "            blur_image = blur_image.to(device)\n",
    "            sharp_image = sharp_image.to(device)\n",
    "            outputs = model(blur_image)\n",
    "            loss = criterion(outputs, sharp_image)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            if epoch == 0 and i == (len(val_data)/dataloader.batch_size)-1:\n",
    "                save_decoded_image(sharp_image.cpu().data, name=f\"drive/My Drive/Image-Deblurring/outputs/saved_images/sharp{epoch}.jpg\")\n",
    "                save_decoded_image(blur_image.cpu().data, name=f\"drive/My Drive/Image-Deblurring/outputs/saved_images/blur{epoch}.jpg\")\n",
    "\n",
    "        val_loss = running_loss/len(dataloader.dataset)\n",
    "        print(f\"Val Loss: {val_loss:.5f}\")\n",
    "\n",
    "        save_decoded_image(outputs.cpu().data, name=f\"drive/My Drive/Image-Deblurring/outputs/saved_images/val_deblurred{epoch}.jpg\")\n",
    "        \n",
    "        return val_loss\n",
    "\n",
    "train_loss  = []\n",
    "val_loss = []\n",
    "start = time.time()\n",
    "for epoch in range(args['epochs']):\n",
    "    print(f\"Epoch {epoch+1} of {args['epochs']}\")\n",
    "    train_epoch_loss = fit(model, trainloader, epoch)\n",
    "    val_epoch_loss = validate(model, valloader, epoch)\n",
    "    train_loss.append(train_epoch_loss)\n",
    "    val_loss.append(val_epoch_loss)\n",
    "    scheduler.step(val_epoch_loss)\n",
    "end = time.time()\n",
    "\n",
    "print(f\"Took {((start-end)/60):.3f} minutes to train\")\n",
    "\n",
    "# loss plots\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(train_loss, color='orange', label='train loss')\n",
    "plt.plot(val_loss, color='red', label='validataion loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.savefig('drive/My Drive/Image-Deblurring/outputs/loss.png')\n",
    "plt.show()\n",
    "\n",
    "# save the model to disk\n",
    "print('Saving model...')\n",
    "torch.save(model.state_dict(), 'drive/My Drive/Image-Deblurring/outputs/model.pth')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
